{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QyMLXsfVvob"
   },
   "source": [
    "# Recursos de la GPU\n",
    "\n",
    "Pr치ctica realizada por: \n",
    "- Blanca Cano Camarero\n",
    "- Iker Villegas Labairu\n",
    "\n",
    "\n",
    "Nota: Los datos en las tablas pueden varias ligeramente por no tratarse de la misma ejecuci칩n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faOZSDwBWxNz"
   },
   "source": [
    "Comprobamos las caracter칤sticas del sistema proporcionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAu0BAAmVyej",
    "outputId": "b50a82ee-5280-4299-b3ba-cf40a2989e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:        x86_64\n",
      "CPU op-mode(s):      32-bit, 64-bit\n",
      "Byte Order:          Little Endian\n",
      "CPU(s):              2\n",
      "On-line CPU(s) list: 0,1\n",
      "Thread(s) per core:  2\n",
      "Core(s) per socket:  1\n",
      "Socket(s):           1\n",
      "NUMA node(s):        1\n",
      "Vendor ID:           GenuineIntel\n",
      "CPU family:          6\n",
      "Model:               85\n",
      "Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "Stepping:            3\n",
      "CPU MHz:             2000.154\n",
      "BogoMIPS:            4000.30\n",
      "Hypervisor vendor:   KVM\n",
      "Virtualization type: full\n",
      "L1d cache:           32K\n",
      "L1i cache:           32K\n",
      "L2 cache:            1024K\n",
      "L3 cache:            39424K\n",
      "NUMA node0 CPU(s):   0,1\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VyM8Gg-V5pl",
    "outputId": "6266b127-c5e6-4e40-ecbc-3a0e634ee2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            12G        576M         10G        1.3M        1.8G         11G\n",
      "Swap:            0B          0B          0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrFEkPjCW_aS"
   },
   "source": [
    "Verificamos la versi칩n de CUDA que tenemos instalada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Z8DAfpWXHMV",
    "outputId": "19a91a5e-dfe4-4aa2-bb6f-9982d2d10080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Feb_14_21:12:58_PST_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.152\n",
      "Build cuda_11.2.r11.2/compiler.29618528_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KnY6rCSXYN_",
    "outputId": "241976ea-1025-4065-bc36-caa4b78ff177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 16 08:54:05 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P8    13W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H09O_xsWXcZz"
   },
   "source": [
    "Procedemos a comprobar las caracter칤stica de las GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efn6F8D7XaYI",
    "outputId": "73628564-4fae-4010-f98a-b502a6e38546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-11.2/samples/1_Utilities/deviceQuery\n"
     ]
    }
   ],
   "source": [
    "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6lNabJQXj-n",
    "outputId": "43ec5e89-46c9-4407-a771-7d582169b62e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviceQuery.cpp  Makefile  NsightEclipse.xml  readme.txt\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJJVu3oMXlWw",
    "outputId": "107a85bc-388a-4649-c24f-047de1eee2fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-11.2/bin/nvcc -ccbin g++ -I../../common/inc  -m64    --threads 0 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86 -o deviceQuery.o -c deviceQuery.cpp\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "/usr/local/cuda-11.2/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86 -o deviceQuery deviceQuery.o \n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mkdir -p ../../bin/x86_64/linux/release\n",
      "cp deviceQuery ../../bin/x86_64/linux/release\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qagVg_BnXmpc",
    "outputId": "11ba56de-efcc-4236-809f-b174ff1fd7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./deviceQuery Starting...\n",
      "\n",
      " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
      "\n",
      "Detected 1 CUDA Capable device(s)\n",
      "\n",
      "Device 0: \"Tesla T4\"\n",
      "  CUDA Driver Version / Runtime Version          11.2 / 11.2\n",
      "  CUDA Capability Major/Minor version number:    7.5\n",
      "  Total amount of global memory:                 15110 MBytes (15843721216 bytes)\n",
      "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
      "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
      "  Memory Clock rate:                             5001 Mhz\n",
      "  Memory Bus Width:                              256-bit\n",
      "  L2 Cache Size:                                 4194304 bytes\n",
      "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
      "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
      "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
      "  Total amount of constant memory:               65536 bytes\n",
      "  Total amount of shared memory per block:       49152 bytes\n",
      "  Total shared memory per multiprocessor:        65536 bytes\n",
      "  Total number of registers available per block: 65536\n",
      "  Warp size:                                     32\n",
      "  Maximum number of threads per multiprocessor:  1024\n",
      "  Maximum number of threads per block:           1024\n",
      "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
      "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
      "  Maximum memory pitch:                          2147483647 bytes\n",
      "  Texture alignment:                             512 bytes\n",
      "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
      "  Run time limit on kernels:                     No\n",
      "  Integrated GPU sharing Host Memory:            No\n",
      "  Support host page-locked memory mapping:       Yes\n",
      "  Alignment requirement for Surfaces:            Yes\n",
      "  Device has ECC support:                        Enabled\n",
      "  Device supports Unified Addressing (UVA):      Yes\n",
      "  Device supports Managed Memory:                Yes\n",
      "  Device supports Compute Preemption:            Yes\n",
      "  Supports Cooperative Kernel Launch:            Yes\n",
      "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
      "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
      "  Compute Mode:\n",
      "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
      "\n",
      "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.2, CUDA Runtime Version = 11.2, NumDevs = 1\n",
      "Result = PASS\n"
     ]
    }
   ],
   "source": [
    "!./deviceQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HocL1ygajJ9"
   },
   "source": [
    "Ahora en base a la informaci칩n obtenida con los comandos anteriores, procedemos a detallar los recursos siguientes:\n",
    "\n",
    "\n",
    "*   **Modelo de CPU, n칰mero de cores y frecuencia de funcionamiento:** 85 (Intel (R) Xeon (R) CPU @ 2.00GHz), 1 core, \n",
    "*   **Memoria de la CPU:** 12 G\n",
    "*   **Tarjeta gr치fica:**\n",
    "*   **Versi칩n de Cuda, indicando en que directorio est치 instalado en el sistema:** version 11.2, instalada en el directorio `/usr/local/cuda-11.2/samples/1_Utilities/deviceQuery`.\n",
    "*   **CUDA capability:** 7.5.\n",
    "*   **Frecuencia de la GPU:**\n",
    "*   **N칰mero de registros disponibles:** 65536\n",
    "*   **M치ximo n칰mero de threads por bloque:** 1024\n",
    "*   **Memoria compartida por bloque:** 49152 bytes.\n",
    "*   **N칰mero m치ximo de threads por core (SP):**\n",
    "*   **Tama침o del Warp:** 32.\n",
    "*   **Memoria de la GPU:**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35XmPTneX90y"
   },
   "source": [
    "# Suma de dos vectores\n",
    "\n",
    "# 5.2  Qu칠 hace el c칩digo de suma0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_UBbLJ0YDRb",
    "outputId": "3b7f012f-a445-40a9-ab77-e8a4e8ab8dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma0.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma0.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "void add(int n, float *x, float *y) {\n",
    "    \n",
    "    for (int i =0; i < n; i++ ){\n",
    "        y[i]=x[i]+y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "\n",
    "    float *x = new float[N];\n",
    "    float *y = new float[N]; \n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de Errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "   \n",
    "   delete [] x;\n",
    "   delete [] y;\n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH81__xhYut7"
   },
   "source": [
    "**Soluci칩n**. \n",
    "\n",
    "Se muestra en la casilla de c칩digo anterior el c칩digo suma0\n",
    "Como podemos ver el c칩digo se compone de dos funciones: \n",
    "\n",
    "- `add`: Dados dos arrays $x,y$ de la misma longitud $n$ suma coordenada a cada coordenada de $y$ la respectiva coordenada de $x$. \n",
    "- `main` funci칩n principal que va a ejecutarse y que comprende los siguientes pasos: \n",
    "\n",
    "1. **Inicializaci칩n de los vectores** con tama침o $N = 2^{20}$. $X$ es un vector de unos e $y$ es un vector de dos. \n",
    "\n",
    "2. Se **llama a la funci칩n suma** midiendo el tiempo que tarda. \n",
    "3. Se **muestra una serie de estad칤sticos** como: n칰mero de coordenadas sumadas, el n칰mero de errores que ha habido en cada coordenada, y el error m치ximo. \n",
    "\n",
    "A continuaci칩n mostramos su ejecuci칩n: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpHzgKj9bOoT",
    "outputId": "4d5fd334-2ed2-4e6f-85e6-a05d618dc665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo : 3.105000 ms\n",
      "suma de 1048576 Elementos\n",
      "N칰mero de Errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "# Compilaci칩n de CUDA (aunque aqu칤 no utiliza funciones propias de cuda)\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma0.cu -o suma0 -lcudadevrt\n",
    "!./suma0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnzSyjcibvOA"
   },
   "source": [
    "Como era de esperar no hay erroes de c치lculo y han sido sumados todas las coordenadas, adem치s destacamos que el tiempo obtendio de c치lculo ha sido: \n",
    "$$3.517000 ms$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfhcB4AWcHUx"
   },
   "source": [
    "##  Qu칠 hace el c칩digo de suma1 ?\n",
    "\n",
    "A continuaci칩n mostramos el c칩digo suma1: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxofn2zzcx4O",
    "outputId": "47a47caa-daf0-4333-c328-a682338ef48e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma1.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__ void add(int n, float *x, float *y) {\n",
    "    \n",
    "    for (int i =0; i < n; i++ ){\n",
    "        y[i]=x[i]+y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add<<<1,1>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de Errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0JZzC6Ec2CS"
   },
   "source": [
    "**Soluci칩n** \n",
    "\n",
    "Notemos que ahora la estrutura y funci칩n del c칩digo es la misma salvo que se est치 programando para poder ejecutarse en gr치ficas de envida. \n",
    "\n",
    "Esto supone la adici칩n con respecto a la implementaci칩n anterior: \n",
    "1. Macros de caracter global para la funci칩n`add`.\n",
    "2. Reservar el espacio de memoria para alojar en la gr치fica, con la funci칩n ` cudaMallocManaged`. \n",
    "3. Recibir los resultados de la app. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGyphZWvewd3",
    "outputId": "1e2f6203-3e99-41ed-e8dc-dc62c17d73b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo : 0.056000 ms\n",
      "Tiempo con el synchronize  : 109.472000 ms\n",
      "suma de 1048576 Elementos\n",
      "N칰mero de Errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma1.cu -o suma1 -lcudadevrt\n",
    "!./suma1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihbYWkgLfAEP"
   },
   "source": [
    "Veamos que ahora el tiempo de c치lculo se es de \n",
    "$$0.048000 ms$$ \n",
    "pero que a침adiendo el tiempo de sincronizaci칩n asciende a\n",
    "\n",
    "$$109.487000 ms$$\n",
    "\n",
    "que es superior a los $3.517000 ms$ en suma0, luego podemos observar la existencia de un cuello de botella en la sincronizaci칩n. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sh-k8yvEgccf",
    "outputId": "c93ae77d-ff35-4dc7-8163-74b8ec2b0a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo del c치lculo : 0.032000 ms\n",
      "Tiempo con el synchronize  : 109.409000 ms\n",
      "suma de 1048576 Elementos\n",
      "N칰mero de Errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de ejcuci칩n sin especificar la arquitectura\n",
    "\n",
    "!/usr/local/cuda/bin/nvcc -rdc=true suma1.cu -o suma1sinarch -lcudadevrt\n",
    "!./suma1sinarch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nY1bM8-CfmIs"
   },
   "source": [
    "## P1: 쯈u칠 caracter칤stica del modelo de computaci칩n esta siendo necesaria para que el ejemplo funcione correctamente?\n",
    "\n",
    "\n",
    "La diferencia que se intentaba mostrar era la necesidad de compilar con un `flag` determinado para especificar la arquitectura. En actualizaciones actuales esto ya no es necesario y por eso no apreciamos errores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXsgi5VVhDeN"
   },
   "source": [
    "## P2 쯃a suma ha tardado m치s o menos que en la CPU? Justifique como est치 funcionando.\n",
    "\n",
    "Ya adelant치bamos eta respuesta con anterioridad: \n",
    "\n",
    "El tiempo de c치lculo es de \n",
    "$$0.048000 ms$$ \n",
    "pero que a침adiendo el tiempo de sincronizaci칩n asciende a\n",
    "\n",
    "$$109.487000 ms$$\n",
    "\n",
    "que es superior a los $3.517000 ms$ en suma0, luego podemos observar la existencia de un cuello de botella en la sincronizaci칩n. \n",
    "\n",
    "Esto pone de manifiesto la necesidad de utilizar la gr치fica cuando el n칰mero de operaciones sea lo suficientemente grande como para que a pesar de a침adir la sincronizaci칩n merezca la pena el utilizar la GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWmtwc66hpQl"
   },
   "source": [
    "# 5.4  Qu칠 hace el c칩digo de suma2 ?\n",
    "\n",
    "El c칩digo suma2 es el siguiente: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOq_BiIOhu1a",
    "outputId": "f56e6cc5-0661-4926-ded6-4fea7b90f65c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma2.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__ void add(int n, float *x, float *y) {\n",
    "    \n",
    "    for (int i =0; i < n; i++ ){\n",
    "        y[i]=x[i]+y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add<<<1,256>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo suma2 : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWsIlVqOh52A",
    "outputId": "1ec4d66b-0700-4022-eec1-28420e5635ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo suma2 : 0.027000 ms\n",
      "Tiempo con el synchronize  : 116.435000 ms\n",
      "Suma de 1048576 elementos\n",
      "N칰mero de errores: 1048451\n",
      "Max error: 7\n"
     ]
    }
   ],
   "source": [
    "# Compilaci칩n y ejecuci칩n \n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
    "!./suma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njc2mXiGihEe"
   },
   "source": [
    "# P3 쯃a suma ha funcionado?  Ha tardado m치s o menos que en el caso anterior? Explique como est치 funcionando y si podr칤an generarse situaciones de funcionamiento incorrecto.\n",
    "\n",
    "**Soluci칩n**\n",
    "\n",
    "Notemos que a diferencia con suma1, ahora la diferencia principal del c칩digo es la siguiente: \n",
    "\n",
    "`add<<<1,256>>>(N, x, y);`\n",
    "\n",
    "Esto lo que hace es comenzar una rutina en paralelo, en **un bloque** y con **256** hebras, donde en cada hebra se repiten todos los c치lculos. \n",
    "\n",
    "Todos hilos est치n trabajando con las mismas posiciones de memoria a la vez y esto explica que se den situaciones como que no est칠n actualizadas posiciones de memoria necesarias, es decir que *corrompan los datos guardados*, produciendo errores aleatorios y diferentes en cada ejecuci칩n. \n",
    "\n",
    "Respecto al tiempo de c칩mputo vemos que a ascendido un poco, pero se mantiene en mismo rango que cuando trabaj치bamos con una hebra sola,  esto se debe a la sobrecarga de gestionar distintos hilos. \n",
    "\n",
    "Lo ideal ser칤a repartir la carga de trabajo entre los hilos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LCY7dKnlab2"
   },
   "source": [
    "# 5.5  Qu칠 hace el c칩digo de suma3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqfGLpxclY4K",
    "outputId": "d121e2d4-07a5-4c77-d74d-72c17ec3c998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma3.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "\n",
    "__global__ void add(int n, float *x, float *y) {\n",
    "    \n",
    "    for (int i =0; i < n; i++ ){\n",
    "        y[i]=x[i]+y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add<<<256,1>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo suma3 : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de Errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNrllw0YlhOW",
    "outputId": "71f4e6c8-0a43-4cb9-ceee-2bde368d59ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo suma3 : 0.027000 ms\n",
      "Tiempo con el synchronize  : 138.911000 ms\n",
      "suma de 1048576 Elementos\n",
      "N칰mero de Errores: 1048568\n",
      "Max error: 255\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma3.cu -o suma3 -lcudadevrt\n",
    "!./suma3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgC8daU3lyYp"
   },
   "source": [
    "**Soluci칩n** \n",
    "\n",
    "Podemos apreciar que ahora se est치 realizando un paralelismo a nivel de bloque\n",
    "\n",
    "`add<<<256,1>>>(N, x, y);`\n",
    "Lo llamativo ahora es el error, que es exactamente mayor al n칰mero de hebras que se ejecuta. \n",
    "\n",
    "## P4 쯃a suma tarda ha tardado m치s o menos que en el caso anterior? Explique que est치 pasando.\n",
    "\n",
    "La suma ha tardado pr치cticamente igual que en el caso de suma2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNFf9oksmy_6"
   },
   "source": [
    "# 5.6  Qu칠 hace el c칩digo de suma4 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmA40t0OnIPr",
    "outputId": "6efef5f8-3ea1-4d16-b5ab-b7b135980b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma4.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = threadIdx.x;\n",
    "  int stride = blockDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "//__global__ void add(int n, float *x, float *y) {\n",
    "//    for (int i =0; i < n; i++ ){\n",
    "//        y[i]=x[i]+y[i];\n",
    "//    }\n",
    "//}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add<<<1,256>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo suma 4 : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b0567dsnq73",
    "outputId": "ced77b95-c0ff-4aec-9bee-5a04d56d96eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo suma 4 : 0.034000 ms\n",
      "Tiempo con el synchronize  : 2.887000 ms\n",
      "Suma de 1048576 elementos\n",
      "N칰mero de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma4.cu -o suma4 -lcudadevrt\n",
    "!./suma4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pr0EXXy7nMAh"
   },
   "source": [
    "Si nos fijamos en el c칩digo \n",
    "\n",
    "```c++\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = threadIdx.x;\n",
    "  int stride = blockDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];\n",
    "}\n",
    "```\n",
    "\n",
    "ahora se est치 aprovechando correctamente el paralelismo sin repetir c치lculo. \n",
    "\n",
    "# P5 Compare con el tiempo de ejecuci칩n de un solo Thread y con la ejecuci칩n en CPU.쯈ue puede deducir de estos comportamientos?\n",
    "\n",
    "(Vamos a suponer que una ejecuci칩n es lo suficientemente significativa y no se va realizar el c치lculo de un tiempo medio ni test de hip칩tesis) \n",
    "\n",
    "\n",
    "El tiempo obtenido con un bloque y 256 hebras es de:`\n",
    "\n",
    "```\n",
    "Tiempo del c치lculo suma 4 : 0.027000 ms\n",
    "Tiempo con el synchronize  : 4.124000 ms\n",
    "````\n",
    "\n",
    "Que si recordamos el tiempo para CPU era de \n",
    "\n",
    "```\n",
    "3.517000 洧녴洧 \n",
    "```\n",
    "\n",
    "Vemos que el tiempo de c치lculo es al rededor de 150% menor en el uso de las hebra, pero que \n",
    "sin embargo el tiempo de sincronizaci칩n supera al una CPU y eso hace que para nuestro peque침a situaci칩n no merezca la pena. \n",
    "\n",
    "\n",
    "# P6 쯉e puede seguir optimizando?  \n",
    "\n",
    "Se puede mejorar el tiempo de c치lculo, combinando el uso de hebras y bloques, v칠ase como ejemplo el c칩digo suma 5. Sin embargo el tiempo de sincronizaci칩n no se podr치 mejorar y no hemos conseguimos superar al de la CPU por mucha optimizaci칩n que realicemos en los c치lculos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT25Fb3wrF1M"
   },
   "source": [
    "P7 Realice el paralelismo correspondiente a la Suma en la GPU con paralelismo <<<256,1>> y estudie el comportamiento de los tiempos de ejecuci칩n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OonrGkw9rt9J",
    "outputId": "fc66b673-d521-461e-b1eb-c95038a2e260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma4_bloque.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma4_bloque.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index =  blockIdx.x * blockDim.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];    \n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "    \n",
    "    int NUM_BLOQUES =  256; // 2^8\n",
    "    add<<<NUM_BLOQUES,1>>>(N, x, y);\n",
    "    \n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo suma 4 bloque: %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0){\n",
    "          contError++; \n",
    "       }\n",
    "   }\n",
    "  \n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4BZSxk2tAy1",
    "outputId": "22e58cf7-bcdb-49cd-9248-1089e3caee1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo suma 4 bloque: 0.034000 ms\n",
      "Tiempo con el synchronize  : 3.889000 ms\n",
      "Suma de 1048576 elementos\n",
      "N칰mero de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma4_bloque.cu -o suma4_bloque -lcudadevrt\n",
    "!./suma4_bloque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1oyFHn2hrxN"
   },
   "source": [
    "# 5.7  Qu칠 hace el c칩digo de suma5 ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brDKETddiK_K"
   },
   "source": [
    "**Soluci칩n**\n",
    "\n",
    "En esta nueva iteraci칩n del programa los cambios son los siguientes: \n",
    "- La funci칩n suma ahora tiene en cuenta el n칰mero de bloque y la hebra. \n",
    "- El n칰mero de bloque y hebra viene dada por: \n",
    "\n",
    "```\n",
    " int blockSize = 256;\n",
    " int numBlocks = (N + blockSize - 1) / blockSize;  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bh6e6LtqhzQO",
    "outputId": "5839f743-da27-448f-f706-9bb3af8d906a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma5.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    \n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "   add<<<numBlocks, blockSize>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo suma 5 : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90JTs707iD3f",
    "outputId": "581488a8-ff8c-4847-eb10-470ef0e9a4e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo suma 5 : 0.030000 ms\n",
      "Tiempo con el synchronize  : 2.454000 ms\n",
      "Suma de 1048576 elementos\n",
      "N칰mero de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma5.cu -o suma5 -lcudadevrt\n",
    "!./suma5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIHs0SU8jU0q"
   },
   "source": [
    "P8 Compare con el tiempo de ejecuci칩n con el resto de ejemplos anteriores.쯈ue puede deducir de estos comportamientos? \n",
    "\n",
    "**Soluci칩n**\n",
    "\n",
    "Podemos obervar que este ha sido el programa m치s eficiente, ya que los tiempos optenidos han sido (nota, este resultado puede variar ligeramente si se vuelve a ejecutar: \n",
    "\n",
    "Programa | Tiempo c치lculo (ms) | Tiempo sincronizaci칩n  (ms)  | Descripci칩n    \n",
    "--- | --- | ---  | --- \n",
    "suma 0 |   3.23 | = | Ejecuci칩n CPU  \n",
    "Suma 1 | 0.057 | 108 | Ejecutamos para una hebra y un bloque \n",
    "Suma 2 | 0.036 | 130 | Repetimos el mismo c치lculo e 256 hebras\n",
    "Suma 3 | 0.031 | 141 |  Repetimos el mismo c치lculo e 256 bloque  \n",
    "Suma 4| 0.03 | 2.93 | Repartimos tareas en 256 hebras\n",
    "Suma 5 | 0.03 | 2 |    Reparto de tareareas bloque y hebras \n",
    "\n",
    "\n",
    "A la vista de los resultados suma 5 ha sabido aprovechar los recursos y ser el mejor tiempo, superando incluso a la CPU. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dj_6S9CYn5MF"
   },
   "source": [
    "# P9 Pruebe el 칰ltimo ejercicio con m치s threads por bloque y explique los resultados obtenidos \n",
    "\n",
    "El c칩digo modificaci칩n del c칩digo consiste en aumentar el tama침o de la variable\n",
    "\n",
    "`int blockSize = 1 <<9;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCFY3A4Kn-Qh",
    "outputId": "7c6d66af-fc5b-4a8a-d2a1-3242b98dca58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma6.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma6.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    int blockSize = 1 <<9;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    \n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "   add<<<numBlocks, blockSize>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo suma con 2^9 hebras : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "us_ANUbboHHY",
    "outputId": "7eb00bdd-d900-42e4-f3ee-fdf6178642b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo suma con 2^9 hebras : 0.032000 ms\n",
      "Tiempo con el synchronize  : 2.228000 ms\n",
      "Suma de 1048576 elementos\n",
      "N칰mero de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma6.cu -o suma6 -lcudadevrt\n",
    "!./suma6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pfBQgoupgtV"
   },
   "source": [
    "Los resultados obtenidos han sido los siguientes: \n",
    "\n",
    "\n",
    "Programa | Tiempo c치lculo (ms) | Tiempo sincronizaci칩n  (ms)  | Descripci칩n    \n",
    "--- | --- | ---  | ---   \n",
    "Suma 4| 0.03 | 2.93 | Repartimos tareas en 256 hebras\n",
    "Suma 5 | 0.0300 | 2.13 |    Reparto de tareareas bloque y hebras \n",
    "suma 6 | 0.034 | 2.65 | Aumentamos el reparto a 2^9 hebras en vez de a 2^8\n",
    "\n",
    "\n",
    "Los tiempo de c치lculo no han mejorado, esto se debe a que estamos superando el l칤mite de hebras m치ximas que se pueden ejecutar en paralelo por bloque y por tanto a침adiendo un coste de c칩mputo adicional. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1NhUlknrQB3"
   },
   "source": [
    "# P10 Modifique el 칰ltimo ejercicio para permitir vectores de tama침o N que no sean m칰ltiplos del n칰mero de threads por bloque que se est칠 usando. Indique los cambios que han sido necesarios.\n",
    "\n",
    "**Soluci칩n**. \n",
    "\n",
    "Lo 칰nico que tendremos que hacer es a침adir una condici칩n de salida en el caso de que se vayan a superar las iteraciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGsELml-rpoV",
    "outputId": "b130ba66-eb8f-4342-c03e-d92431d9decd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma7.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma7.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n ; i += stride) {\n",
    "    if(i >= n) break;\n",
    "    y[i] = x[i] + y[i];\n",
    "  }\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    N--; // Quitamos uno para que ya no sea m칰ltiplo\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize; // ceil \n",
    "    \n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "   add<<<numBlocks, blockSize>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del c치lculo suma con N no m칰ltiplo : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HF25iVIruge",
    "outputId": "5d00e0fa-3b06-4087-abb9-02419e40c2ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del c치lculo suma con N no m칰ltiplo : 0.043000 ms\n",
      "Tiempo con el synchronize  : 2.259000 ms\n",
      "Suma de 1048575 elementos\n",
      "N칰mero de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma7.cu -o suma7 -lcudadevrt\n",
    "!./suma7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eD3hkYzatxAz"
   },
   "source": [
    "# 6. Suma de 2 matrices\n",
    "Refs:\n",
    "http://www.mat.unimi.it/users/sansotte/cuda/CUDA_by_Example.pdf. \n",
    "\n",
    "Se propone extender el c칩digo del ejemplo anterior para que realice la resta (o suma) de matrices cuadradas de dimensi칩n N.\n",
    "\n",
    "- Configure adecuadamente el Grid de threads para aceptar matrices de cualquier tama침o.\n",
    "- En el kernel, utilice las variables blockIdx y threadIdx adecuadamente para acceder a una estructura bidimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsrUYEoEuVx9"
   },
   "source": [
    "**Soluci칩n** \n",
    "\n",
    "\n",
    "La idea se mantiene pero ahora trabajaremos en una dimensi칩n m치s. \n",
    "Para ello ser치 necesario a침adir la dimensi칩n en la funci칩n `MatAdd`. \n",
    "\n",
    "Adem치s ahora cada hebra se encargar치 de una operaci칩n. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2lgyjBgAAlI",
    "outputId": "1ac2f795-a562-4c2f-9a1f-f9bdd250e62c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrices2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrices2.cu\n",
    "#include <algorithm>\n",
    "#include <iostream>\n",
    "\n",
    "const int N = 10;\n",
    "\n",
    "__global__ void MatAdd(float A[][N], float B[][N], float C[][N])\n",
    "{\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    if (i < N && j < N)\n",
    "        C[i][j] = A[i][j] + B[i][j];\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    float* A; cudaMallocManaged(&A, N*N*sizeof(float));\n",
    "    float* B; cudaMallocManaged(&B, N*N*sizeof(float));\n",
    "    float* C; cudaMallocManaged(&C, N*N*sizeof(float));\n",
    "\n",
    "    float A_vals[N][N]; \n",
    "    float B_vals[N][N]; \n",
    "    for(int i= 0; i < N; i++){\n",
    "      for(int j=0; j<N; j++){\n",
    "        A_vals[i][j] = 1.0f;\n",
    "        B_vals[i][j] = 2.0f;\n",
    "      }\n",
    "    }\n",
    "    float (*C_vals)[N] = reinterpret_cast<float (*)[N]>(C);\n",
    "\n",
    "    std::copy(&A_vals[0][0], &A_vals[0][0] + N*N, A);\n",
    "    std::copy(&B_vals[0][0], &B_vals[0][0] + N*N, B);\n",
    "\n",
    "    const int numberOfThread = N;\n",
    "    const int numberOfBlocks = (N - 1 + numberOfThread) / numberOfThread; // ceil \n",
    "    dim3 threadsPerBlock(numberOfThread, numberOfThread);\n",
    "    dim3 numBlocks(numberOfBlocks, numberOfBlocks);\n",
    "\n",
    "    MatAdd<<<numBlocks, threadsPerBlock>>>( reinterpret_cast<float (*)[N]>(A),\n",
    "                                            reinterpret_cast<float (*)[N]>(B),\n",
    "                                            C_vals );\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    \n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "\n",
    "   for(int i= 0; i < N; i++){\n",
    "      for(int j=0; j<N; j++){\n",
    "        maxError=fmax(maxError,fabs(C_vals[i][j]-3.0f));\n",
    "        if (C_vals[i][j] != 3.0) contError++; \n",
    "      }\n",
    "    }\n",
    "\n",
    "   \n",
    "   std::cout << \"Suma de dos matrices con \" << N*N << \" elementos\" << std::endl;\n",
    "   std::cout << \"N칰mero de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "\n",
    "   // Free memory\n",
    "   cudaFree (A);\n",
    "   cudaFree (B);\n",
    "    return 0;\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLJvXimlAPJz",
    "outputId": "bec951e6-2464-434e-8ea8-1bb9046cba20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Suma de dos matrices con 100 elementos\n",
      "N칰mero de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true matrices2.cu -o matrices2 -lcudadevrt\n",
    "!./matrices2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFh-s45N-SYR"
   },
   "source": [
    "# 7. Stencil1d: Estudiar el efecto de la memoria compartida\n",
    "Descripci칩n:\n",
    "El c칩digo stencil 1D es 칰til para entender los beneficios y uso de memoria compartida en una GPU. Para hacerlo explicito conviene valorar los resultados utilizando el generador de perfiles ( `nvprof`) que muestra los cuellos de botella y su efecto en la aceleraci칩n final que se consigue.\n",
    "Pasos:\n",
    "1. Primero compile y ejecute el c칩digo sin usar memoria compartida. Hacer un perfil con `nvprof` y sacar el comportamiento temporal.\n",
    "2. Use el generador de perfiles para determinar cu치l es el problema.\n",
    "3. Introduzca la modificaci칩n en el c칩digo para hacer uso de la memoria compartida.\n",
    "Valore la situaci칩n que sucede cuando no se usa la funci칩n __syncthreads (). Ejecute el c칩digo varias veces y observe cuando se obtienen errores semi-aleatorios en la salida.\n",
    "8. A침adiendo __syncthreads () evalue despu칠s de las diferentes modificaciones la aceleraci칩n obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wil7WJ0y9K_f"
   },
   "source": [
    "## 1. Primero compile y ejecute el c칩digo sin usar memoria compartida. Hacer un perfil con nvprof y sacar el comportamiento temporal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkGdJj-BcdUy",
    "outputId": "be05a572-8466-4bf6-bf4f-fe62721c7136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stencil1d_1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_1.cu\n",
    "\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) \n",
    "{\n",
    "    // Just one global index \n",
    "    int index = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    "\n",
    "    // Apply the stencil\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
    "        result += in[index + offset];\n",
    "\n",
    "    // Store the result\n",
    "    out[index-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  unsigned int i;\n",
    "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "  int *d_in, *d_out;\n",
    "\n",
    "  // Initialize host data\n",
    "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
    "\n",
    "  // Allocate space on the device\n",
    "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "  // Copy input data to device\n",
    "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "  // Verify every out value is 7\n",
    "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
    "    if (h_out[i] != 7)\n",
    "    {\n",
    "      printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
    "      break;\n",
    "    }\n",
    "\n",
    "  if (i == NUM_ELEMENTS)\n",
    "    printf(\"SUCCESS!\\n\");\n",
    "\n",
    "  // Free out memory\n",
    "  cudaFree(d_in);\n",
    "  cudaFree(d_out);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPKobWhu-ud4"
   },
   "source": [
    "## Comportamiento sin utilizar memoria compartidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfavSjnZ-I0X",
    "outputId": "0e3f7794-cdc9-403a-afb6-8589606ce945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==621== NVPROF is profiling process 621, command: ./stencil1d_1\n",
      "SUCCESS!\n",
      "==621== Profiling application: ./stencil1d_1\n",
      "==621== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   36.15%  5.3440us         1  5.3440us  5.3440us  5.3440us  [CUDA memcpy HtoD]\n",
      "                   33.33%  4.9280us         1  4.9280us  4.9280us  4.9280us  stencil_1d(int*, int*)\n",
      "                   30.52%  4.5120us         1  4.5120us  4.5120us  4.5120us  [CUDA memcpy DtoH]\n",
      "      API calls:   99.68%  250.77ms         2  125.39ms  5.5350us  250.77ms  cudaMalloc\n",
      "                    0.15%  381.62us         1  381.62us  381.62us  381.62us  cuDeviceTotalMem\n",
      "                    0.06%  160.22us       101  1.5860us     132ns  72.238us  cuDeviceGetAttribute\n",
      "                    0.05%  116.72us         2  58.361us  9.0930us  107.63us  cudaFree\n",
      "                    0.03%  75.952us         2  37.976us  27.817us  48.135us  cudaMemcpy\n",
      "                    0.01%  28.307us         1  28.307us  28.307us  28.307us  cuDeviceGetName\n",
      "                    0.01%  27.647us         1  27.647us  27.647us  27.647us  cudaLaunchKernel\n",
      "                    0.00%  6.2030us         1  6.2030us  6.2030us  6.2030us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.6360us         3     545ns     209ns  1.1460us  cuDeviceGetCount\n",
      "                    0.00%  1.1570us         2     578ns     216ns     941ns  cuDeviceGet\n",
      "                    0.00%     268ns         1     268ns     268ns     268ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_1.cu -o stencil1d_1 -lcudadevrt\n",
    "\n",
    "!nvprof ./stencil1d_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDd3R_Xd-_xo"
   },
   "source": [
    "## 2. Use el generador de perfiles para determinar cu치l es el problema.\n",
    "\n",
    "**Soluci칩n**\n",
    "\n",
    "En vista a la gr치fica anterior es f치cil ver que el cuello de botella se encuentra en \n",
    "\n",
    "` API calls:   99.70%  279.86ms         2  139.93ms  5.0210us  279.86ms  cudaMalloc` ya que consume el `99.70%`. \n",
    "\n",
    "Que seg칰n la documentaci칩n oficial: *Allocates size bytes of linear memory on the device and returns in \\*devPtr a pointer to the allocated memory.*\n",
    "\n",
    "Es por tanto natural plantearse un sistema que reduzca este tiempo utilizando memoria compartida entre hilos. Veremos el efecto de esto en los siguientes apartados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G3BFG_W_Oy8"
   },
   "source": [
    "\n",
    "# 3. Introduzca la modificaci칩n en el c칩digo para hacer uso de la memoria compartida.\n",
    "Valore la situaci칩n que sucede cuando no se usa la funci칩n __syncthreads (). Ejecute el c칩digo varias veces y observe cuando se obtienen errores semi-aleatorios en la salida.\n",
    "\n",
    "\n",
    "**Soluci칩n sin `_synchthreads()`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWahwwWv_d6H",
    "outputId": "9fef6725-d084-4e5c-d33d-7df099dc35b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stencil1d_2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_2.cu\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) \n",
    "{\n",
    "    __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n",
    "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    "    int lindex = threadIdx.x + RADIUS;\n",
    "\n",
    "    // Read input elements into shared memory\n",
    "    temp[lindex] = in[gindex];\n",
    "    if (threadIdx.x < RADIUS) \n",
    "    {\n",
    "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
    "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
    "    }\n",
    "\n",
    "    // Make sure all threads get to this point before proceeding!\n",
    "    //__syncthreads();\n",
    "\n",
    "    // Apply the stencil\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
    "        result += temp[lindex + offset];\n",
    "\n",
    "    // Store the result\n",
    "    out[gindex-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  unsigned int i;\n",
    "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "  int *d_in, *d_out;\n",
    "\n",
    "  // Initialize host data\n",
    "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
    "\n",
    "  // Allocate space on the device\n",
    "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "  // Copy input data to device\n",
    "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "  // Verify every out value is 7\n",
    "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
    "    if (h_out[i] != 7)\n",
    "    {\n",
    "      printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
    "      break;\n",
    "    }\n",
    "\n",
    "  if (i == NUM_ELEMENTS)\n",
    "    printf(\"SUCCESS!\\n\");\n",
    "\n",
    "  // Free out memory\n",
    "  cudaFree(d_in);\n",
    "  cudaFree(d_out);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqgaI72e_zyb",
    "outputId": "c062ee58-491a-4aa9-fa9b-5730b122b548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Element h_out[0] == 2 != 7\n",
      "Element h_out[0] == 2 != 7\n",
      "Element h_out[0] == 2 != 7\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_2.cu -o stencil1d_2 -lcudadevrt\n",
    "\n",
    "repeticiones = 3\n",
    "for i in range(repeticiones):\n",
    "  !./stencil1d_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-jJOTwrATiL"
   },
   "source": [
    "Como vemos est치n ocurriendo errores, esto se debe a que se est치 produciendo *data race* (condici칩n de carrera) con los threads, ya que no se est치 haciendo uso de la funci칩n que sincroniza los hilos. \n",
    "\n",
    "## Versi칩n que sincroniza la hebras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CR3JkBRLBRrV",
    "outputId": "46487ac6-3955-4b49-f3c1-4fa6b2d5f8ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stencil1d_3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_3.cu\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) \n",
    "{\n",
    "    __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n",
    "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    "    int lindex = threadIdx.x + RADIUS;\n",
    "\n",
    "    // Read input elements into shared memory\n",
    "    temp[lindex] = in[gindex];\n",
    "    if (threadIdx.x < RADIUS) \n",
    "    {\n",
    "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
    "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
    "    }\n",
    "\n",
    "    // Make sure all threads get to this point before proceeding!\n",
    "    __syncthreads();\n",
    "\n",
    "    // Apply the stencil\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
    "        result += temp[lindex + offset];\n",
    "\n",
    "    // Store the result\n",
    "    out[gindex-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  unsigned int i;\n",
    "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "  int *d_in, *d_out;\n",
    "\n",
    "  // Initialize host data\n",
    "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
    "\n",
    "  // Allocate space on the device\n",
    "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "  // Copy input data to device\n",
    "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "  // Verify every out value is 7\n",
    "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
    "    if (h_out[i] != 7)\n",
    "    {\n",
    "      printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
    "      break;\n",
    "    }\n",
    "\n",
    "  if (i == NUM_ELEMENTS)\n",
    "    printf(\"SUCCESS! \");\n",
    "\n",
    "  // Free out memory\n",
    "  cudaFree(d_in);\n",
    "  cudaFree(d_out);\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1HXmQ3jBg4L",
    "outputId": "156ce70a-c963-4cb2-88de-6a86d196312b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! "
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_3.cu -o stencil1d_3 -lcudadevrt\n",
    "\n",
    "repeticiones = 10\n",
    "for i in range(repeticiones):\n",
    "  !./stencil1d_3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_giij0LB0d2"
   },
   "source": [
    "Podemos observar que ya se ejetua con 칠xito el programa. \n",
    "\n",
    "Veamos ahora el profile: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XaUQygkfCJJ3",
    "outputId": "76279cf7-84c3-4d68-f06c-f81095daaa01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==737== NVPROF is profiling process 737, command: ./stencil1d_3\n",
      "SUCCESS! ==737== Profiling application: ./stencil1d_3\n",
      "==737== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   38.17%  5.8870us         1  5.8870us  5.8870us  5.8870us  [CUDA memcpy HtoD]\n",
      "                   32.78%  5.0560us         1  5.0560us  5.0560us  5.0560us  stencil_1d(int*, int*)\n",
      "                   29.04%  4.4790us         1  4.4790us  4.4790us  4.4790us  [CUDA memcpy DtoH]\n",
      "      API calls:   99.59%  200.10ms         2  100.05ms  5.4880us  200.09ms  cudaMalloc\n",
      "                    0.20%  403.24us         1  403.24us  403.24us  403.24us  cuDeviceTotalMem\n",
      "                    0.08%  164.77us       101  1.6310us     143ns  70.656us  cuDeviceGetAttribute\n",
      "                    0.05%  106.13us         2  53.066us  7.7810us  98.352us  cudaFree\n",
      "                    0.04%  77.835us         2  38.917us  28.998us  48.837us  cudaMemcpy\n",
      "                    0.02%  31.427us         1  31.427us  31.427us  31.427us  cuDeviceGetName\n",
      "                    0.01%  23.953us         1  23.953us  23.953us  23.953us  cudaLaunchKernel\n",
      "                    0.00%  6.5490us         1  6.5490us  6.5490us  6.5490us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9540us         3     651ns     255ns  1.3380us  cuDeviceGetCount\n",
      "                    0.00%  1.4540us         2     727ns     234ns  1.2200us  cuDeviceGet\n",
      "                    0.00%     268ns         1     268ns     268ns     268ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!nvprof ./stencil1d_3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26mDqJVJDFRh"
   },
   "source": [
    "Tengamos presentes que los resultados con el primer profile fueron de: \n",
    "\n",
    "```\n",
    "==738== Profiling result:\n",
    "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
    " GPU activities:   38.20%  5.6960us         1  5.6960us  5.6960us  5.6960us  [CUDA memcpy HtoD]\n",
    "                   32.40%  4.8320us         1  4.8320us  4.8320us  4.8320us  stencil_1d(int*, int*)\n",
    "                   29.40%  4.3840us         1  4.3840us  4.3840us  4.3840us  [CUDA memcpy DtoH]\n",
    "      API calls:   99.70%  279.86ms         2  139.93ms  5.0210us  279.86ms  cudaMalloc\n",
    "                    0.13%  372.11us         1  372.11us  372.11us  372.11us  cuDeviceTotalMem\n",
    "                    0.06%  162.05us       101  1.6040us     123ns  65.153us  cuDeviceGetAttribute\n",
    "                    0.05%  130.15us         2  65.072us  52.962us  77.183us  cudaMemcpy\n",
    "                    0.04%  118.75us         2  59.373us  11.104us  107.64us  cudaFree\n",
    "                    0.01%  30.679us         1  30.679us  30.679us  30.679us  cudaLaunchKernel\n",
    "                    0.01%  27.238us         1  27.238us  27.238us  27.238us  cuDeviceGetName\n",
    "                    0.00%  7.3760us         1  7.3760us  7.3760us  7.3760us  cuDeviceGetPCIBusId\n",
    "                    0.00%  1.2530us         3     417ns     187ns     723ns  cuDeviceGetCount\n",
    "                    0.00%  1.1450us         2     572ns     313ns     832ns  cuDeviceGet\n",
    "                    0.00%     231ns         1     231ns     231ns     231ns  cuDeviceGetUuid\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKrTIUveDn9S"
   },
   "source": [
    "A la vista de estos resultados hemos mejorado significativamente el tiempo de `cudaMalloc` y `cudaMemcpy`, que ha reducido su tiempo casi a la mitad. \n",
    "\n",
    "Lo cual se corresponde con el funcionamiento esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIgIP4OIF-tV"
   },
   "source": [
    "# Ejercicios opcionales de la pr치ctica 2\n",
    "\n",
    "# 8. Producto de matrices en \n",
    "\n",
    "## Ejecuci칩n del c칩digo de CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwA35Fb6GukH",
    "outputId": "fa27e8b3-ff56-4db1-8d68-e9f8ca2c4427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing producto_cpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile producto_cpu.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define N 16\n",
    "#define M 1\n",
    "\n",
    "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]){\n",
    "    int n, m;\n",
    "    for (int i = 0; i < N; i++){\n",
    "        for (int j = 0; j < N; j++){\n",
    "            int sum = 0;\n",
    "            for (int k = 0; k < N; k++){\n",
    "                m = a[i][k];\n",
    "                n = b[k][j];\n",
    "                sum += m*n;\n",
    "            }\n",
    "            c[i][j] = sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultCPU(a, b, c);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    for (int y = 0; y < N; y++){\n",
    "        for (int x = 0; x < N; x++){\n",
    "            printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXJqGSJMHKub",
    "outputId": "adcd02d3-a3ec-4ead-f539-de5184f25217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['==781== NVPROF is profiling process 781, command: ./producto_cpu',\n",
       " '[0][0]=0 [0][1]=0 [0][2]=0 [0][3]=0 [0][4]=0 [0][5]=0 [0][6]=0 [0][7]=0 [0][8]=0 [0][9]=0 [0][10]=0 [0][11]=0 [0][12]=0 [0][13]=0 [0][14]=0 [0][15]=0 ',\n",
       " '[1][0]=120 [1][1]=120 [1][2]=120 [1][3]=120 [1][4]=120 [1][5]=120 [1][6]=120 [1][7]=120 [1][8]=120 [1][9]=120 [1][10]=120 [1][11]=120 [1][12]=120 [1][13]=120 [1][14]=120 [1][15]=120 ',\n",
       " '[2][0]=240 [2][1]=240 [2][2]=240 [2][3]=240 [2][4]=240 [2][5]=240 [2][6]=240 [2][7]=240 [2][8]=240 [2][9]=240 [2][10]=240 [2][11]=240 [2][12]=240 [2][13]=240 [2][14]=240 [2][15]=240 ',\n",
       " '[3][0]=360 [3][1]=360 [3][2]=360 [3][3]=360 [3][4]=360 [3][5]=360 [3][6]=360 [3][7]=360 [3][8]=360 [3][9]=360 [3][10]=360 [3][11]=360 [3][12]=360 [3][13]=360 [3][14]=360 [3][15]=360 ',\n",
       " '[4][0]=480 [4][1]=480 [4][2]=480 [4][3]=480 [4][4]=480 [4][5]=480 [4][6]=480 [4][7]=480 [4][8]=480 [4][9]=480 [4][10]=480 [4][11]=480 [4][12]=480 [4][13]=480 [4][14]=480 [4][15]=480 ',\n",
       " '[5][0]=600 [5][1]=600 [5][2]=600 [5][3]=600 [5][4]=600 [5][5]=600 [5][6]=600 [5][7]=600 [5][8]=600 [5][9]=600 [5][10]=600 [5][11]=600 [5][12]=600 [5][13]=600 [5][14]=600 [5][15]=600 ',\n",
       " '[6][0]=720 [6][1]=720 [6][2]=720 [6][3]=720 [6][4]=720 [6][5]=720 [6][6]=720 [6][7]=720 [6][8]=720 [6][9]=720 [6][10]=720 [6][11]=720 [6][12]=720 [6][13]=720 [6][14]=720 [6][15]=720 ',\n",
       " '[7][0]=840 [7][1]=840 [7][2]=840 [7][3]=840 [7][4]=840 [7][5]=840 [7][6]=840 [7][7]=840 [7][8]=840 [7][9]=840 [7][10]=840 [7][11]=840 [7][12]=840 [7][13]=840 [7][14]=840 [7][15]=840 ',\n",
       " '[8][0]=960 [8][1]=960 [8][2]=960 [8][3]=960 [8][4]=960 [8][5]=960 [8][6]=960 [8][7]=960 [8][8]=960 [8][9]=960 [8][10]=960 [8][11]=960 [8][12]=960 [8][13]=960 [8][14]=960 [8][15]=960 ',\n",
       " '[9][0]=1080 [9][1]=1080 [9][2]=1080 [9][3]=1080 [9][4]=1080 [9][5]=1080 [9][6]=1080 [9][7]=1080 [9][8]=1080 [9][9]=1080 [9][10]=1080 [9][11]=1080 [9][12]=1080 [9][13]=1080 [9][14]=1080 [9][15]=1080 ',\n",
       " '[10][0]=1200 [10][1]=1200 [10][2]=1200 [10][3]=1200 [10][4]=1200 [10][5]=1200 [10][6]=1200 [10][7]=1200 [10][8]=1200 [10][9]=1200 [10][10]=1200 [10][11]=1200 [10][12]=1200 [10][13]=1200 [10][14]=1200 [10][15]=1200 ',\n",
       " '[11][0]=1320 [11][1]=1320 [11][2]=1320 [11][3]=1320 [11][4]=1320 [11][5]=1320 [11][6]=1320 [11][7]=1320 [11][8]=1320 [11][9]=1320 [11][10]=1320 [11][11]=1320 [11][12]=1320 [11][13]=1320 [11][14]=1320 [11][15]=1320 ',\n",
       " '[12][0]=1440 [12][1]=1440 [12][2]=1440 [12][3]=1440 [12][4]=1440 [12][5]=1440 [12][6]=1440 [12][7]=1440 [12][8]=1440 [12][9]=1440 [12][10]=1440 [12][11]=1440 [12][12]=1440 [12][13]=1440 [12][14]=1440 [12][15]=1440 ',\n",
       " '[13][0]=1560 [13][1]=1560 [13][2]=1560 [13][3]=1560 [13][4]=1560 [13][5]=1560 [13][6]=1560 [13][7]=1560 [13][8]=1560 [13][9]=1560 [13][10]=1560 [13][11]=1560 [13][12]=1560 [13][13]=1560 [13][14]=1560 [13][15]=1560 ',\n",
       " '[14][0]=1680 [14][1]=1680 [14][2]=1680 [14][3]=1680 [14][4]=1680 [14][5]=1680 [14][6]=1680 [14][7]=1680 [14][8]=1680 [14][9]=1680 [14][10]=1680 [14][11]=1680 [14][12]=1680 [14][13]=1680 [14][14]=1680 [14][15]=1680 ',\n",
       " '[15][0]=1800 [15][1]=1800 [15][2]=1800 [15][3]=1800 [15][4]=1800 [15][5]=1800 [15][6]=1800 [15][7]=1800 [15][8]=1800 [15][9]=1800 [15][10]=1800 [15][11]=1800 [15][12]=1800 [15][13]=1800 [15][14]=1800 [15][15]=1800 ',\n",
       " 'GigaFlops: 0.668018==781== Profiling application: ./producto_cpu',\n",
       " '==781== Profiling result:',\n",
       " 'No kernels were profiled.',\n",
       " '            Type  Time(%)      Time     Calls       Avg       Min       Max  Name',\n",
       " '      API calls:   99.75%  241.65ms         2  120.83ms  1.3340us  241.65ms  cudaEventCreate',\n",
       " '                    0.15%  358.08us         1  358.08us  358.08us  358.08us  cuDeviceTotalMem',\n",
       " '                    0.07%  170.55us       101  1.6880us     130ns  71.752us  cuDeviceGetAttribute',\n",
       " '                    0.01%  36.254us         1  36.254us  36.254us  36.254us  cuDeviceGetName',\n",
       " '                    0.01%  14.734us         2  7.3670us  4.1010us  10.633us  cudaEventRecord',\n",
       " '                    0.00%  8.8030us         1  8.8030us  8.8030us  8.8030us  cudaEventSynchronize',\n",
       " '                    0.00%  6.0870us         1  6.0870us  6.0870us  6.0870us  cuDeviceGetPCIBusId',\n",
       " '                    0.00%  1.9970us         1  1.9970us  1.9970us  1.9970us  cudaEventElapsedTime',\n",
       " '                    0.00%  1.5940us         3     531ns     175ns  1.0930us  cuDeviceGetCount',\n",
       " '                    0.00%  1.2740us         2     637ns     295ns     979ns  cuDeviceGet',\n",
       " '                    0.00%     399ns         1     399ns     399ns     399ns  cuDeviceGetUuid']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true producto_cpu.cu -o producto_cpu -lcudadevrt\n",
    "!!nvprof ./producto_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNQ6LIcCMIAl"
   },
   "source": [
    "## GPU memoria global "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGz2fq8tMMbi",
    "outputId": "c79f0693-635d-461b-8fdc-9fcd1eb7a63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gpu_global.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile gpu_global.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#define N 16\n",
    "#define M 1\n",
    "\n",
    "__global__ void matrixMultGPU(int *a, int *b, int *c){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "    int fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
    "    if (col < N && fil < N){\n",
    "        for (k = 0; k < N; k++){\n",
    "            sum += a[fil*N+k] * b[k*N+col];\n",
    "        }\n",
    "        c[fil*N+col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int *dev_a, *dev_b, *dev_c;\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid(M, M);\n",
    "    dim3 dimBlock(N, N);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "    for (int y = 0; y < N; y++){\n",
    "        for (int x = 0; x < N; x++){\n",
    "            printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgkK-HCzMjQc",
    "outputId": "4133c227-2667-4720-9e7e-6c527301a3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==825== NVPROF is profiling process 825, command: ./gpu_global\n",
      "[0][0]=0 [0][1]=0 [0][2]=0 [0][3]=0 [0][4]=0 [0][5]=0 [0][6]=0 [0][7]=0 [0][8]=0 [0][9]=0 [0][10]=0 [0][11]=0 [0][12]=0 [0][13]=0 [0][14]=0 [0][15]=0 \n",
      "[1][0]=120 [1][1]=120 [1][2]=120 [1][3]=120 [1][4]=120 [1][5]=120 [1][6]=120 [1][7]=120 [1][8]=120 [1][9]=120 [1][10]=120 [1][11]=120 [1][12]=120 [1][13]=120 [1][14]=120 [1][15]=120 \n",
      "[2][0]=240 [2][1]=240 [2][2]=240 [2][3]=240 [2][4]=240 [2][5]=240 [2][6]=240 [2][7]=240 [2][8]=240 [2][9]=240 [2][10]=240 [2][11]=240 [2][12]=240 [2][13]=240 [2][14]=240 [2][15]=240 \n",
      "[3][0]=360 [3][1]=360 [3][2]=360 [3][3]=360 [3][4]=360 [3][5]=360 [3][6]=360 [3][7]=360 [3][8]=360 [3][9]=360 [3][10]=360 [3][11]=360 [3][12]=360 [3][13]=360 [3][14]=360 [3][15]=360 \n",
      "[4][0]=480 [4][1]=480 [4][2]=480 [4][3]=480 [4][4]=480 [4][5]=480 [4][6]=480 [4][7]=480 [4][8]=480 [4][9]=480 [4][10]=480 [4][11]=480 [4][12]=480 [4][13]=480 [4][14]=480 [4][15]=480 \n",
      "[5][0]=600 [5][1]=600 [5][2]=600 [5][3]=600 [5][4]=600 [5][5]=600 [5][6]=600 [5][7]=600 [5][8]=600 [5][9]=600 [5][10]=600 [5][11]=600 [5][12]=600 [5][13]=600 [5][14]=600 [5][15]=600 \n",
      "[6][0]=720 [6][1]=720 [6][2]=720 [6][3]=720 [6][4]=720 [6][5]=720 [6][6]=720 [6][7]=720 [6][8]=720 [6][9]=720 [6][10]=720 [6][11]=720 [6][12]=720 [6][13]=720 [6][14]=720 [6][15]=720 \n",
      "[7][0]=840 [7][1]=840 [7][2]=840 [7][3]=840 [7][4]=840 [7][5]=840 [7][6]=840 [7][7]=840 [7][8]=840 [7][9]=840 [7][10]=840 [7][11]=840 [7][12]=840 [7][13]=840 [7][14]=840 [7][15]=840 \n",
      "[8][0]=960 [8][1]=960 [8][2]=960 [8][3]=960 [8][4]=960 [8][5]=960 [8][6]=960 [8][7]=960 [8][8]=960 [8][9]=960 [8][10]=960 [8][11]=960 [8][12]=960 [8][13]=960 [8][14]=960 [8][15]=960 \n",
      "[9][0]=1080 [9][1]=1080 [9][2]=1080 [9][3]=1080 [9][4]=1080 [9][5]=1080 [9][6]=1080 [9][7]=1080 [9][8]=1080 [9][9]=1080 [9][10]=1080 [9][11]=1080 [9][12]=1080 [9][13]=1080 [9][14]=1080 [9][15]=1080 \n",
      "[10][0]=1200 [10][1]=1200 [10][2]=1200 [10][3]=1200 [10][4]=1200 [10][5]=1200 [10][6]=1200 [10][7]=1200 [10][8]=1200 [10][9]=1200 [10][10]=1200 [10][11]=1200 [10][12]=1200 [10][13]=1200 [10][14]=1200 [10][15]=1200 \n",
      "[11][0]=1320 [11][1]=1320 [11][2]=1320 [11][3]=1320 [11][4]=1320 [11][5]=1320 [11][6]=1320 [11][7]=1320 [11][8]=1320 [11][9]=1320 [11][10]=1320 [11][11]=1320 [11][12]=1320 [11][13]=1320 [11][14]=1320 [11][15]=1320 \n",
      "[12][0]=1440 [12][1]=1440 [12][2]=1440 [12][3]=1440 [12][4]=1440 [12][5]=1440 [12][6]=1440 [12][7]=1440 [12][8]=1440 [12][9]=1440 [12][10]=1440 [12][11]=1440 [12][12]=1440 [12][13]=1440 [12][14]=1440 [12][15]=1440 \n",
      "[13][0]=1560 [13][1]=1560 [13][2]=1560 [13][3]=1560 [13][4]=1560 [13][5]=1560 [13][6]=1560 [13][7]=1560 [13][8]=1560 [13][9]=1560 [13][10]=1560 [13][11]=1560 [13][12]=1560 [13][13]=1560 [13][14]=1560 [13][15]=1560 \n",
      "[14][0]=1680 [14][1]=1680 [14][2]=1680 [14][3]=1680 [14][4]=1680 [14][5]=1680 [14][6]=1680 [14][7]=1680 [14][8]=1680 [14][9]=1680 [14][10]=1680 [14][11]=1680 [14][12]=1680 [14][13]=1680 [14][14]=1680 [14][15]=1680 \n",
      "[15][0]=1800 [15][1]=1800 [15][2]=1800 [15][3]=1800 [15][4]=1800 [15][5]=1800 [15][6]=1800 [15][7]=1800 [15][8]=1800 [15][9]=1800 [15][10]=1800 [15][11]=1800 [15][12]=1800 [15][13]=1800 [15][14]=1800 [15][15]=1800 \n",
      "GigaFlops: 1.221502==825== Profiling application: ./gpu_global\n",
      "==825== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.90%  5.3954ms      1000  5.3950us  5.2800us  14.016us  matrixMultGPU(int*, int*, int*)\n",
      "                    0.06%  3.3920us         2  1.6960us  1.5040us  1.8880us  [CUDA memcpy HtoD]\n",
      "                    0.04%  2.1760us         1  2.1760us  2.1760us  2.1760us  [CUDA memcpy DtoH]\n",
      "      API calls:   97.23%  259.96ms         2  129.98ms     982ns  259.96ms  cudaEventCreate\n",
      "                    1.65%  4.4228ms      1000  4.4220us  3.2020us  26.529us  cudaLaunchKernel\n",
      "                    0.75%  2.0088ms         1  2.0088ms  2.0088ms  2.0088ms  cudaEventSynchronize\n",
      "                    0.15%  392.15us         1  392.15us  392.15us  392.15us  cuDeviceTotalMem\n",
      "                    0.07%  175.90us         3  58.631us  1.9950us  170.24us  cudaMalloc\n",
      "                    0.06%  157.44us       101  1.5580us     134ns  66.800us  cuDeviceGetAttribute\n",
      "                    0.06%  147.19us         3  49.063us  2.4900us  134.47us  cudaFree\n",
      "                    0.02%  56.798us         3  18.932us  8.3980us  28.383us  cudaMemcpy\n",
      "                    0.01%  30.590us         1  30.590us  30.590us  30.590us  cuDeviceGetName\n",
      "                    0.00%  8.2380us         2  4.1190us  3.8510us  4.3870us  cudaEventRecord\n",
      "                    0.00%  5.9590us         1  5.9590us  5.9590us  5.9590us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.3440us         1  2.3440us  2.3440us  2.3440us  cudaEventElapsedTime\n",
      "                    0.00%  1.3310us         2     665ns     242ns  1.0890us  cuDeviceGet\n",
      "                    0.00%  1.3040us         3     434ns     184ns     778ns  cuDeviceGetCount\n",
      "                    0.00%     298ns         1     298ns     298ns     298ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true gpu_global.cu -o gpu_global -lcudadevrt\n",
    "!nvprof ./gpu_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OHMjW_zNDlM"
   },
   "source": [
    "Obs칠rvese que con el uso de CPU con memoria global ahora el n칰mero de \n",
    "`Gflops` es de `GigaFlops: 1.248567` mientras que con CPU era de `GigaFlops: 0.460247` lo cual ya supone una mejora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj8KxcUCOBrZ"
   },
   "source": [
    "## Optimizaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6hSDhBvOEeH",
    "outputId": "b25acd2c-fbf5-49a4-83b7-f560c4007b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing optimizaciones.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile optimizaciones.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#define N 64\n",
    "#define MAX 8\n",
    "\n",
    "__global__ void matrixMultGPU(int *a, int *b, int *c, int n){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int thx = threadIdx.x;\n",
    "    int thy = threadIdx.y;\n",
    "    int col = thx + blockDim.x * blockIdx.x;\n",
    "    int fil = thy + blockDim.y * blockIdx.y;\n",
    "\n",
    "    __shared__ float Aij[MAX][MAX];\n",
    "    __shared__ float Bij[MAX][MAX];\n",
    "\n",
    "    for (int lim = 0; lim < (n + MAX - 1)/MAX; lim++){\n",
    "        if ((thy + (lim*MAX)) < n  && col < n){\n",
    "            Aij[thy][thx] = a[(col*n) + (thy + (lim*MAX))];\n",
    "        }\n",
    "        else {\n",
    "            Aij[thy][thx] = 0.0;\n",
    "        }\n",
    "        if ((thx + (lim*MAX)) < n  && fil < n){\n",
    "            Bij[thy][thx] = b[((thx + (lim*MAX))*n) + fil];\n",
    "        }\n",
    "        else{\n",
    "            Bij[thy][thx] = 0.0;\n",
    "        }\n",
    "        __syncthreads();\n",
    "    #pragma unroll\n",
    "        for (k = 0; k < MAX; k++){\n",
    "            sum += Aij[k][thx] * Bij[thy][k];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (col < n && fil < n){\n",
    "        c[col * n + fil] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int *dev_a, *dev_b, *dev_c;\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid((N + MAX - 1)/MAX, (N + MAX - 1)/MAX);\n",
    "    dim3 dimBlock(MAX, MAX);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c, N);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "    //for (int y = 0; y < N; y++){\n",
    "    //    for (int x = 0; x < N; x++){\n",
    "    //        printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "    //    }\n",
    "    //    printf(\"\\n\");\n",
    "    //}\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\\n\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNt7HstJOv27",
    "outputId": "30dd8df4-c22e-44ec-ed01-ea7e435f28a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==869== NVPROF is profiling process 869, command: ./optimizaciones\n",
      "GigaFlops: 45.511742\n",
      "==869== Profiling application: ./optimizaciones\n",
      "==869== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.90%  10.271ms      1000  10.270us  10.175us  11.008us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.07%  6.7830us         2  3.3910us  3.0720us  3.7110us  [CUDA memcpy HtoD]\n",
      "                    0.03%  3.2000us         1  3.2000us  3.2000us  3.2000us  [CUDA memcpy DtoH]\n",
      "      API calls:   95.33%  249.28ms         2  124.64ms  1.0350us  249.27ms  cudaEventCreate\n",
      "                    2.70%  7.0662ms         1  7.0662ms  7.0662ms  7.0662ms  cudaEventSynchronize\n",
      "                    1.60%  4.1792ms      1000  4.1790us  3.1720us  24.539us  cudaLaunchKernel\n",
      "                    0.13%  344.53us         1  344.53us  344.53us  344.53us  cuDeviceTotalMem\n",
      "                    0.07%  190.43us         3  63.476us  3.3350us  181.34us  cudaMalloc\n",
      "                    0.06%  148.76us       101  1.4720us     132ns  62.913us  cuDeviceGetAttribute\n",
      "                    0.05%  131.40us         3  43.801us  2.3320us  119.06us  cudaFree\n",
      "                    0.03%  85.705us         3  28.568us  15.595us  39.288us  cudaMemcpy\n",
      "                    0.01%  33.835us         1  33.835us  33.835us  33.835us  cuDeviceGetName\n",
      "                    0.00%  8.9580us         2  4.4790us  4.1690us  4.7890us  cudaEventRecord\n",
      "                    0.00%  5.6160us         1  5.6160us  5.6160us  5.6160us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.1630us         1  2.1630us  2.1630us  2.1630us  cudaEventElapsedTime\n",
      "                    0.00%  1.2800us         2     640ns     200ns  1.0800us  cuDeviceGet\n",
      "                    0.00%  1.2100us         3     403ns     202ns     693ns  cuDeviceGetCount\n",
      "                    0.00%     289ns         1     289ns     289ns     289ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true optimizaciones.cu -o optimizaciones -lcudadevrt\n",
    "!nvprof ./optimizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjBCd4FKO56F"
   },
   "source": [
    "Con la optimizaci칩n de memoria compartida y desenrollado de bucles se han obtenido `GigaFlops: 45.45454` lo cual supera claramente a los `GigaFlops: 1.248567` de GPU con memoria global. \n",
    "\n",
    "A la vista de estos resultados conlcu칤mos que si bien el uso de la GPU acelera los c치lculos, lo que verdaderamente marcar치 la diferencia es la optimizaci칩n del c칩digo. \n",
    "\n",
    "\n",
    "A contnuaci칩n vamos a limpiar un poco la salida de los programas y efectuar los experimentos para poder completar las tablas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbBFtOLpQ8KT",
    "outputId": "d64ede92-ae49-4470-fcc3-5a9c0d8abe37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gpu_global_2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile gpu_global_2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#define M 1\n",
    "\n",
    "__global__ void matrixMultGPU(int N, int *a, int *b, int *c){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "    int fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
    "    if (col < N && fil < N){\n",
    "        for (k = 0; k < N; k++){\n",
    "            sum += a[fil*N+k] * b[k*N+col];\n",
    "        }\n",
    "        c[fil*N+col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    int N = strtol(argv[1], NULL, 10);\n",
    "\n",
    "    printf(\"Matriz %d x %d \", N, N);\n",
    "\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int *dev_a, *dev_b, *dev_c;\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid(M, M);\n",
    "    dim3 dimBlock(N, N);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(N, dev_a, dev_b, dev_c);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "  /*\n",
    "    for (int y = 0; y < N; y++){\n",
    "        for (int x = 0; x < N; x++){\n",
    "            printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "*/\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f \\n\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gr42A_R8RgtU",
    "outputId": "77fae855-a6c6-4319-a5b8-c7b7701a9e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==915== NVPROF is profiling process 915, command: ./gpu_global_2 16\n",
      "Matriz 16 x 16 GigaFlops: 1.202392 \n",
      "==915== Profiling application: ./gpu_global_2 16\n",
      "==915== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.89%  5.4742ms      1000  5.4740us  5.4070us  9.7920us  matrixMultGPU(int, int*, int*, int*)\n",
      "                    0.07%  3.8400us         2  1.9200us  1.5360us  2.3040us  [CUDA memcpy HtoD]\n",
      "                    0.04%  2.1760us         1  2.1760us  2.1760us  2.1760us  [CUDA memcpy DtoH]\n",
      "      API calls:   97.11%  253.36ms         2  126.68ms     984ns  253.36ms  cudaEventCreate\n",
      "                    1.57%  4.0983ms      1000  4.0980us  3.2060us  27.146us  cudaLaunchKernel\n",
      "                    0.94%  2.4525ms         1  2.4525ms  2.4525ms  2.4525ms  cudaEventSynchronize\n",
      "                    0.14%  368.30us         1  368.30us  368.30us  368.30us  cuDeviceTotalMem\n",
      "                    0.09%  231.34us         3  77.112us  2.3770us  224.19us  cudaMalloc\n",
      "                    0.06%  151.48us       101  1.4990us     129ns  63.858us  cuDeviceGetAttribute\n",
      "                    0.05%  137.02us         3  45.672us  2.5340us  123.28us  cudaFree\n",
      "                    0.02%  64.960us         3  21.653us  8.5500us  32.295us  cudaMemcpy\n",
      "                    0.01%  28.995us         1  28.995us  28.995us  28.995us  cuDeviceGetName\n",
      "                    0.00%  8.1340us         2  4.0670us  3.7400us  4.3940us  cudaEventRecord\n",
      "                    0.00%  6.0250us         1  6.0250us  6.0250us  6.0250us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.2580us         1  2.2580us  2.2580us  2.2580us  cudaEventElapsedTime\n",
      "                    0.00%  1.4610us         3     487ns     202ns     894ns  cuDeviceGetCount\n",
      "                    0.00%  1.1260us         2     563ns     205ns     921ns  cuDeviceGet\n",
      "                    0.00%     264ns         1     264ns     264ns     264ns  cuDeviceGetUuid\n",
      "==926== NVPROF is profiling process 926, command: ./gpu_global_2 32\n",
      "Matriz 32 x 32 GigaFlops: 4.497363 \n",
      "==926== Profiling application: ./gpu_global_2 32\n",
      "==926== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.95%  13.301ms      1000  13.301us  13.055us  13.791us  matrixMultGPU(int, int*, int*, int*)\n",
      "                    0.03%  3.8720us         2  1.9360us  1.7600us  2.1120us  [CUDA memcpy HtoD]\n",
      "                    0.02%  2.3040us         1  2.3040us  2.3040us  2.3040us  [CUDA memcpy DtoH]\n",
      "      API calls:   92.53%  188.86ms         2  94.430ms     821ns  188.86ms  cudaEventCreate\n",
      "                    5.05%  10.312ms         1  10.312ms  10.312ms  10.312ms  cudaEventSynchronize\n",
      "                    1.96%  4.0083ms      1000  4.0080us  3.1710us  30.453us  cudaLaunchKernel\n",
      "                    0.17%  356.40us         1  356.40us  356.40us  356.40us  cuDeviceTotalMem\n",
      "                    0.08%  168.98us         3  56.326us  2.3590us  163.32us  cudaMalloc\n",
      "                    0.08%  159.33us       101  1.5770us     126ns  72.262us  cuDeviceGetAttribute\n",
      "                    0.06%  121.21us         3  40.404us  2.5130us  109.55us  cudaFree\n",
      "                    0.03%  59.704us         3  19.901us  9.5110us  32.149us  cudaMemcpy\n",
      "                    0.01%  29.050us         1  29.050us  29.050us  29.050us  cuDeviceGetName\n",
      "                    0.00%  7.8340us         2  3.9170us  3.6080us  4.2260us  cudaEventRecord\n",
      "                    0.00%  7.2390us         1  7.2390us  7.2390us  7.2390us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.5790us         1  2.5790us  2.5790us  2.5790us  cudaEventElapsedTime\n",
      "                    0.00%  1.5480us         3     516ns     176ns  1.0500us  cuDeviceGetCount\n",
      "                    0.00%  1.2970us         2     648ns     206ns  1.0910us  cuDeviceGet\n",
      "                    0.00%     283ns         1     283ns     283ns     283ns  cuDeviceGetUuid\n",
      "==937== NVPROF is profiling process 937, command: ./gpu_global_2 64\n",
      "Matriz 64 x 64 GigaFlops: 1310.615089 \n",
      "==937== Profiling application: ./gpu_global_2 64\n",
      "==937== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   66.35%  6.7520us         2  3.3760us  3.3280us  3.4240us  [CUDA memcpy HtoD]\n",
      "                   33.65%  3.4240us         1  3.4240us  3.4240us  3.4240us  [CUDA memcpy DtoH]\n",
      "      API calls:   99.42%  191.71ms         2  95.857ms  1.0330us  191.71ms  cudaEventCreate\n",
      "                    0.18%  353.30us         1  353.30us  353.30us  353.30us  cuDeviceTotalMem\n",
      "                    0.10%  183.41us      1000     183ns     162ns  6.1460us  cudaLaunchKernel\n",
      "                    0.09%  173.11us         3  57.703us  2.0360us  167.95us  cudaMalloc\n",
      "                    0.09%  166.68us       101  1.6500us     128ns  80.332us  cuDeviceGetAttribute\n",
      "                    0.05%  98.640us         3  32.880us  2.2320us  90.806us  cudaFree\n",
      "                    0.04%  86.481us         3  28.827us  14.647us  46.129us  cudaMemcpy\n",
      "                    0.01%  26.787us         1  26.787us  26.787us  26.787us  cuDeviceGetName\n",
      "                    0.00%  6.8650us         1  6.8650us  6.8650us  6.8650us  cudaEventSynchronize\n",
      "                    0.00%  6.3030us         2  3.1510us  2.2420us  4.0610us  cudaEventRecord\n",
      "                    0.00%  5.2900us         1  5.2900us  5.2900us  5.2900us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9780us         1  1.9780us  1.9780us  1.9780us  cudaEventElapsedTime\n",
      "                    0.00%  1.2640us         2     632ns     304ns     960ns  cuDeviceGet\n",
      "                    0.00%  1.2340us         3     411ns     190ns     737ns  cuDeviceGetCount\n",
      "                    0.00%     322ns         1     322ns     322ns     322ns  cuDeviceGetUuid\n",
      "==948== NVPROF is profiling process 948, command: ./gpu_global_2 128\n",
      "Matriz 128 x 128 GigaFlops: 8550.589980 \n",
      "==948== Profiling application: ./gpu_global_2 128\n",
      "==948== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   73.15%  20.224us         2  10.112us  9.7600us  10.464us  [CUDA memcpy HtoD]\n",
      "                   26.85%  7.4240us         1  7.4240us  7.4240us  7.4240us  [CUDA memcpy DtoH]\n",
      "      API calls:   99.36%  189.44ms         2  94.719ms     876ns  189.44ms  cudaEventCreate\n",
      "                    0.18%  343.13us         1  343.13us  343.13us  343.13us  cuDeviceTotalMem\n",
      "                    0.11%  218.14us      1000     218ns     170ns     885ns  cudaLaunchKernel\n",
      "                    0.09%  168.70us         3  56.234us  41.191us  79.507us  cudaMemcpy\n",
      "                    0.08%  159.61us       101  1.5800us     127ns  65.166us  cuDeviceGetAttribute\n",
      "                    0.08%  150.99us         3  50.329us  2.1140us  145.79us  cudaMalloc\n",
      "                    0.06%  119.00us         3  39.666us  2.4420us  107.58us  cudaFree\n",
      "                    0.02%  28.792us         1  28.792us  28.792us  28.792us  cuDeviceGetName\n",
      "                    0.01%  11.294us         2  5.6470us  3.9490us  7.3450us  cudaEventRecord\n",
      "                    0.00%  6.8400us         1  6.8400us  6.8400us  6.8400us  cudaEventSynchronize\n",
      "                    0.00%  5.8660us         1  5.8660us  5.8660us  5.8660us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.4560us         1  2.4560us  2.4560us  2.4560us  cudaEventElapsedTime\n",
      "                    0.00%  1.3450us         2     672ns     283ns  1.0620us  cuDeviceGet\n",
      "                    0.00%  1.2090us         3     403ns     169ns     685ns  cuDeviceGetCount\n",
      "                    0.00%     261ns         1     261ns     261ns     261ns  cuDeviceGetUuid\n",
      "==959== NVPROF is profiling process 959, command: ./gpu_global_2 512\n",
      "Matriz 512 x 512 GigaFlops: 843415.254114 \n",
      "==959== Profiling application: ./gpu_global_2 512\n",
      "==959== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   68.17%  175.90us         2  87.948us  87.740us  88.156us  [CUDA memcpy HtoD]\n",
      "                   31.83%  82.141us         1  82.141us  82.141us  82.141us  [CUDA memcpy DtoH]\n",
      "      API calls:   98.69%  199.29ms         2  99.644ms     911ns  199.29ms  cudaEventCreate\n",
      "                    0.66%  1.3279ms         3  442.64us  262.22us  764.63us  cudaMemcpy\n",
      "                    0.19%  380.59us         1  380.59us  380.59us  380.59us  cuDeviceTotalMem\n",
      "                    0.14%  283.46us         3  94.485us  4.1640us  178.76us  cudaMalloc\n",
      "                    0.12%  235.42us         3  78.471us  9.2380us  119.38us  cudaFree\n",
      "                    0.10%  193.48us      1000     193ns     167ns  12.113us  cudaLaunchKernel\n",
      "                    0.08%  159.40us       101  1.5780us     136ns  71.111us  cuDeviceGetAttribute\n",
      "                    0.01%  28.821us         1  28.821us  28.821us  28.821us  cuDeviceGetName\n",
      "                    0.00%  7.6830us         2  3.8410us  2.3480us  5.3350us  cudaEventRecord\n",
      "                    0.00%  6.8650us         1  6.8650us  6.8650us  6.8650us  cudaEventSynchronize\n",
      "                    0.00%  5.4520us         1  5.4520us  5.4520us  5.4520us  cuDeviceGetPCIBusId\n",
      "                    0.00%  3.0210us         1  3.0210us  3.0210us  3.0210us  cudaEventElapsedTime\n",
      "                    0.00%  1.7340us         3     578ns     203ns  1.1830us  cuDeviceGetCount\n",
      "                    0.00%  1.1700us         2     585ns     324ns     846ns  cuDeviceGet\n",
      "                    0.00%     249ns         1     249ns     249ns     249ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true gpu_global_2.cu -o gpu_global_2 -lcudadevrt\n",
    "# 16 32 64 128 512\n",
    "!nvprof ./gpu_global_2 16\n",
    "!nvprof ./gpu_global_2 32\n",
    "!nvprof ./gpu_global_2 64\n",
    "!nvprof ./gpu_global_2 128\n",
    "!nvprof ./gpu_global_2 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KznwW_Q_VbY0"
   },
   "source": [
    "## Tabla de resutlados \n",
    "(Note que para la construcci칩n de esta tabla se ha usado los datos de la ejecuci칩n que se recoge en el ap칠ndice). \n",
    "\n",
    "\n",
    "GPU sin usar memoria compartidad | \t| Tiempo de Ejecuci칩n (msec) | \t| \t- |  -   \n",
    "--- | --- | --- | ---  | --- | ---| \n",
    "Tama침o de la matriz\t | CPU- >GPU |\tGPU- >CPU | \tEjecuci칩n kernel | \tRatio comparado con 128x128\t | GFLOPs  | \n",
    "16x16\t|0.003 | 0.002| 5.443 |0.03 | 1.228|\n",
    "32x32\t|0.003 | 0.002| 13.275 | 0.078 | 4.51|  \n",
    "64x64\t| 0.006| 0.003 |181 | 1.06 | 1347.1 |  \n",
    "128x128\t| 0.018|0.007 |170 |  1| 11771 |  \n",
    "512x512\t| 0.176|0.082 | 172| 1.01| 933104|  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iorrqnEasc2M",
    "outputId": "4de6118a-83f4-48cb-bf1d-7116835eaed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032017647058823526\n",
      "0.07780588235294118\n",
      "1.0647058823529412\n",
      "1.0\n",
      "1.011764705882353\n"
     ]
    }
   ],
   "source": [
    "# c치lculo de ratios\n",
    "\n",
    "rt = [5.443, 13.227, 181,170,172]\n",
    "for r in rt:\n",
    "  print(r/rt[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG5VQI1jtPdi"
   },
   "source": [
    "## Comparativas usando memoria compartida \n",
    "\n",
    "Compararemos la versi칩n optimizada, ya que es la m치s eficiente. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZs42SkWtPFz",
    "outputId": "b85ceb1f-4a2f-457d-e27c-51b438af3df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing optimizaciones2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile optimizaciones2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define MAX 8\n",
    "\n",
    "__global__ void matrixMultGPU(int *a, int *b, int *c, int n){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int thx = threadIdx.x;\n",
    "    int thy = threadIdx.y;\n",
    "    int col = thx + blockDim.x * blockIdx.x;\n",
    "    int fil = thy + blockDim.y * blockIdx.y;\n",
    "\n",
    "    __shared__ float Aij[MAX][MAX];\n",
    "    __shared__ float Bij[MAX][MAX];\n",
    "\n",
    "    for (int lim = 0; lim < (n + MAX - 1)/MAX; lim++){\n",
    "        if ((thy + (lim*MAX)) < n  && col < n){\n",
    "            Aij[thy][thx] = a[(col*n) + (thy + (lim*MAX))];\n",
    "        }\n",
    "        else {\n",
    "            Aij[thy][thx] = 0.0;\n",
    "        }\n",
    "        if ((thx + (lim*MAX)) < n  && fil < n){\n",
    "            Bij[thy][thx] = b[((thx + (lim*MAX))*n) + fil];\n",
    "        }\n",
    "        else{\n",
    "            Bij[thy][thx] = 0.0;\n",
    "        }\n",
    "        __syncthreads();\n",
    "    #pragma unroll\n",
    "        for (k = 0; k < MAX; k++){\n",
    "            sum += Aij[k][thx] * Bij[thy][k];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (col < n && fil < n){\n",
    "        c[col * n + fil] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    int N = strtol(argv[1], NULL, 10);\n",
    "\n",
    "    printf(\"Matriz %d x %d \", N, N);\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int *dev_a, *dev_b, *dev_c;\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid((N + MAX - 1)/MAX, (N + MAX - 1)/MAX);\n",
    "    dim3 dimBlock(MAX, MAX);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c, N);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "    //for (int y = 0; y < N; y++){\n",
    "    //    for (int x = 0; x < N; x++){\n",
    "    //        printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "    //    }\n",
    "    //    printf(\"\\n\");\n",
    "    //}\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\\n\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rZ3j8dtumUZ",
    "outputId": "e13f2f69-994d-4cac-82bf-dcd23211f63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==1003== NVPROF is profiling process 1003, command: ./optimizaciones2 16\n",
      "Matriz 16 x 16 GigaFlops: 1.258926\n",
      "==1003== Profiling application: ./optimizaciones2 16\n",
      "==1003== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.89%  5.2104ms      1000  5.2100us  5.1510us  5.8560us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.07%  3.4240us         2  1.7120us  1.4720us  1.9520us  [CUDA memcpy HtoD]\n",
      "                    0.04%  2.1760us         1  2.1760us  2.1760us  2.1760us  [CUDA memcpy DtoH]\n",
      "      API calls:   96.38%  188.83ms         2  94.417ms     857ns  188.83ms  cudaEventCreate\n",
      "                    2.13%  4.1767ms      1000  4.1760us  3.2930us  23.068us  cudaLaunchKernel\n",
      "                    1.03%  2.0234ms         1  2.0234ms  2.0234ms  2.0234ms  cudaEventSynchronize\n",
      "                    0.18%  351.81us         1  351.81us  351.81us  351.81us  cuDeviceTotalMem\n",
      "                    0.08%  158.32us         3  52.774us  1.9150us  153.56us  cudaMalloc\n",
      "                    0.08%  147.93us       101  1.4640us     127ns  63.465us  cuDeviceGetAttribute\n",
      "                    0.06%  120.09us         3  40.031us  2.2880us  109.41us  cudaFree\n",
      "                    0.03%  57.091us         3  19.030us  8.8110us  29.102us  cudaMemcpy\n",
      "                    0.01%  28.342us         1  28.342us  28.342us  28.342us  cuDeviceGetName\n",
      "                    0.00%  9.7230us         2  4.8610us  4.5430us  5.1800us  cudaEventRecord\n",
      "                    0.00%  6.3600us         1  6.3600us  6.3600us  6.3600us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9160us         1  1.9160us  1.9160us  1.9160us  cudaEventElapsedTime\n",
      "                    0.00%  1.7090us         3     569ns     218ns  1.1340us  cuDeviceGetCount\n",
      "                    0.00%  1.2730us         2     636ns     294ns     979ns  cuDeviceGet\n",
      "                    0.00%     272ns         1     272ns     272ns     272ns  cuDeviceGetUuid\n",
      "==1014== NVPROF is profiling process 1014, command: ./optimizaciones2 32\n",
      "Matriz 32 x 32 GigaFlops: 8.362972\n",
      "==1014== Profiling application: ./optimizaciones2 32\n",
      "==1014== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.91%  6.5491ms      1000  6.5490us  6.4950us  12.000us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.06%  3.8400us         2  1.9200us  1.7280us  2.1120us  [CUDA memcpy HtoD]\n",
      "                    0.04%  2.3360us         1  2.3360us  2.3360us  2.3360us  [CUDA memcpy DtoH]\n",
      "      API calls:   95.79%  193.51ms         2  96.754ms     862ns  193.51ms  cudaEventCreate\n",
      "                    2.12%  4.2780ms      1000  4.2780us  3.1510us  25.969us  cudaLaunchKernel\n",
      "                    1.62%  3.2804ms         1  3.2804ms  3.2804ms  3.2804ms  cudaEventSynchronize\n",
      "                    0.18%  356.15us         1  356.15us  356.15us  356.15us  cuDeviceTotalMem\n",
      "                    0.08%  156.08us         3  52.025us  2.5520us  150.41us  cudaMalloc\n",
      "                    0.08%  154.91us         3  51.635us  4.0630us  139.58us  cudaFree\n",
      "                    0.08%  153.97us       101  1.5240us     129ns  66.941us  cuDeviceGetAttribute\n",
      "                    0.03%  68.390us         3  22.796us  9.5890us  40.149us  cudaMemcpy\n",
      "                    0.01%  28.630us         1  28.630us  28.630us  28.630us  cuDeviceGetName\n",
      "                    0.00%  9.5330us         2  4.7660us  4.6610us  4.8720us  cudaEventRecord\n",
      "                    0.00%  6.2400us         1  6.2400us  6.2400us  6.2400us  cuDeviceGetPCIBusId\n",
      "                    0.00%  3.2970us         1  3.2970us  3.2970us  3.2970us  cudaEventElapsedTime\n",
      "                    0.00%  1.8010us         3     600ns     206ns  1.2110us  cuDeviceGetCount\n",
      "                    0.00%  1.2360us         2     618ns     315ns     921ns  cuDeviceGet\n",
      "                    0.00%     229ns         1     229ns     229ns     229ns  cuDeviceGetUuid\n",
      "==1025== NVPROF is profiling process 1025, command: ./optimizaciones2 64\n",
      "Matriz 64 x 64 GigaFlops: 45.537293\n",
      "==1025== Profiling application: ./optimizaciones2 64\n",
      "==1025== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.91%  10.259ms      1000  10.258us  10.176us  11.167us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.06%  6.5280us         2  3.2640us  3.0400us  3.4880us  [CUDA memcpy HtoD]\n",
      "                    0.03%  3.1680us         1  3.1680us  3.1680us  3.1680us  [CUDA memcpy DtoH]\n",
      "      API calls:   94.01%  192.07ms         2  96.036ms     968ns  192.07ms  cudaEventCreate\n",
      "                    3.51%  7.1675ms         1  7.1675ms  7.1675ms  7.1675ms  cudaEventSynchronize\n",
      "                    1.99%  4.0755ms      1000  4.0750us  3.1840us  24.114us  cudaLaunchKernel\n",
      "                    0.18%  375.78us         1  375.78us  375.78us  375.78us  cuDeviceTotalMem\n",
      "                    0.10%  194.24us       101  1.9230us     134ns  76.914us  cuDeviceGetAttribute\n",
      "                    0.08%  158.19us         3  52.731us  2.0950us  152.86us  cudaMalloc\n",
      "                    0.06%  127.13us         3  42.377us  2.7560us  115.28us  cudaFree\n",
      "                    0.04%  88.321us         3  29.440us  20.750us  41.774us  cudaMemcpy\n",
      "                    0.01%  29.582us         1  29.582us  29.582us  29.582us  cuDeviceGetName\n",
      "                    0.00%  8.3890us         2  4.1940us  4.0630us  4.3260us  cudaEventRecord\n",
      "                    0.00%  6.5040us         1  6.5040us  6.5040us  6.5040us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.3240us         1  2.3240us  2.3240us  2.3240us  cudaEventElapsedTime\n",
      "                    0.00%  1.7920us         3     597ns     227ns  1.2010us  cuDeviceGetCount\n",
      "                    0.00%  1.2950us         2     647ns     274ns  1.0210us  cuDeviceGet\n",
      "                    0.00%     321ns         1     321ns     321ns     321ns  cuDeviceGetUuid\n",
      "==1036== NVPROF is profiling process 1036, command: ./optimizaciones2 128\n",
      "Matriz 128 x 128 GigaFlops: 113.898789\n",
      "==1036== Profiling application: ./optimizaciones2 128\n",
      "==1036== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.93%  35.525ms      1000  35.525us  34.623us  36.191us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.05%  19.232us         2  9.6160us  9.5680us  9.6640us  [CUDA memcpy HtoD]\n",
      "                    0.02%  7.0080us         1  7.0080us  7.0080us  7.0080us  [CUDA memcpy DtoH]\n",
      "      API calls:   83.48%  189.90ms         2  94.948ms  1.2700us  189.90ms  cudaEventCreate\n",
      "                   13.99%  31.822ms         1  31.822ms  31.822ms  31.822ms  cudaEventSynchronize\n",
      "                    2.04%  4.6382ms      1000  4.6380us  3.7660us  25.986us  cudaLaunchKernel\n",
      "                    0.17%  394.70us         1  394.70us  394.70us  394.70us  cuDeviceTotalMem\n",
      "                    0.08%  186.29us         3  62.096us  2.4680us  180.01us  cudaMalloc\n",
      "                    0.08%  179.62us         3  59.872us  36.975us  98.601us  cudaMemcpy\n",
      "                    0.07%  156.08us         3  52.025us  3.1260us  140.14us  cudaFree\n",
      "                    0.07%  153.91us       101  1.5230us     136ns  64.786us  cuDeviceGetAttribute\n",
      "                    0.01%  28.737us         1  28.737us  28.737us  28.737us  cuDeviceGetName\n",
      "                    0.00%  10.638us         2  5.3190us  5.2580us  5.3800us  cudaEventRecord\n",
      "                    0.00%  6.0990us         1  6.0990us  6.0990us  6.0990us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.8190us         1  2.8190us  2.8190us  2.8190us  cudaEventElapsedTime\n",
      "                    0.00%  1.9910us         3     663ns     210ns  1.4210us  cuDeviceGetCount\n",
      "                    0.00%  1.2400us         2     620ns     310ns     930ns  cuDeviceGet\n",
      "                    0.00%     254ns         1     254ns     254ns     254ns  cuDeviceGetUuid\n",
      "==1047== NVPROF is profiling process 1047, command: ./optimizaciones2 512\n",
      "Matriz 512 x 512 GigaFlops: 329.444397\n",
      "==1047== Profiling application: ./optimizaciones2 512\n",
      "==1047== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.97%  813.99ms      1000  813.99us  653.01us  1.7294ms  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.02%  176.06us         2  88.029us  87.997us  88.061us  [CUDA memcpy HtoD]\n",
      "                    0.01%  81.917us         1  81.917us  81.917us  81.917us  [CUDA memcpy DtoH]\n",
      "      API calls:   80.19%  810.57ms         1  810.57ms  810.57ms  810.57ms  cudaEventSynchronize\n",
      "                   19.16%  193.71ms         2  96.853ms     993ns  193.70ms  cudaEventCreate\n",
      "                    0.40%  4.0216ms      1000  4.0210us  3.1510us  40.786us  cudaLaunchKernel\n",
      "                    0.14%  1.3713ms         3  457.12us  240.60us  811.44us  cudaMemcpy\n",
      "                    0.04%  399.46us         1  399.46us  399.46us  399.46us  cuDeviceTotalMem\n",
      "                    0.03%  271.86us         3  90.620us  21.408us  168.88us  cudaFree\n",
      "                    0.03%  257.73us         3  85.910us  3.4270us  167.01us  cudaMalloc\n",
      "                    0.02%  156.71us       101  1.5510us     136ns  66.351us  cuDeviceGetAttribute\n",
      "                    0.00%  42.395us         1  42.395us  42.395us  42.395us  cuDeviceGetName\n",
      "                    0.00%  8.8860us         2  4.4430us  3.8500us  5.0360us  cudaEventRecord\n",
      "                    0.00%  5.7580us         1  5.7580us  5.7580us  5.7580us  cuDeviceGetPCIBusId\n",
      "                    0.00%  5.1200us         1  5.1200us  5.1200us  5.1200us  cudaEventElapsedTime\n",
      "                    0.00%  1.9210us         3     640ns     201ns  1.3740us  cuDeviceGetCount\n",
      "                    0.00%  1.0960us         2     548ns     199ns     897ns  cuDeviceGet\n",
      "                    0.00%     257ns         1     257ns     257ns     257ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true optimizaciones2.cu -o optimizaciones2 -lcudadevrt\n",
    "# 16 32 64 128 512\n",
    "!nvprof ./optimizaciones2 16\n",
    "!nvprof ./optimizaciones2 32\n",
    "!nvprof ./optimizaciones2 64\n",
    "!nvprof ./optimizaciones2 128\n",
    "!nvprof ./optimizaciones2 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfL1sD4PxJyw",
    "outputId": "5d36f2e7-d4af-4457-9ecc-98ecf9adb0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1452938527358703\n",
      "0.18464309840126097\n",
      "0.2871819410042783\n",
      "1.0\n",
      "22.489304210763343\n"
     ]
    }
   ],
   "source": [
    "# c치lculo de ratios\n",
    "\n",
    "rt = [5.162, 6.56, 10.203, 35.528,799]\n",
    "for r in rt:\n",
    "  print(r/rt[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5y06LCUOwk60"
   },
   "source": [
    "GPU **optimizada** | \t| Tiempo de Ejecuci칩n (msec) | \t| \t- |  -   \n",
    "--- | --- | --- | ---  | --- | ---| \n",
    "Tama침o de la matriz\t | CPU- >GPU |\tGPU- >CPU | \tEjecuci칩n kernel | \tRatio comparado con 128x128\t | GFLOPs  | \n",
    "16x16\t| 0.0036| 0.0021 | 5.162| 0.145| 1.266|\n",
    "32x32\t| 0.0037| 0.002 |6.56  | 0.184|8.365 | \n",
    "64x64\t| 0.006| 0.003| 10.203 |0.287|45.67 |\n",
    "128x128\t| 0.18 | 0.0069| 35.528 |1| 113.9|\n",
    "512x512\t| 0.179 | 0.08| 799 |22.48| 355.46|\n",
    "\n",
    "\n",
    "Teniendo presente los resultados de las ejecuciones sin compartir memoria.  \n",
    "\n",
    "\n",
    "Puede observarse que los tiempos de copia de datos se mantienen constantes pero que el tiempo de ejecuci칩n del kernel baja notablemente, manifest치ndose en un menor ratio y un mayor n칰mero de GFLOP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjmnrdsa0Z5G"
   },
   "source": [
    "## Como ejercicio adicional, prueba a migrar los c칩digos a aritm칠tica en doble precisi칩n (cambiar \"float\" por \"double\" en el tipo de dato de las matrices). 쮼n qu칠 medida se ven afectadas las prestaciones?\n",
    "\n",
    "**Soluci칩n**\n",
    "\n",
    "C칩digo con doubles: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IT8j0OI40iwo",
    "outputId": "43ae49ae-a014-477f-fe2b-11e46189a046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing optimizaciones3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile optimizaciones3.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define MAX 8\n",
    "\n",
    "__global__ void matrixMultGPU(double *a, double *b, double *c, int n){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int thx = threadIdx.x;\n",
    "    int thy = threadIdx.y;\n",
    "    int col = thx + blockDim.x * blockIdx.x;\n",
    "    int fil = thy + blockDim.y * blockIdx.y;\n",
    "\n",
    "    __shared__ float Aij[MAX][MAX];\n",
    "    __shared__ float Bij[MAX][MAX];\n",
    "\n",
    "    for (int lim = 0; lim < (n + MAX - 1)/MAX; lim++){\n",
    "        if ((thy + (lim*MAX)) < n  && col < n){\n",
    "            Aij[thy][thx] = a[(col*n) + (thy + (lim*MAX))];\n",
    "        }\n",
    "        else {\n",
    "            Aij[thy][thx] = 0.0;\n",
    "        }\n",
    "        if ((thx + (lim*MAX)) < n  && fil < n){\n",
    "            Bij[thy][thx] = b[((thx + (lim*MAX))*n) + fil];\n",
    "        }\n",
    "        else{\n",
    "            Bij[thy][thx] = 0.0;\n",
    "        }\n",
    "        __syncthreads();\n",
    "    #pragma unroll\n",
    "        for (k = 0; k < MAX; k++){\n",
    "            sum += Aij[k][thx] * Bij[thy][k];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (col < n && fil < n){\n",
    "        c[col * n + fil] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    int N = strtol(argv[1], NULL, 10);\n",
    "\n",
    "    printf(\"Matriz %d x %d \", N, N);\n",
    "    double a[N][N], b[N][N], c[N][N];\n",
    "    double *dev_a, *dev_b, *dev_c;\n",
    "    int  i , j;\n",
    "    double cont;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0.0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid((N + MAX - 1)/MAX, (N + MAX - 1)/MAX);\n",
    "    dim3 dimBlock(MAX, MAX);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c, N);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\\n\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCBIgFWM1P6F",
    "outputId": "0fe4d316-4e01-44bc-f7fa-bb7933b317af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==1091== NVPROF is profiling process 1091, command: ./optimizaciones3 16\n",
      "Matriz 16 x 16 GigaFlops: 1.801244\n",
      "==1091== Profiling application: ./optimizaciones3 16\n",
      "==1091== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.85%  2.8477ms      1000  2.8470us  2.7830us  7.8400us  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.10%  2.8160us         2  1.4080us  1.1200us  1.6960us  [CUDA memcpy HtoD]\n",
      "                    0.05%  1.5680us         1  1.5680us  1.5680us  1.5680us  [CUDA memcpy DtoH]\n",
      "      API calls:   97.95%  250.03ms         2  125.02ms     973ns  250.03ms  cudaEventCreate\n",
      "                    1.68%  4.2807ms      1000  4.2800us  3.3870us  25.333us  cudaLaunchKernel\n",
      "                    0.14%  347.75us         1  347.75us  347.75us  347.75us  cuDeviceTotalMem\n",
      "                    0.08%  213.14us         3  71.046us  2.0950us  206.25us  cudaMalloc\n",
      "                    0.06%  155.65us       101  1.5410us     128ns  63.361us  cuDeviceGetAttribute\n",
      "                    0.05%  131.46us         3  43.820us  2.8520us  115.07us  cudaFree\n",
      "                    0.02%  52.273us         3  17.424us  7.3330us  25.501us  cudaMemcpy\n",
      "                    0.01%  27.342us         1  27.342us  27.342us  27.342us  cuDeviceGetName\n",
      "                    0.00%  9.3410us         2  4.6700us  4.4600us  4.8810us  cudaEventRecord\n",
      "                    0.00%  8.1370us         1  8.1370us  8.1370us  8.1370us  cuDeviceGetPCIBusId\n",
      "                    0.00%  7.0330us         1  7.0330us  7.0330us  7.0330us  cudaEventSynchronize\n",
      "                    0.00%  1.9450us         1  1.9450us  1.9450us  1.9450us  cudaEventElapsedTime\n",
      "                    0.00%  1.4840us         3     494ns     206ns     997ns  cuDeviceGetCount\n",
      "                    0.00%  1.1700us         2     585ns     205ns     965ns  cuDeviceGet\n",
      "                    0.00%     277ns         1     277ns     277ns     277ns  cuDeviceGetUuid\n",
      "==1102== NVPROF is profiling process 1102, command: ./optimizaciones3 32\n",
      "Matriz 32 x 32 GigaFlops: 7.808687\n",
      "==1102== Profiling application: ./optimizaciones3 32\n",
      "==1102== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.91%  7.1355ms      1000  7.1350us  7.0710us  8.0960us  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.05%  3.8720us         2  1.9360us  1.7600us  2.1120us  [CUDA memcpy HtoD]\n",
      "                    0.03%  2.3040us         1  2.3040us  2.3040us  2.3040us  [CUDA memcpy DtoH]\n",
      "      API calls:   95.59%  197.19ms         2  98.595ms     746ns  197.19ms  cudaEventCreate\n",
      "                    2.00%  4.1214ms      1000  4.1210us  3.1630us  25.439us  cudaLaunchKernel\n",
      "                    1.94%  4.0011ms         1  4.0011ms  4.0011ms  4.0011ms  cudaEventSynchronize\n",
      "                    0.18%  378.53us         1  378.53us  378.53us  378.53us  cuDeviceTotalMem\n",
      "                    0.08%  173.39us       101  1.7160us     140ns  70.479us  cuDeviceGetAttribute\n",
      "                    0.08%  162.31us         3  54.102us  2.5590us  156.56us  cudaMalloc\n",
      "                    0.06%  131.66us         3  43.886us  2.4710us  120.50us  cudaFree\n",
      "                    0.03%  67.642us         3  22.547us  9.3260us  37.237us  cudaMemcpy\n",
      "                    0.02%  32.276us         1  32.276us  32.276us  32.276us  cuDeviceGetName\n",
      "                    0.00%  8.9030us         2  4.4510us  4.2000us  4.7030us  cudaEventRecord\n",
      "                    0.00%  5.6810us         1  5.6810us  5.6810us  5.6810us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.0220us         1  2.0220us  2.0220us  2.0220us  cudaEventElapsedTime\n",
      "                    0.00%  1.6130us         2     806ns     264ns  1.3490us  cuDeviceGet\n",
      "                    0.00%  1.5950us         3     531ns     204ns  1.0780us  cuDeviceGetCount\n",
      "                    0.00%     334ns         1     334ns     334ns     334ns  cuDeviceGetUuid\n",
      "==1113== NVPROF is profiling process 1113, command: ./optimizaciones3 64\n",
      "Matriz 64 x 64 GigaFlops: 39.996291\n",
      "==1113== Profiling application: ./optimizaciones3 64\n",
      "==1113== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.92%  11.842ms      1000  11.842us  11.744us  17.567us  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.06%  6.7200us         2  3.3600us  3.2320us  3.4880us  [CUDA memcpy HtoD]\n",
      "                    0.03%  3.2320us         1  3.2320us  3.2320us  3.2320us  [CUDA memcpy DtoH]\n",
      "      API calls:   93.78%  210.46ms         2  105.23ms     953ns  210.46ms  cudaEventCreate\n",
      "                    3.87%  8.6774ms         1  8.6774ms  8.6774ms  8.6774ms  cudaEventSynchronize\n",
      "                    1.88%  4.2148ms      1000  4.2140us  3.2810us  24.139us  cudaLaunchKernel\n",
      "                    0.17%  380.84us         1  380.84us  380.84us  380.84us  cuDeviceTotalMem\n",
      "                    0.08%  187.74us       101  1.8580us     154ns  79.073us  cuDeviceGetAttribute\n",
      "                    0.08%  181.43us         3  60.476us  4.3680us  144.95us  cudaFree\n",
      "                    0.07%  158.90us         3  52.965us  2.4430us  153.14us  cudaMalloc\n",
      "                    0.04%  100.51us         3  33.504us  14.481us  62.044us  cudaMemcpy\n",
      "                    0.01%  30.492us         1  30.492us  30.492us  30.492us  cuDeviceGetName\n",
      "                    0.00%  8.6780us         2  4.3390us  4.1070us  4.5710us  cudaEventRecord\n",
      "                    0.00%  5.2590us         1  5.2590us  5.2590us  5.2590us  cuDeviceGetPCIBusId\n",
      "                    0.00%  3.3890us         1  3.3890us  3.3890us  3.3890us  cudaEventElapsedTime\n",
      "                    0.00%  1.5430us         3     514ns     138ns  1.0860us  cuDeviceGetCount\n",
      "                    0.00%  1.2450us         2     622ns     380ns     865ns  cuDeviceGet\n",
      "                    0.00%     340ns         1     340ns     340ns     340ns  cuDeviceGetUuid\n",
      "==1126== NVPROF is profiling process 1126, command: ./optimizaciones3 128\n",
      "Matriz 128 x 128 GigaFlops: 85.383300\n",
      "==1126== Profiling application: ./optimizaciones3 128\n",
      "==1126== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.94%  47.831ms      1000  47.831us  47.231us  48.607us  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.04%  19.742us         2  9.8710us  9.5990us  10.143us  [CUDA memcpy HtoD]\n",
      "                    0.01%  6.9430us         1  6.9430us  6.9430us  6.9430us  [CUDA memcpy DtoH]\n",
      "      API calls:   79.63%  195.07ms         2  97.533ms     915ns  195.07ms  cudaEventCreate\n",
      "                   18.24%  44.690ms         1  44.690ms  44.690ms  44.690ms  cudaEventSynchronize\n",
      "                    1.70%  4.1763ms      1000  4.1760us  3.2030us  24.777us  cudaLaunchKernel\n",
      "                    0.14%  345.12us         1  345.12us  345.12us  345.12us  cuDeviceTotalMem\n",
      "                    0.07%  175.17us         3  58.388us  39.572us  92.383us  cudaMemcpy\n",
      "                    0.07%  167.74us       101  1.6600us     134ns  72.118us  cuDeviceGetAttribute\n",
      "                    0.07%  160.69us         3  53.561us  2.2000us  155.57us  cudaMalloc\n",
      "                    0.06%  137.43us         3  45.811us  2.5070us  124.25us  cudaFree\n",
      "                    0.01%  28.512us         1  28.512us  28.512us  28.512us  cuDeviceGetName\n",
      "                    0.00%  9.2230us         2  4.6110us  4.5580us  4.6650us  cudaEventRecord\n",
      "                    0.00%  7.9990us         1  7.9990us  7.9990us  7.9990us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.5030us         1  2.5030us  2.5030us  2.5030us  cudaEventElapsedTime\n",
      "                    0.00%  1.7760us         3     592ns     260ns  1.2060us  cuDeviceGetCount\n",
      "                    0.00%  1.2670us         2     633ns     192ns  1.0750us  cuDeviceGet\n",
      "                    0.00%     309ns         1     309ns     309ns     309ns  cuDeviceGetUuid\n",
      "==1137== NVPROF is profiling process 1137, command: ./optimizaciones3 512\n",
      "Matriz 512 x 512 GigaFlops: 243.940397\n",
      "==1137== Profiling application: ./optimizaciones3 512\n",
      "==1137== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.98%  1.09960s      1000  1.0996ms  919.49us  2.4612ms  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.02%  176.16us         2  88.077us  87.709us  88.446us  [CUDA memcpy HtoD]\n",
      "                    0.01%  81.150us         1  81.150us  81.150us  81.150us  [CUDA memcpy DtoH]\n",
      "      API calls:   83.51%  1.09335s         1  1.09335s  1.09335s  1.09335s  cudaEventSynchronize\n",
      "                   15.78%  206.60ms         2  103.30ms     985ns  206.59ms  cudaEventCreate\n",
      "                    0.51%  6.6554ms      1000  6.6550us  3.4530us  503.94us  cudaLaunchKernel\n",
      "                    0.11%  1.4398ms         3  479.95us  253.48us  863.15us  cudaMemcpy\n",
      "                    0.03%  386.29us         1  386.29us  386.29us  386.29us  cuDeviceTotalMem\n",
      "                    0.02%  277.55us         3  92.517us  4.0390us  182.39us  cudaMalloc\n",
      "                    0.02%  267.98us         3  89.326us  21.022us  167.29us  cudaFree\n",
      "                    0.01%  151.91us       101  1.5040us     133ns  64.733us  cuDeviceGetAttribute\n",
      "                    0.00%  28.996us         1  28.996us  28.996us  28.996us  cuDeviceGetName\n",
      "                    0.00%  9.5190us         2  4.7590us  4.1480us  5.3710us  cudaEventRecord\n",
      "                    0.00%  5.8780us         1  5.8780us  5.8780us  5.8780us  cuDeviceGetPCIBusId\n",
      "                    0.00%  4.6220us         1  4.6220us  4.6220us  4.6220us  cudaEventElapsedTime\n",
      "                    0.00%  1.2320us         2     616ns     268ns     964ns  cuDeviceGet\n",
      "                    0.00%  1.1100us         3     370ns     165ns     678ns  cuDeviceGetCount\n",
      "                    0.00%     251ns         1     251ns     251ns     251ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true optimizaciones3.cu -o optimizaciones3 -lcudadevrt\n",
    "# 16 32 64 128 512\n",
    "!nvprof ./optimizaciones3 16\n",
    "!nvprof ./optimizaciones3 32\n",
    "!nvprof ./optimizaciones3 64\n",
    "!nvprof ./optimizaciones3 128\n",
    "!nvprof ./optimizaciones3 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKovw2qM4Y8-",
    "outputId": "7ea65abd-c5f8-4d9e-a239-57439f74e09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10791938451246028\n",
      "0.14864525840441545\n",
      "0.24598595082789765\n",
      "1.0\n",
      "22.495400568656965\n"
     ]
    }
   ],
   "source": [
    "# c치lculo de ratios\n",
    "\n",
    "rt = [5.162, 7.11, 11.766, 47.832, 1076]\n",
    "for r in rt:\n",
    "  print(r/rt[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXaIvX4I4grk"
   },
   "source": [
    "El compendio de resultado obtenidos es de: \n",
    "\n",
    "GPU sin usar memoria compartidad | \t| Tiempo de Ejecuci칩n (msec) | \t| \t- |  -   \n",
    "--- | --- | --- | ---  | --- | ---| \n",
    "Tama침o de la matriz\t | CPU- >GPU |\tGPU- >CPU | \tEjecuci칩n kernel | \tRatio comparado con 128x128\t | GFLOPs  | \n",
    "16x16\t| 0.0034| 0.0021 | 5.162| 0.107| 1.206|\n",
    "32x32\t| 0.0037| 0.0027 |7.11  |0.148 |7.807| \n",
    "64x64\t| 0.006| 0.003| 11.766 | 0.246 |39.94 |\n",
    "128x128\t| 0.18 | 0.0069| 47.832|1| 85.39|\n",
    "512x512\t| 0.179 | 0.081| 1076 | 22.49| 249.4|\n",
    "\n",
    "\n",
    "Puede apreciarse c칩mo los tiempos de CPU->GPU y viceversa no han aumentado significativamente, pero s칤 lo ha hecho el tiempo de ejecuci칩n; y por ende, tambi칠n a disminuido el n칰mero de GFLOPS. \n",
    "\n",
    "Sin embargo, algo llamativo es que el ratio se mantiene constante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4poCRKI5z3h"
   },
   "source": [
    "# Reducci칩n en GPU\n",
    "\n",
    "Comenzaremos mostrando el c칩digo proporcionado y explic치ndolo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3uMD5Q7DF6p",
    "outputId": "07178303-b2ad-42fb-9736-ac3e434e7935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction0.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction0.cu\n",
    "\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, int n)\n",
    "{\n",
    "  int stride;\n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
    "  if(threadIdx.x + blockDim.x < n)\n",
    "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  for(stride = 1 ; stride < blockDim.x; stride *= 2)\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if(threadIdx.x % (2*stride) == 0)\n",
    "          scratch[threadIdx.x] += scratch[threadIdx.x + stride];\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "  if(threadIdx.x == 0)\n",
    "    g_data[0] = scratch[0];\n",
    "return; \n",
    "}\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "            // initialize the input data on the host to be integer values\n",
    "            // between 0 and 1000\n",
    "            for( unsigned int i = 0; i < num_elements; ++i)\n",
    "            {\n",
    "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
    "                h_data[i] = i*1.0;\n",
    "}\n",
    "        // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "   //int threads = (num_elements/2) + num_elements%2;\n",
    "   int threads = num_elements;\n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5NFDFyoEXWP"
   },
   "source": [
    "La funciones que aparecen son las siguientes: \n",
    "1. `void reduction(float *g_data, int n)`\n",
    "2. `computeOnDevice(float* h_data, int num_elements)`\n",
    "3. `void computeGold( float* reference, float* idata, const unsigned int len)`\n",
    "4. `main`\n",
    "Que realizan las funciones: \n",
    "\n",
    "### 1. `void reduction(float *g_data, int n)`. \n",
    "\n",
    "- Utilizando la memoria compartida guarda los `n` primeros elementos en un vector. \n",
    "- Realiza la suma acumulada en la posici칩n $X$  de $2^i \\leq n$, es decir implementa el **esquema 2**, de esta manera se simula en una hebra el proceso iterarivo de sumar los elementos que disten distancia 2 de un vector y despu칠s reducir la longitud del vector a la mitad. \n",
    "\n",
    "### 2. `computeOnDevice(float* h_data, int num_elements)`\n",
    "Realiza las funciones pertinentes de CUDA, ya sea de copia en memoria y llamada a la funci칩n para poder ejectuar `reduction` en la gr치fica y obtener los resultados. \n",
    "\n",
    "### 3. `void computeGold( float* reference, float* idata, const unsigned int len)`\n",
    "\n",
    "Realiza la misma reducci칩n en local. \n",
    "\n",
    "### 4. `main` \n",
    "\n",
    "Inicializa el vector de manera aleatoria, llama a las funciones `computeOnDevice` y `computeGold` y comprueba que ambos resultados son iguales. \n",
    "\n",
    "Un ejemplo de ejuci칩n del programa es el siguiente: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRI3ni8SI8lJ",
    "outputId": "e4118fcd-c988-45ca-c839-b95786b1572b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    " !/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction0.cu -o labsolReduction0 -lcudadevrt\n",
    " !./labsolReduction0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfazFpHbKnXE"
   },
   "source": [
    "## Apartado 2: Realiza un an치lisis del efecto en el rendimiento por los accesos a memoria y la divergencia de Threads.\n",
    "\n",
    "Para ello utilizaremos el profile del programa `./labsolReduction0` donde se produce la divergencia. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2qKqf5sMBdG",
    "outputId": "0a66ef9c-7ad7-4817-d685-eab06d062020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==1184== NVPROF is profiling process 1184, command: ./labsolReduction0\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n",
      "==1184== Profiling application: ./labsolReduction0\n",
      "==1184== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   61.25%  4.7040us         1  4.7040us  4.7040us  4.7040us  reduction(float*, int)\n",
      "                   20.00%  1.5360us         1  1.5360us  1.5360us  1.5360us  [CUDA memcpy DtoH]\n",
      "                   18.75%  1.4400us         1  1.4400us  1.4400us  1.4400us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.61%  189.24ms         1  189.24ms  189.24ms  189.24ms  cudaMalloc\n",
      "                    0.19%  353.38us         1  353.38us  353.38us  353.38us  cuDeviceTotalMem\n",
      "                    0.09%  171.53us       101  1.6980us     131ns  78.711us  cuDeviceGetAttribute\n",
      "                    0.05%  99.963us         1  99.963us  99.963us  99.963us  cudaFree\n",
      "                    0.02%  42.052us         2  21.026us  19.496us  22.556us  cudaMemcpy\n",
      "                    0.02%  30.904us         1  30.904us  30.904us  30.904us  cudaLaunchKernel\n",
      "                    0.01%  26.398us         1  26.398us  26.398us  26.398us  cuDeviceGetName\n",
      "                    0.00%  6.2270us         1  6.2270us  6.2270us  6.2270us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9230us         3     641ns     195ns  1.1970us  cuDeviceGetCount\n",
      "                    0.00%  1.2520us         2     626ns     299ns     953ns  cuDeviceGet\n",
      "                    0.00%     275ns         1     275ns     275ns     275ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!nvprof ./labsolReduction0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ts1_wInKTKR3"
   },
   "source": [
    "Podemos comprobar que la funci칩n que m치s actividad de GPU consume es la funci칩n `reduction` es un $71.76\\%$ del tiempo total, aqu칤 se aprecia que es la que contiene la condici칩n de `if`, es decir la divergencia. \n",
    "\n",
    "y en lo que refiere llamadas a la API las que consumen m치s son (citando la documentaci칩n oficial): \n",
    "\n",
    "- `cudaMalloc` cuya funci칩n es *Allocate memory on the device* con un tiempo de $99.54\\%$\n",
    "- `cuDeviceTotalMem`: *Returns the total amount of memory on the device* $0.26\\%$\n",
    "\n",
    "Por lo que se deduce que el cuello de botiella principal se encuenta en la gesti칩n de la memoria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LxOKqNjVjNT"
   },
   "source": [
    "## Generalizar el funcionamiento del m치s eficiente para cualquier tama침o de elementos, N >> Tama침o de bloque. \n",
    "\n",
    "\n",
    "Primero determinaremos qu칠 comportamiento es el m치s eficiente viendo los tiempos de ejecuci칩n del otro ejemplo proporcionado: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciM83Dc3b-Yw",
    "outputId": "dbc30d1f-a796-4ef3-f76d-c5866a0f57a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction1.cu\n",
    "\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, int n)\n",
    "{\n",
    "  int stride;\n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
    "  if(threadIdx.x + blockDim.x < n)\n",
    "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  for(stride = 1 ; stride < blockDim.x; stride *= 2)\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if(threadIdx.x % (2*stride) == 0)\n",
    "          scratch[threadIdx.x] += scratch[threadIdx.x + stride];\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "  if(threadIdx.x == 0)\n",
    "    g_data[0] = scratch[0];\n",
    "return; \n",
    "}\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "            // initialize the input data on the host to be integer values\n",
    "            // between 0 and 1000\n",
    "            for( unsigned int i = 0; i < num_elements; ++i)\n",
    "            {\n",
    "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
    "                h_data[i] = i*1.0;\n",
    "}\n",
    "        // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "   int threads = (num_elements/2) + num_elements%2; \n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0mskp_xVy_M",
    "outputId": "d141660e-1b01-4543-db3e-c09493c9b4da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction3.cu\n",
    "\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, int n)\n",
    "{\n",
    "  int stride;\n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
    "  if(threadIdx.x + blockDim.x < n)\n",
    "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  \n",
    "  ///////  Reduction scheme 3 //////\n",
    "  int stride2;\n",
    "  for (stride = 1, stride2=1; stride <= 9; stride++, stride2<<=1)\n",
    "  {\n",
    "      int t = threadIdx.x << stride;\n",
    "      if (t  + stride2 < n)\n",
    "        scratch[ t ] = scratch[ t ]  + scratch[ t + stride2];\n",
    "     __syncthreads();\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "  if(threadIdx.x == 0)\n",
    "    g_data[0] = scratch[0];\n",
    "return; \n",
    "}\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "            // initialize the input data on the host to be integer values\n",
    "            // between 0 and 1000\n",
    "            for( unsigned int i = 0; i < num_elements; ++i)\n",
    "            {\n",
    "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
    "                h_data[i] = i*1.0;\n",
    "}\n",
    "        // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "   //int threads = (num_elements/2) + num_elements%2;\n",
    "   int threads = num_elements;\n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXaV3Fy1WXav",
    "outputId": "3bd4f602-0e1d-4d5b-f536-039667a7dbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Reduction 0\n",
      "==1261== NVPROF is profiling process 1261, command: ./labsolReduction0\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n",
      "==1261== Profiling application: ./labsolReduction0\n",
      "==1261== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   69.56%  10.016us         1  10.016us  10.016us  10.016us  reduction(float*, int)\n",
      "                   16.44%  2.3680us         1  2.3680us  2.3680us  2.3680us  [CUDA memcpy DtoH]\n",
      "                   14.00%  2.0160us         1  2.0160us  2.0160us  2.0160us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.55%  195.73ms         1  195.73ms  195.73ms  195.73ms  cudaMalloc\n",
      "                    0.24%  465.09us         1  465.09us  465.09us  465.09us  cuDeviceTotalMem\n",
      "                    0.08%  153.12us       101  1.5160us     129ns  63.885us  cuDeviceGetAttribute\n",
      "                    0.06%  122.85us         1  122.85us  122.85us  122.85us  cudaFree\n",
      "                    0.03%  54.052us         2  27.026us  25.253us  28.799us  cudaMemcpy\n",
      "                    0.02%  41.183us         1  41.183us  41.183us  41.183us  cuDeviceGetName\n",
      "                    0.02%  31.197us         1  31.197us  31.197us  31.197us  cudaLaunchKernel\n",
      "                    0.00%  6.6840us         1  6.6840us  6.6840us  6.6840us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.5450us         3     515ns     190ns  1.0430us  cuDeviceGetCount\n",
      "                    0.00%  1.2200us         2     610ns     218ns  1.0020us  cuDeviceGet\n",
      "                    0.00%     248ns         1     248ns     248ns     248ns  cuDeviceGetUuid\n",
      "Reduction 1\n",
      "==1272== NVPROF is profiling process 1272, command: ./labsolReduction1\n",
      "Test FAILED\n",
      "device: 32640.000000  host: 130816.000000\n",
      "==1272== Profiling application: ./labsolReduction1\n",
      "==1272== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   67.18%  8.3840us         1  8.3840us  8.3840us  8.3840us  reduction(float*, int)\n",
      "                   16.92%  2.1110us         1  2.1110us  2.1110us  2.1110us  [CUDA memcpy DtoH]\n",
      "                   15.90%  1.9840us         1  1.9840us  1.9840us  1.9840us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.61%  191.06ms         1  191.06ms  191.06ms  191.06ms  cudaMalloc\n",
      "                    0.21%  408.42us         1  408.42us  408.42us  408.42us  cuDeviceTotalMem\n",
      "                    0.08%  152.32us       101  1.5080us     127ns  65.208us  cuDeviceGetAttribute\n",
      "                    0.05%  88.992us         1  88.992us  88.992us  88.992us  cudaFree\n",
      "                    0.02%  43.430us         2  21.715us  15.536us  27.894us  cudaMemcpy\n",
      "                    0.01%  27.686us         1  27.686us  27.686us  27.686us  cuDeviceGetName\n",
      "                    0.01%  24.220us         1  24.220us  24.220us  24.220us  cudaLaunchKernel\n",
      "                    0.00%  6.4800us         1  6.4800us  6.4800us  6.4800us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.6270us         2     813ns     291ns  1.3360us  cuDeviceGet\n",
      "                    0.00%  1.5540us         3     518ns     267ns     960ns  cuDeviceGetCount\n",
      "                    0.00%     284ns         1     284ns     284ns     284ns  cuDeviceGetUuid\n",
      "Reduction 3\n",
      "==1283== NVPROF is profiling process 1283, command: ./labsolReduction3\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n",
      "==1283== Profiling application: ./labsolReduction3\n",
      "==1283== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   62.64%  6.9760us         1  6.9760us  6.9760us  6.9760us  reduction(float*, int)\n",
      "                   19.25%  2.1440us         1  2.1440us  2.1440us  2.1440us  [CUDA memcpy DtoH]\n",
      "                   18.10%  2.0160us         1  2.0160us  2.0160us  2.0160us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.69%  244.04ms         1  244.04ms  244.04ms  244.04ms  cudaMalloc\n",
      "                    0.16%  382.41us         1  382.41us  382.41us  382.41us  cuDeviceTotalMem\n",
      "                    0.07%  162.63us       101  1.6100us     127ns  68.160us  cuDeviceGetAttribute\n",
      "                    0.04%  104.80us         1  104.80us  104.80us  104.80us  cudaFree\n",
      "                    0.02%  51.098us         2  25.549us  23.933us  27.165us  cudaMemcpy\n",
      "                    0.01%  31.381us         1  31.381us  31.381us  31.381us  cuDeviceGetName\n",
      "                    0.01%  26.868us         1  26.868us  26.868us  26.868us  cudaLaunchKernel\n",
      "                    0.00%  7.5010us         1  7.5010us  7.5010us  7.5010us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.2670us         3     422ns     191ns     751ns  cuDeviceGetCount\n",
      "                    0.00%  1.0680us         2     534ns     207ns     861ns  cuDeviceGet\n",
      "                    0.00%     273ns         1     273ns     273ns     273ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction1.cu -o labsolReduction1 -lcudadevrt\n",
    "!/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction3.cu -o labsolReduction3 -lcudadevrt\n",
    "print('Reduction 0')\n",
    "!nvprof ./labsolReduction0\n",
    "print('Reduction 1')\n",
    "!nvprof ./labsolReduction1\n",
    "print('Reduction 3')\n",
    "!nvprof ./labsolReduction3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioROslujcece"
   },
   "source": [
    "A la vista de los resultados el tercero es el m치s eficiente, ser치 el que modificaremos. \n",
    "\n",
    "Observemos que para este c칩digo el tama침o de bloque es igual al de elementos. \n",
    "\n",
    "La primera modificaci칩n que podemos hacer es determinar un nuevo tama침o de bloque dado por: \n",
    "\n",
    "`int threads = (num_elements/2) + num_elements%2;`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgSleHYzd7g6",
    "outputId": "804e705f-4161-4427-dad0-f2172aa735c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction4.cu\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, int n)\n",
    "{\n",
    "  int stride;\n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
    "  if(threadIdx.x + blockDim.x < n)\n",
    "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  \n",
    "  ///////  Reduction scheme 3 //////\n",
    "  int stride2;\n",
    "  for (stride = 1, stride2=1; stride <= 9; stride++, stride2<<=1)\n",
    "  {\n",
    "      int t = threadIdx.x << stride;\n",
    "      if (t  + stride2 < n)\n",
    "        scratch[ t ] = scratch[ t ]  + scratch[ t + stride2];\n",
    "     __syncthreads();\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "  if(threadIdx.x == 0)\n",
    "    g_data[0] = scratch[0];\n",
    "return; \n",
    "}\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "            // initialize the input data on the host to be integer values\n",
    "            // between 0 and 1000\n",
    "            for( unsigned int i = 0; i < num_elements; ++i)\n",
    "            {\n",
    "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
    "                h_data[i] = i*1.0;\n",
    "}\n",
    "        // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "   int threads = (num_elements/2) + num_elements%2;\n",
    "  \n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKFawQCGeDzl",
    "outputId": "5274d425-1b1e-41be-fbd2-e3b2e5700d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction4.cu -o labsolReduction4 -lcudadevrt\n",
    "! ./labsolReduction4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ClS2c-Xi61K"
   },
   "source": [
    "Podemos generalizar m치s todav칤a la formulaci칩n, para un n칰mero muy peque침o de hebras $threads$ lo que conllevar칤a  aumentar el n칰mero de elementos contiguos a sumar. \n",
    "\n",
    "Para ello cada hebra deber치 de realizar la suma de lo que antes eran varias hilos, con este fin los cambios esenciales a la funci칩n `reduction` han sido:\n",
    "\n",
    "1. Copia de los elementos del vector en memoria compartida \n",
    "\n",
    "```\n",
    "// Alamacenamos nuestra posici칩n y los contiguos \n",
    "  for(int i = init; i < init + stride_size && i < n; i++){\n",
    "    scratch[i] = g_data[i]; // \n",
    "  }\n",
    "  // Almacenamos los saltos \n",
    "  for (int stride = init+stride_size; stride < n; stride+= stride_size)\n",
    "  {\n",
    "    scratch[stride] = g_data[stride];\n",
    "  }\n",
    "  __syncthreads();\n",
    "```\n",
    "\n",
    "2. Como ahora $thread < n$, los elementos contiguos ser치n mayores de dos, as칤 que los sumaremos. \n",
    "\n",
    "\n",
    "```\n",
    "///////  Reduction scheme 3 //////\n",
    "  for(int i = init+1; i < init + stride_size; i++){\n",
    "    if(i < n)\n",
    "      scratch[init] = scratch[init] + scratch[i]; // sumamos elementos contiguos \n",
    "    __syncthreads(); // agrupamos\n",
    "  }\n",
    "```\n",
    "\n",
    "3. Finalmente igualmente que hac칤amos con stride, sumaremos las primeras casillas que contienen la sumatoria del paso dos:\n",
    "\n",
    "\n",
    "```\n",
    "int stride_size = ( n + blockDim.x -1) / blockDim.x; // ceil \n",
    "  int init = threadIdx.x * stride_size; \n",
    "if (init + j*stride_size < n)\n",
    "        scratch[ init ] = scratch[ init ] + scratch[init  + j*stride_size];\n",
    "```\n",
    "Como suponemos que que $thread$ es muy peque침o, esto tomar치 pocos valores y por eficiencia lo haremos directamente en la hebra $0$. \n",
    "\n",
    "Notemos adem치s que **hemos adaptado nuestro c칩digo para que admita un n칰mero de hebras que no sean potencias de dos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHaU2Y33gbB4",
    "outputId": "44cfe6c6-540b-4053-ffd8-82c1df10f2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction5.cu\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, const int n)\n",
    "{\n",
    "  // params\n",
    "  int stride_size = ( n + blockDim.x -1) / blockDim.x; // ceil \n",
    "  int init = threadIdx.x * stride_size; \n",
    "  \n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  // Alamcenamos nuestra posici칩n y los contiguos \n",
    "  for(int i = init; i < init + stride_size && i < n; i++){\n",
    "    scratch[i] = g_data[i]; // \n",
    "  }\n",
    "  // Almacenamos los saltos \n",
    "  for (int stride = init+stride_size; stride < n; stride+= stride_size)\n",
    "  {\n",
    "    scratch[stride] = g_data[stride];\n",
    "  }\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  \n",
    "  ///////  Reduction scheme 3 //////\n",
    "  for(int i = init+1; i < init + stride_size; i++){\n",
    "    if(i < n)\n",
    "      scratch[init] = scratch[init] + scratch[i]; // sumamos elementos contiguos \n",
    "    __syncthreads(); // agrupamos\n",
    "  }\n",
    "  // sumamos el resultado del bloque de la derecha\n",
    "  if(threadIdx.x == 0) {\n",
    "  for(int j = blockDim.x-1; j > 0 ; j-- ){\n",
    "    if (init + j*stride_size < n)\n",
    "        scratch[ init ] = scratch[ init ] + scratch[init  + j*stride_size];\n",
    "    __syncthreads();\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "    g_data[0] = scratch[0];\n",
    "  }\n",
    "return; \n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "    // initialize the input data on the host to be integer values\n",
    "    // between 0 and 1000\n",
    "    for( unsigned int i = 0; i < num_elements; ++i)\n",
    "      {\n",
    "                  h_data[i] = i*1.0;\n",
    "\n",
    "    }\n",
    "    // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    \n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "   int threads = 3; \n",
    "\n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1EuJeGcggRY",
    "outputId": "37a5008f-f900-4f95-e585-2047a3cc72f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==1363== NVPROF is profiling process 1363, command: ./labsolReduction5\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n",
      "==1363== Profiling application: ./labsolReduction5\n",
      "==1363== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   91.25%  42.367us         1  42.367us  42.367us  42.367us  reduction(float*, int)\n",
      "                    4.55%  2.1120us         1  2.1120us  2.1120us  2.1120us  [CUDA memcpy DtoH]\n",
      "                    4.20%  1.9520us         1  1.9520us  1.9520us  1.9520us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.71%  261.85ms         1  261.85ms  261.85ms  261.85ms  cudaMalloc\n",
      "                    0.13%  351.39us         1  351.39us  351.39us  351.39us  cuDeviceTotalMem\n",
      "                    0.06%  152.37us       101  1.5080us     128ns  65.985us  cuDeviceGetAttribute\n",
      "                    0.04%  103.47us         1  103.47us  103.47us  103.47us  cudaFree\n",
      "                    0.03%  81.230us         2  40.615us  26.747us  54.483us  cudaMemcpy\n",
      "                    0.01%  31.207us         1  31.207us  31.207us  31.207us  cuDeviceGetName\n",
      "                    0.01%  27.077us         1  27.077us  27.077us  27.077us  cudaLaunchKernel\n",
      "                    0.00%  6.2970us         1  6.2970us  6.2970us  6.2970us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.5200us         3     840ns     290ns  1.9120us  cuDeviceGetCount\n",
      "                    0.00%  1.6490us         2     824ns     291ns  1.3580us  cuDeviceGet\n",
      "                    0.00%     259ns         1     259ns     259ns     259ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction5.cu -o labsolReduction5 -lcudadevrt\n",
    "!nvprof ./labsolReduction5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ds1JTWQQqWQZ"
   },
   "source": [
    "Podemos observar que el resultado es correcto y que como era de esperar el tiempo se ha visto incrementado. \n",
    "\n",
    "Concretamente, para una ejecuci칩n de 3 hebras se ha tardado $442.367us$ mientras que antes para $256$ hebras ha tardado $6.9760us$. \n",
    "\n",
    "Notemos que el ratio de $tiempo \\times numero hebra$ es para el caso $threads = 3$\n",
    "$$442.365 \\times 3 = 1327.101$$ \n",
    "\n",
    "y para el caso $threads = 256$\n",
    "\n",
    "$$6.970 \\times 256 = 1784.32$$ \n",
    "\n",
    "Es decir que el factor de paralelizaci칩n no es proporcional al beneficio en tiempo, lo que pone de manifiesto la ley de Amdahl: \n",
    "\n",
    "*La mejora obtenida en el rendimiento de un sistema debido a la alteraci칩n de uno de sus componentes est치 limitada por la fracci칩n de tiempo que se utiliza dicho componente`*\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nY1bM8-CfmIs",
    "tXsgi5VVhDeN",
    "Njc2mXiGihEe",
    "3LCY7dKnlab2",
    "lgC8daU3lyYp",
    "qNFf9oksmy_6",
    "Pr0EXXy7nMAh",
    "x1oyFHn2hrxN",
    "Dj_6S9CYn5MF",
    "e1NhUlknrQB3",
    "eD3hkYzatxAz",
    "OFh-s45N-SYR",
    "wil7WJ0y9K_f",
    "wPKobWhu-ud4",
    "yDd3R_Xd-_xo",
    "1G3BFG_W_Oy8",
    "T-jJOTwrATiL",
    "LIgIP4OIF-tV",
    "eNQ6LIcCMIAl",
    "Hj8KxcUCOBrZ",
    "KznwW_Q_VbY0",
    "vG5VQI1jtPdi",
    "mjmnrdsa0Z5G",
    "Y5NFDFyoEXWP",
    "YfazFpHbKnXE"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
