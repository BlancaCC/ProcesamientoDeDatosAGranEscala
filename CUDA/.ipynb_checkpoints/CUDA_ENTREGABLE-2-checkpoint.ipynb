{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QyMLXsfVvob"
   },
   "source": [
    "# Recursos de la GPU\n",
    "\n",
    "Práctica realizada por: \n",
    "- Blanca Cano Camarero\n",
    "- Iker Villegas Labairu\n",
    "\n",
    "\n",
    "Nota: Los datos en las tablas pueden varias ligeramente por no tratarse de la misma ejecución. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faOZSDwBWxNz"
   },
   "source": [
    "Comprobamos las características del sistema proporcionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAu0BAAmVyej",
    "outputId": "b50a82ee-5280-4299-b3ba-cf40a2989e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:        x86_64\n",
      "CPU op-mode(s):      32-bit, 64-bit\n",
      "Byte Order:          Little Endian\n",
      "CPU(s):              2\n",
      "On-line CPU(s) list: 0,1\n",
      "Thread(s) per core:  2\n",
      "Core(s) per socket:  1\n",
      "Socket(s):           1\n",
      "NUMA node(s):        1\n",
      "Vendor ID:           GenuineIntel\n",
      "CPU family:          6\n",
      "Model:               85\n",
      "Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "Stepping:            3\n",
      "CPU MHz:             2000.154\n",
      "BogoMIPS:            4000.30\n",
      "Hypervisor vendor:   KVM\n",
      "Virtualization type: full\n",
      "L1d cache:           32K\n",
      "L1i cache:           32K\n",
      "L2 cache:            1024K\n",
      "L3 cache:            39424K\n",
      "NUMA node0 CPU(s):   0,1\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VyM8Gg-V5pl",
    "outputId": "6266b127-c5e6-4e40-ecbc-3a0e634ee2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            12G        576M         10G        1.3M        1.8G         11G\n",
      "Swap:            0B          0B          0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrFEkPjCW_aS"
   },
   "source": [
    "Verificamos la versión de CUDA que tenemos instalada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Z8DAfpWXHMV",
    "outputId": "19a91a5e-dfe4-4aa2-bb6f-9982d2d10080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Feb_14_21:12:58_PST_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.152\n",
      "Build cuda_11.2.r11.2/compiler.29618528_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KnY6rCSXYN_",
    "outputId": "241976ea-1025-4065-bc36-caa4b78ff177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 16 08:54:05 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P8    13W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H09O_xsWXcZz"
   },
   "source": [
    "Procedemos a comprobar las característica de las GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efn6F8D7XaYI",
    "outputId": "73628564-4fae-4010-f98a-b502a6e38546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-11.2/samples/1_Utilities/deviceQuery\n"
     ]
    }
   ],
   "source": [
    "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6lNabJQXj-n",
    "outputId": "43ec5e89-46c9-4407-a771-7d582169b62e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviceQuery.cpp  Makefile  NsightEclipse.xml  readme.txt\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJJVu3oMXlWw",
    "outputId": "107a85bc-388a-4649-c24f-047de1eee2fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-11.2/bin/nvcc -ccbin g++ -I../../common/inc  -m64    --threads 0 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86 -o deviceQuery.o -c deviceQuery.cpp\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "/usr/local/cuda-11.2/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86 -o deviceQuery deviceQuery.o \n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mkdir -p ../../bin/x86_64/linux/release\n",
      "cp deviceQuery ../../bin/x86_64/linux/release\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qagVg_BnXmpc",
    "outputId": "11ba56de-efcc-4236-809f-b174ff1fd7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./deviceQuery Starting...\n",
      "\n",
      " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
      "\n",
      "Detected 1 CUDA Capable device(s)\n",
      "\n",
      "Device 0: \"Tesla T4\"\n",
      "  CUDA Driver Version / Runtime Version          11.2 / 11.2\n",
      "  CUDA Capability Major/Minor version number:    7.5\n",
      "  Total amount of global memory:                 15110 MBytes (15843721216 bytes)\n",
      "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
      "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
      "  Memory Clock rate:                             5001 Mhz\n",
      "  Memory Bus Width:                              256-bit\n",
      "  L2 Cache Size:                                 4194304 bytes\n",
      "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
      "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
      "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
      "  Total amount of constant memory:               65536 bytes\n",
      "  Total amount of shared memory per block:       49152 bytes\n",
      "  Total shared memory per multiprocessor:        65536 bytes\n",
      "  Total number of registers available per block: 65536\n",
      "  Warp size:                                     32\n",
      "  Maximum number of threads per multiprocessor:  1024\n",
      "  Maximum number of threads per block:           1024\n",
      "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
      "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
      "  Maximum memory pitch:                          2147483647 bytes\n",
      "  Texture alignment:                             512 bytes\n",
      "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
      "  Run time limit on kernels:                     No\n",
      "  Integrated GPU sharing Host Memory:            No\n",
      "  Support host page-locked memory mapping:       Yes\n",
      "  Alignment requirement for Surfaces:            Yes\n",
      "  Device has ECC support:                        Enabled\n",
      "  Device supports Unified Addressing (UVA):      Yes\n",
      "  Device supports Managed Memory:                Yes\n",
      "  Device supports Compute Preemption:            Yes\n",
      "  Supports Cooperative Kernel Launch:            Yes\n",
      "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
      "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
      "  Compute Mode:\n",
      "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
      "\n",
      "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.2, CUDA Runtime Version = 11.2, NumDevs = 1\n",
      "Result = PASS\n"
     ]
    }
   ],
   "source": [
    "!./deviceQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HocL1ygajJ9"
   },
   "source": [
    "Ahora en base a la información obtenida con los comandos anteriores, procedemos a detallar los recursos siguientes:\n",
    "\n",
    "\n",
    "*   **Modelo de CPU, número de cores y frecuencia de funcionamiento:** 85 (Intel (R) Xeon (R) CPU @ 2.00GHz), 1 core, \n",
    "*   **Memoria de la CPU:** 12 G\n",
    "*   **Tarjeta gráfica:**\n",
    "*   **Versión de Cuda, indicando en que directorio está instalado en el sistema:** version 11.2, instalada en el directorio `/usr/local/cuda-11.2/samples/1_Utilities/deviceQuery`.\n",
    "*   **CUDA capability:** 7.5.\n",
    "*   **Frecuencia de la GPU:**\n",
    "*   **Número de registros disponibles:** 65536\n",
    "*   **Máximo número de threads por bloque:** 1024\n",
    "*   **Memoria compartida por bloque:** 49152 bytes.\n",
    "*   **Número máximo de threads por core (SP):**\n",
    "*   **Tamaño del Warp:** 32.\n",
    "*   **Memoria de la GPU:**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35XmPTneX90y"
   },
   "source": [
    "# Suma de dos vectores\n",
    "\n",
    "# 5.2 ¿ Qué hace el código de suma0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_UBbLJ0YDRb",
    "outputId": "3b7f012f-a445-40a9-ab77-e8a4e8ab8dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma0.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma0.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "void add(int n, float *x, float *y) {\n",
    "    \n",
    "    for (int i =0; i < n; i++ ){\n",
    "        y[i]=x[i]+y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "\n",
    "    float *x = new float[N];\n",
    "    float *y = new float[N]; \n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
    "   std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "   \n",
    "   delete [] x;\n",
    "   delete [] y;\n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH81__xhYut7"
   },
   "source": [
    "**Solución**. \n",
    "\n",
    "Se muestra en la casilla de código anterior el código suma0\n",
    "Como podemos ver el código se compone de dos funciones: \n",
    "\n",
    "- `add`: Dados dos arrays $x,y$ de la misma longitud $n$ suma coordenada a cada coordenada de $y$ la respectiva coordenada de $x$. \n",
    "- `main` función principal que va a ejecutarse y que comprende los siguientes pasos: \n",
    "\n",
    "1. **Inicialización de los vectores** con tamaño $N = 2^{20}$. $X$ es un vector de unos e $y$ es un vector de dos. \n",
    "\n",
    "2. Se **llama a la función suma** midiendo el tiempo que tarda. \n",
    "3. Se **muestra una serie de estadísticos** como: número de coordenadas sumadas, el número de errores que ha habido en cada coordenada, y el error máximo. \n",
    "\n",
    "A continuación mostramos su ejecución: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpHzgKj9bOoT",
    "outputId": "4d5fd334-2ed2-4e6f-85e6-a05d618dc665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo : 3.105000 ms\n",
      "suma de 1048576 Elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "# Compilación de CUDA (aunque aquí no utiliza funciones propias de cuda)\n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma0.cu -o suma0 -lcudadevrt\n",
    "!./suma0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnzSyjcibvOA"
   },
   "source": [
    "Como era de esperar no hay erroes de cálculo y han sido sumados todas las coordenadas, además destacamos que el tiempo obtendio de cálculo ha sido: \n",
    "$$3.517000 ms$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfhcB4AWcHUx"
   },
   "source": [
    "## ¿ Qué hace el código de suma1 ?\n",
    "\n",
    "A continuación mostramos el código suma1: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxofn2zzcx4O",
    "outputId": "47a47caa-daf0-4333-c328-a682338ef48e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma1.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__ void add(int n, float *x, float *y) {\n",
    "    \n",
    "    for (int i =0; i < n; i++ ){\n",
    "        y[i]=x[i]+y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add<<<1,1>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
    "   std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0JZzC6Ec2CS"
   },
   "source": [
    "**Solución** \n",
    "\n",
    "Notemos que ahora la estrutura y función del código es la misma salvo que se está programando para poder ejecutarse en gráficas de envida. \n",
    "\n",
    "Esto supone la adición con respecto a la implementación anterior: \n",
    "1. Macros de caracter global para la función`add`.\n",
    "2. Reservar el espacio de memoria para alojar en la gráfica, con la función ` cudaMallocManaged`. \n",
    "3. Recibir los resultados de la app. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGyphZWvewd3",
    "outputId": "1e2f6203-3e99-41ed-e8dc-dc62c17d73b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo : 0.056000 ms\n",
      "Tiempo con el synchronize  : 109.472000 ms\n",
      "suma de 1048576 Elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma1.cu -o suma1 -lcudadevrt\n",
    "!./suma1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihbYWkgLfAEP"
   },
   "source": [
    "Veamos que ahora el tiempo de cálculo se es de \n",
    "$$0.048000 ms$$ \n",
    "pero que añadiendo el tiempo de sincronización asciende a\n",
    "\n",
    "$$109.487000 ms$$\n",
    "\n",
    "que es superior a los $3.517000 ms$ en suma0, luego podemos observar la existencia de un cuello de botella en la sincronización. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sh-k8yvEgccf",
    "outputId": "c93ae77d-ff35-4dc7-8163-74b8ec2b0a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo del cálculo : 0.032000 ms\n",
      "Tiempo con el synchronize  : 109.409000 ms\n",
      "suma de 1048576 Elementos\n",
      "Número de Errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de ejcución sin especificar la arquitectura\n",
    "\n",
    "!/usr/local/cuda/bin/nvcc -rdc=true suma1.cu -o suma1sinarch -lcudadevrt\n",
    "!./suma1sinarch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nY1bM8-CfmIs"
   },
   "source": [
    "## P1: ¿Qué característica del modelo de computación esta siendo necesaria para que el ejemplo funcione correctamente?\n",
    "\n",
    "\n",
    "La diferencia que se intentaba mostrar era la necesidad de compilar con un `flag` determinado para especificar la arquitectura. En actualizaciones actuales esto ya no es necesario y por eso no apreciamos errores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXsgi5VVhDeN"
   },
   "source": [
    "## P2 ¿La suma ha tardado más o menos que en la CPU? Justifique como está funcionando.\n",
    "\n",
    "Ya adelantábamos eta respuesta con anterioridad: \n",
    "\n",
    "El tiempo de cálculo es de \n",
    "$$0.048000 ms$$ \n",
    "pero que añadiendo el tiempo de sincronización asciende a\n",
    "\n",
    "$$109.487000 ms$$\n",
    "\n",
    "que es superior a los $3.517000 ms$ en suma0, luego podemos observar la existencia de un cuello de botella en la sincronización. \n",
    "\n",
    "Esto pone de manifiesto la necesidad de utilizar la gráfica cuando el número de operaciones sea lo suficientemente grande como para que a pesar de añadir la sincronización merezca la pena el utilizar la GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWmtwc66hpQl"
   },
   "source": [
    "# 5.4 ¿ Qué hace el código de suma2 ?\n",
    "\n",
    "El código suma2 es el siguiente: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOq_BiIOhu1a",
    "outputId": "f56e6cc5-0661-4926-ded6-4fea7b90f65c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma2.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__ void add(int n, float *x, float *y) {\n",
    "    \n",
    "    for (int i =0; i < n; i++ ){\n",
    "        y[i]=x[i]+y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add<<<1,256>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo suma2 : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"Número de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWsIlVqOh52A",
    "outputId": "1ec4d66b-0700-4022-eec1-28420e5635ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo suma2 : 0.027000 ms\n",
      "Tiempo con el synchronize  : 116.435000 ms\n",
      "Suma de 1048576 elementos\n",
      "Número de errores: 1048451\n",
      "Max error: 7\n"
     ]
    }
   ],
   "source": [
    "# Compilación y ejecución \n",
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma2.cu -o suma2 -lcudadevrt\n",
    "!./suma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njc2mXiGihEe"
   },
   "source": [
    "# P3 ¿La suma ha funcionado? ¿ Ha tardado más o menos que en el caso anterior? Explique como está funcionando y si podrían generarse situaciones de funcionamiento incorrecto.\n",
    "\n",
    "**Solución**\n",
    "\n",
    "Notemos que a diferencia con suma1, ahora la diferencia principal del código es la siguiente: \n",
    "\n",
    "`add<<<1,256>>>(N, x, y);`\n",
    "\n",
    "Esto lo que hace es comenzar una rutina en paralelo, en **un bloque** y con **256** hebras, donde en cada hebra se repiten todos los cálculos. \n",
    "\n",
    "Todos hilos están trabajando con las mismas posiciones de memoria a la vez y esto explica que se den situaciones como que no estén actualizadas posiciones de memoria necesarias, es decir que *corrompan los datos guardados*, produciendo errores aleatorios y diferentes en cada ejecución. \n",
    "\n",
    "Respecto al tiempo de cómputo vemos que a ascendido un poco, pero se mantiene en mismo rango que cuando trabajábamos con una hebra sola,  esto se debe a la sobrecarga de gestionar distintos hilos. \n",
    "\n",
    "Lo ideal sería repartir la carga de trabajo entre los hilos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LCY7dKnlab2"
   },
   "source": [
    "# 5.5 ¿ Qué hace el código de suma3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqfGLpxclY4K",
    "outputId": "d121e2d4-07a5-4c77-d74d-72c17ec3c998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma3.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "\n",
    "__global__ void add(int n, float *x, float *y) {\n",
    "    \n",
    "    for (int i =0; i < n; i++ ){\n",
    "        y[i]=x[i]+y[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add<<<256,1>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo suma3 : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
    "   std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNrllw0YlhOW",
    "outputId": "71f4e6c8-0a43-4cb9-ceee-2bde368d59ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo suma3 : 0.027000 ms\n",
      "Tiempo con el synchronize  : 138.911000 ms\n",
      "suma de 1048576 Elementos\n",
      "Número de Errores: 1048568\n",
      "Max error: 255\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma3.cu -o suma3 -lcudadevrt\n",
    "!./suma3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgC8daU3lyYp"
   },
   "source": [
    "**Solución** \n",
    "\n",
    "Podemos apreciar que ahora se está realizando un paralelismo a nivel de bloque\n",
    "\n",
    "`add<<<256,1>>>(N, x, y);`\n",
    "Lo llamativo ahora es el error, que es exactamente mayor al número de hebras que se ejecuta. \n",
    "\n",
    "## P4 ¿La suma tarda ha tardado más o menos que en el caso anterior? Explique que está pasando.\n",
    "\n",
    "La suma ha tardado prácticamente igual que en el caso de suma2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNFf9oksmy_6"
   },
   "source": [
    "# 5.6 ¿ Qué hace el código de suma4 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmA40t0OnIPr",
    "outputId": "6efef5f8-3ea1-4d16-b5ab-b7b135980b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma4.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = threadIdx.x;\n",
    "  int stride = blockDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "//__global__ void add(int n, float *x, float *y) {\n",
    "//    for (int i =0; i < n; i++ ){\n",
    "//        y[i]=x[i]+y[i];\n",
    "//    }\n",
    "//}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "    add<<<1,256>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo suma 4 : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"Número de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b0567dsnq73",
    "outputId": "ced77b95-c0ff-4aec-9bee-5a04d56d96eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo suma 4 : 0.034000 ms\n",
      "Tiempo con el synchronize  : 2.887000 ms\n",
      "Suma de 1048576 elementos\n",
      "Número de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma4.cu -o suma4 -lcudadevrt\n",
    "!./suma4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pr0EXXy7nMAh"
   },
   "source": [
    "Si nos fijamos en el código \n",
    "\n",
    "```c++\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = threadIdx.x;\n",
    "  int stride = blockDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];\n",
    "}\n",
    "```\n",
    "\n",
    "ahora se está aprovechando correctamente el paralelismo sin repetir cálculo. \n",
    "\n",
    "# P5 Compare con el tiempo de ejecución de un solo Thread y con la ejecución en CPU.¿Que puede deducir de estos comportamientos?\n",
    "\n",
    "(Vamos a suponer que una ejecución es lo suficientemente significativa y no se va realizar el cálculo de un tiempo medio ni test de hipótesis) \n",
    "\n",
    "\n",
    "El tiempo obtenido con un bloque y 256 hebras es de:`\n",
    "\n",
    "```\n",
    "Tiempo del cálculo suma 4 : 0.027000 ms\n",
    "Tiempo con el synchronize  : 4.124000 ms\n",
    "````\n",
    "\n",
    "Que si recordamos el tiempo para CPU era de \n",
    "\n",
    "```\n",
    "3.517000 𝑚𝑠 \n",
    "```\n",
    "\n",
    "Vemos que el tiempo de cálculo es al rededor de 150% menor en el uso de las hebra, pero que \n",
    "sin embargo el tiempo de sincronización supera al una CPU y eso hace que para nuestro pequeña situación no merezca la pena. \n",
    "\n",
    "\n",
    "# P6 ¿Se puede seguir optimizando?  \n",
    "\n",
    "Se puede mejorar el tiempo de cálculo, combinando el uso de hebras y bloques, véase como ejemplo el código suma 5. Sin embargo el tiempo de sincronización no se podrá mejorar y no hemos conseguimos superar al de la CPU por mucha optimización que realicemos en los cálculos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT25Fb3wrF1M"
   },
   "source": [
    "P7 Realice el paralelismo correspondiente a la Suma en la GPU con paralelismo <<<256,1>> y estudie el comportamiento de los tiempos de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OonrGkw9rt9J",
    "outputId": "fc66b673-d521-461e-b1eb-c95038a2e260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma4_bloque.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma4_bloque.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index =  blockIdx.x * blockDim.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];    \n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "\n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "    \n",
    "    int NUM_BLOQUES =  256; // 2^8\n",
    "    add<<<NUM_BLOQUES,1>>>(N, x, y);\n",
    "    \n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo suma 4 bloque: %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "  int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0){\n",
    "          contError++; \n",
    "       }\n",
    "   }\n",
    "  \n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"Número de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4BZSxk2tAy1",
    "outputId": "22e58cf7-bcdb-49cd-9248-1089e3caee1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo suma 4 bloque: 0.034000 ms\n",
      "Tiempo con el synchronize  : 3.889000 ms\n",
      "Suma de 1048576 elementos\n",
      "Número de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma4_bloque.cu -o suma4_bloque -lcudadevrt\n",
    "!./suma4_bloque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1oyFHn2hrxN"
   },
   "source": [
    "# 5.7 ¿ Qué hace el código de suma5 ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brDKETddiK_K"
   },
   "source": [
    "**Solución**\n",
    "\n",
    "En esta nueva iteración del programa los cambios son los siguientes: \n",
    "- La función suma ahora tiene en cuenta el número de bloque y la hebra. \n",
    "- El número de bloque y hebra viene dada por: \n",
    "\n",
    "```\n",
    " int blockSize = 256;\n",
    " int numBlocks = (N + blockSize - 1) / blockSize;  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bh6e6LtqhzQO",
    "outputId": "5839f743-da27-448f-f706-9bb3af8d906a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma5.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    \n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "   add<<<numBlocks, blockSize>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo suma 5 : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"Número de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90JTs707iD3f",
    "outputId": "581488a8-ff8c-4847-eb10-470ef0e9a4e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo suma 5 : 0.030000 ms\n",
      "Tiempo con el synchronize  : 2.454000 ms\n",
      "Suma de 1048576 elementos\n",
      "Número de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma5.cu -o suma5 -lcudadevrt\n",
    "!./suma5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIHs0SU8jU0q"
   },
   "source": [
    "P8 Compare con el tiempo de ejecución con el resto de ejemplos anteriores.¿Que puede deducir de estos comportamientos? \n",
    "\n",
    "**Solución**\n",
    "\n",
    "Podemos obervar que este ha sido el programa más eficiente, ya que los tiempos optenidos han sido (nota, este resultado puede variar ligeramente si se vuelve a ejecutar: \n",
    "\n",
    "Programa | Tiempo cálculo (ms) | Tiempo sincronización  (ms)  | Descripción    \n",
    "--- | --- | ---  | --- \n",
    "suma 0 |   3.23 | = | Ejecución CPU  \n",
    "Suma 1 | 0.057 | 108 | Ejecutamos para una hebra y un bloque \n",
    "Suma 2 | 0.036 | 130 | Repetimos el mismo cálculo e 256 hebras\n",
    "Suma 3 | 0.031 | 141 |  Repetimos el mismo cálculo e 256 bloque  \n",
    "Suma 4| 0.03 | 2.93 | Repartimos tareas en 256 hebras\n",
    "Suma 5 | 0.03 | 2 |    Reparto de tareareas bloque y hebras \n",
    "\n",
    "\n",
    "A la vista de los resultados suma 5 ha sabido aprovechar los recursos y ser el mejor tiempo, superando incluso a la CPU. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dj_6S9CYn5MF"
   },
   "source": [
    "# P9 Pruebe el último ejercicio con más threads por bloque y explique los resultados obtenidos \n",
    "\n",
    "El código modificación del código consiste en aumentar el tamaño de la variable\n",
    "\n",
    "`int blockSize = 1 <<9;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCFY3A4Kn-Qh",
    "outputId": "7c6d66af-fc5b-4a8a-d2a1-3242b98dca58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma6.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma6.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "    y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    int blockSize = 1 <<9;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
    "    \n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "   add<<<numBlocks, blockSize>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo suma con 2^9 hebras : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"Número de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "us_ANUbboHHY",
    "outputId": "7eb00bdd-d900-42e4-f3ee-fdf6178642b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo suma con 2^9 hebras : 0.032000 ms\n",
      "Tiempo con el synchronize  : 2.228000 ms\n",
      "Suma de 1048576 elementos\n",
      "Número de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma6.cu -o suma6 -lcudadevrt\n",
    "!./suma6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pfBQgoupgtV"
   },
   "source": [
    "Los resultados obtenidos han sido los siguientes: \n",
    "\n",
    "\n",
    "Programa | Tiempo cálculo (ms) | Tiempo sincronización  (ms)  | Descripción    \n",
    "--- | --- | ---  | ---   \n",
    "Suma 4| 0.03 | 2.93 | Repartimos tareas en 256 hebras\n",
    "Suma 5 | 0.0300 | 2.13 |    Reparto de tareareas bloque y hebras \n",
    "suma 6 | 0.034 | 2.65 | Aumentamos el reparto a 2^9 hebras en vez de a 2^8\n",
    "\n",
    "\n",
    "Los tiempo de cálculo no han mejorado, esto se debe a que estamos superando el límite de hebras máximas que se pueden ejecutar en paralelo por bloque y por tanto añadiendo un coste de cómputo adicional. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1NhUlknrQB3"
   },
   "source": [
    "# P10 Modifique el último ejercicio para permitir vectores de tamaño N que no sean múltiplos del número de threads por bloque que se esté usando. Indique los cambios que han sido necesarios.\n",
    "\n",
    "**Solución**. \n",
    "\n",
    "Lo único que tendremos que hacer es añadir una condición de salida en el caso de que se vayan a superar las iteraciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGsELml-rpoV",
    "outputId": "b130ba66-eb8f-4342-c03e-d92431d9decd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma7.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile suma7.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int stride = blockDim.x * gridDim.x;\n",
    "  for (int i = index; i < n ; i += stride) {\n",
    "    if(i >= n) break;\n",
    "    y[i] = x[i] + y[i];\n",
    "  }\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    \n",
    "    int N = 1 <<20;  // N = 2^20 = 1024*1024= 1.048.576\n",
    "    N--; // Quitamos uno para que ya no sea múltiplo\n",
    "    struct timeval tv;\n",
    "\t  unsigned long long start;\n",
    "    float *x; // = new float[N];\n",
    "    float *y; // = new float[N]; \n",
    "\n",
    "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
    "    cudaMallocManaged(&x, N*sizeof(float));\n",
    "    cudaMallocManaged(&y, N*sizeof(float));\n",
    "    \n",
    "    for (int i =0; i < N; i++ ){\n",
    "        x[i]= 1.0f;\n",
    "        y[i]= 2.0f;\n",
    "    }\n",
    "\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N + blockSize - 1) / blockSize; // ceil \n",
    "    \n",
    "    gettimeofday(&tv, NULL); \n",
    "    start=tv.tv_sec*1000000+tv.tv_usec;\n",
    "   \n",
    "   add<<<numBlocks, blockSize>>>(N, x, y);\n",
    "  \n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo del cálculo suma con N no múltiplo : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "  \n",
    "   cudaDeviceSynchronize();\n",
    "    gettimeofday(&tv, NULL); \n",
    "\t  printf(\"Tiempo con el synchronize  : %lf ms\\n\", (tv.tv_sec*1000000+tv.tv_usec - start)/1000.0);\n",
    "\n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "   \n",
    "   for (int i=0; i <N; i++){\n",
    "       maxError=fmax(maxError,fabs(y[i]-3.0f));\n",
    "       if (y[i] != 3.0) contError++; \n",
    "   }\n",
    "   std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
    "   std::cout << \"Número de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "  \n",
    " \n",
    "  // Free memory\n",
    "   cudaFree (x);\n",
    "   cudaFree (y);\n",
    "   \n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HF25iVIruge",
    "outputId": "5d00e0fa-3b06-4087-abb9-02419e40c2ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Tiempo del cálculo suma con N no múltiplo : 0.043000 ms\n",
      "Tiempo con el synchronize  : 2.259000 ms\n",
      "Suma de 1048575 elementos\n",
      "Número de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true suma7.cu -o suma7 -lcudadevrt\n",
    "!./suma7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eD3hkYzatxAz"
   },
   "source": [
    "# 6. Suma de 2 matrices\n",
    "Refs:\n",
    "http://www.mat.unimi.it/users/sansotte/cuda/CUDA_by_Example.pdf. \n",
    "\n",
    "Se propone extender el código del ejemplo anterior para que realice la resta (o suma) de matrices cuadradas de dimensión N.\n",
    "\n",
    "- Configure adecuadamente el Grid de threads para aceptar matrices de cualquier tamaño.\n",
    "- En el kernel, utilice las variables blockIdx y threadIdx adecuadamente para acceder a una estructura bidimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsrUYEoEuVx9"
   },
   "source": [
    "**Solución** \n",
    "\n",
    "\n",
    "La idea se mantiene pero ahora trabajaremos en una dimensión más. \n",
    "Para ello será necesario añadir la dimensión en la función `MatAdd`. \n",
    "\n",
    "Además ahora cada hebra se encargará de una operación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2lgyjBgAAlI",
    "outputId": "1ac2f795-a562-4c2f-9a1f-f9bdd250e62c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrices2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrices2.cu\n",
    "#include <algorithm>\n",
    "#include <iostream>\n",
    "\n",
    "const int N = 10;\n",
    "\n",
    "__global__ void MatAdd(float A[][N], float B[][N], float C[][N])\n",
    "{\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    if (i < N && j < N)\n",
    "        C[i][j] = A[i][j] + B[i][j];\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    float* A; cudaMallocManaged(&A, N*N*sizeof(float));\n",
    "    float* B; cudaMallocManaged(&B, N*N*sizeof(float));\n",
    "    float* C; cudaMallocManaged(&C, N*N*sizeof(float));\n",
    "\n",
    "    float A_vals[N][N]; \n",
    "    float B_vals[N][N]; \n",
    "    for(int i= 0; i < N; i++){\n",
    "      for(int j=0; j<N; j++){\n",
    "        A_vals[i][j] = 1.0f;\n",
    "        B_vals[i][j] = 2.0f;\n",
    "      }\n",
    "    }\n",
    "    float (*C_vals)[N] = reinterpret_cast<float (*)[N]>(C);\n",
    "\n",
    "    std::copy(&A_vals[0][0], &A_vals[0][0] + N*N, A);\n",
    "    std::copy(&B_vals[0][0], &B_vals[0][0] + N*N, B);\n",
    "\n",
    "    const int numberOfThread = N;\n",
    "    const int numberOfBlocks = (N - 1 + numberOfThread) / numberOfThread; // ceil \n",
    "    dim3 threadsPerBlock(numberOfThread, numberOfThread);\n",
    "    dim3 numBlocks(numberOfBlocks, numberOfBlocks);\n",
    "\n",
    "    MatAdd<<<numBlocks, threadsPerBlock>>>( reinterpret_cast<float (*)[N]>(A),\n",
    "                                            reinterpret_cast<float (*)[N]>(B),\n",
    "                                            C_vals );\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    \n",
    "   float maxError = 0.0f;\n",
    "   int contError = 0;\n",
    "\n",
    "   for(int i= 0; i < N; i++){\n",
    "      for(int j=0; j<N; j++){\n",
    "        maxError=fmax(maxError,fabs(C_vals[i][j]-3.0f));\n",
    "        if (C_vals[i][j] != 3.0) contError++; \n",
    "      }\n",
    "    }\n",
    "\n",
    "   \n",
    "   std::cout << \"Suma de dos matrices con \" << N*N << \" elementos\" << std::endl;\n",
    "   std::cout << \"Número de errores: \" <<contError << std::endl;\n",
    "   std::cout << \"Max error: \" <<maxError << std::endl;\n",
    "\n",
    "\n",
    "   // Free memory\n",
    "   cudaFree (A);\n",
    "   cudaFree (B);\n",
    "    return 0;\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLJvXimlAPJz",
    "outputId": "bec951e6-2464-434e-8ea8-1bb9046cba20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Suma de dos matrices con 100 elementos\n",
      "Número de errores: 0\n",
      "Max error: 0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_37 -rdc=true matrices2.cu -o matrices2 -lcudadevrt\n",
    "!./matrices2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFh-s45N-SYR"
   },
   "source": [
    "# 7. Stencil1d: Estudiar el efecto de la memoria compartida\n",
    "Descripción:\n",
    "El código stencil 1D es útil para entender los beneficios y uso de memoria compartida en una GPU. Para hacerlo explicito conviene valorar los resultados utilizando el generador de perfiles ( `nvprof`) que muestra los cuellos de botella y su efecto en la aceleración final que se consigue.\n",
    "Pasos:\n",
    "1. Primero compile y ejecute el código sin usar memoria compartida. Hacer un perfil con `nvprof` y sacar el comportamiento temporal.\n",
    "2. Use el generador de perfiles para determinar cuál es el problema.\n",
    "3. Introduzca la modificación en el código para hacer uso de la memoria compartida.\n",
    "Valore la situación que sucede cuando no se usa la función __syncthreads (). Ejecute el código varias veces y observe cuando se obtienen errores semi-aleatorios en la salida.\n",
    "8. Añadiendo __syncthreads () evalue después de las diferentes modificaciones la aceleración obtenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wil7WJ0y9K_f"
   },
   "source": [
    "## 1. Primero compile y ejecute el código sin usar memoria compartida. Hacer un perfil con nvprof y sacar el comportamiento temporal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkGdJj-BcdUy",
    "outputId": "be05a572-8466-4bf6-bf4f-fe62721c7136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stencil1d_1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_1.cu\n",
    "\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) \n",
    "{\n",
    "    // Just one global index \n",
    "    int index = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    "\n",
    "    // Apply the stencil\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
    "        result += in[index + offset];\n",
    "\n",
    "    // Store the result\n",
    "    out[index-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  unsigned int i;\n",
    "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "  int *d_in, *d_out;\n",
    "\n",
    "  // Initialize host data\n",
    "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
    "\n",
    "  // Allocate space on the device\n",
    "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "  // Copy input data to device\n",
    "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "  // Verify every out value is 7\n",
    "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
    "    if (h_out[i] != 7)\n",
    "    {\n",
    "      printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
    "      break;\n",
    "    }\n",
    "\n",
    "  if (i == NUM_ELEMENTS)\n",
    "    printf(\"SUCCESS!\\n\");\n",
    "\n",
    "  // Free out memory\n",
    "  cudaFree(d_in);\n",
    "  cudaFree(d_out);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPKobWhu-ud4"
   },
   "source": [
    "## Comportamiento sin utilizar memoria compartidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfavSjnZ-I0X",
    "outputId": "0e3f7794-cdc9-403a-afb6-8589606ce945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==621== NVPROF is profiling process 621, command: ./stencil1d_1\n",
      "SUCCESS!\n",
      "==621== Profiling application: ./stencil1d_1\n",
      "==621== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   36.15%  5.3440us         1  5.3440us  5.3440us  5.3440us  [CUDA memcpy HtoD]\n",
      "                   33.33%  4.9280us         1  4.9280us  4.9280us  4.9280us  stencil_1d(int*, int*)\n",
      "                   30.52%  4.5120us         1  4.5120us  4.5120us  4.5120us  [CUDA memcpy DtoH]\n",
      "      API calls:   99.68%  250.77ms         2  125.39ms  5.5350us  250.77ms  cudaMalloc\n",
      "                    0.15%  381.62us         1  381.62us  381.62us  381.62us  cuDeviceTotalMem\n",
      "                    0.06%  160.22us       101  1.5860us     132ns  72.238us  cuDeviceGetAttribute\n",
      "                    0.05%  116.72us         2  58.361us  9.0930us  107.63us  cudaFree\n",
      "                    0.03%  75.952us         2  37.976us  27.817us  48.135us  cudaMemcpy\n",
      "                    0.01%  28.307us         1  28.307us  28.307us  28.307us  cuDeviceGetName\n",
      "                    0.01%  27.647us         1  27.647us  27.647us  27.647us  cudaLaunchKernel\n",
      "                    0.00%  6.2030us         1  6.2030us  6.2030us  6.2030us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.6360us         3     545ns     209ns  1.1460us  cuDeviceGetCount\n",
      "                    0.00%  1.1570us         2     578ns     216ns     941ns  cuDeviceGet\n",
      "                    0.00%     268ns         1     268ns     268ns     268ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_1.cu -o stencil1d_1 -lcudadevrt\n",
    "\n",
    "!nvprof ./stencil1d_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDd3R_Xd-_xo"
   },
   "source": [
    "## 2. Use el generador de perfiles para determinar cuál es el problema.\n",
    "\n",
    "**Solución**\n",
    "\n",
    "En vista a la gráfica anterior es fácil ver que el cuello de botella se encuentra en \n",
    "\n",
    "` API calls:   99.70%  279.86ms         2  139.93ms  5.0210us  279.86ms  cudaMalloc` ya que consume el `99.70%`. \n",
    "\n",
    "Que según la documentación oficial: *Allocates size bytes of linear memory on the device and returns in \\*devPtr a pointer to the allocated memory.*\n",
    "\n",
    "Es por tanto natural plantearse un sistema que reduzca este tiempo utilizando memoria compartida entre hilos. Veremos el efecto de esto en los siguientes apartados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G3BFG_W_Oy8"
   },
   "source": [
    "\n",
    "# 3. Introduzca la modificación en el código para hacer uso de la memoria compartida.\n",
    "Valore la situación que sucede cuando no se usa la función __syncthreads (). Ejecute el código varias veces y observe cuando se obtienen errores semi-aleatorios en la salida.\n",
    "\n",
    "\n",
    "**Solución sin `_synchthreads()`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWahwwWv_d6H",
    "outputId": "9fef6725-d084-4e5c-d33d-7df099dc35b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stencil1d_2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_2.cu\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) \n",
    "{\n",
    "    __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n",
    "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    "    int lindex = threadIdx.x + RADIUS;\n",
    "\n",
    "    // Read input elements into shared memory\n",
    "    temp[lindex] = in[gindex];\n",
    "    if (threadIdx.x < RADIUS) \n",
    "    {\n",
    "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
    "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
    "    }\n",
    "\n",
    "    // Make sure all threads get to this point before proceeding!\n",
    "    //__syncthreads();\n",
    "\n",
    "    // Apply the stencil\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
    "        result += temp[lindex + offset];\n",
    "\n",
    "    // Store the result\n",
    "    out[gindex-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  unsigned int i;\n",
    "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "  int *d_in, *d_out;\n",
    "\n",
    "  // Initialize host data\n",
    "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
    "\n",
    "  // Allocate space on the device\n",
    "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "  // Copy input data to device\n",
    "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "  // Verify every out value is 7\n",
    "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
    "    if (h_out[i] != 7)\n",
    "    {\n",
    "      printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
    "      break;\n",
    "    }\n",
    "\n",
    "  if (i == NUM_ELEMENTS)\n",
    "    printf(\"SUCCESS!\\n\");\n",
    "\n",
    "  // Free out memory\n",
    "  cudaFree(d_in);\n",
    "  cudaFree(d_out);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqgaI72e_zyb",
    "outputId": "c062ee58-491a-4aa9-fa9b-5730b122b548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Element h_out[0] == 2 != 7\n",
      "Element h_out[0] == 2 != 7\n",
      "Element h_out[0] == 2 != 7\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_2.cu -o stencil1d_2 -lcudadevrt\n",
    "\n",
    "repeticiones = 3\n",
    "for i in range(repeticiones):\n",
    "  !./stencil1d_2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-jJOTwrATiL"
   },
   "source": [
    "Como vemos están ocurriendo errores, esto se debe a que se está produciendo *data race* (condición de carrera) con los threads, ya que no se está haciendo uso de la función que sincroniza los hilos. \n",
    "\n",
    "## Versión que sincroniza la hebras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CR3JkBRLBRrV",
    "outputId": "46487ac6-3955-4b49-f3c1-4fa6b2d5f8ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing stencil1d_3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile stencil1d_3.cu\n",
    "#include <stdio.h>\n",
    "\n",
    "#define RADIUS        3\n",
    "#define BLOCK_SIZE    256\n",
    "#define NUM_ELEMENTS  (4096*2)\n",
    "\n",
    "// CUDA API error checking macro\n",
    "#define cudaCheck(error) \\\n",
    "  if (error != cudaSuccess) { \\\n",
    "    printf(\"Fatal error: %s at %s:%d\\n\", \\\n",
    "      cudaGetErrorString(error), \\\n",
    "      __FILE__, __LINE__); \\\n",
    "    exit(1); \\\n",
    "  }\n",
    "\n",
    "__global__ void stencil_1d(int *in, int *out) \n",
    "{\n",
    "    __shared__ int temp[BLOCK_SIZE + 2 * RADIUS];\n",
    "    int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
    "    int lindex = threadIdx.x + RADIUS;\n",
    "\n",
    "    // Read input elements into shared memory\n",
    "    temp[lindex] = in[gindex];\n",
    "    if (threadIdx.x < RADIUS) \n",
    "    {\n",
    "        temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
    "        temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
    "    }\n",
    "\n",
    "    // Make sure all threads get to this point before proceeding!\n",
    "    __syncthreads();\n",
    "\n",
    "    // Apply the stencil\n",
    "    int result = 0;\n",
    "    for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
    "        result += temp[lindex + offset];\n",
    "\n",
    "    // Store the result\n",
    "    out[gindex-RADIUS] = result;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  unsigned int i;\n",
    "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
    "  int *d_in, *d_out;\n",
    "\n",
    "  // Initialize host data\n",
    "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
    "    h_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
    "\n",
    "  // Allocate space on the device\n",
    "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
    "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
    "\n",
    "  // Copy input data to device\n",
    "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
    "\n",
    "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
    "\n",
    "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
    "\n",
    "  // Verify every out value is 7\n",
    "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
    "    if (h_out[i] != 7)\n",
    "    {\n",
    "      printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
    "      break;\n",
    "    }\n",
    "\n",
    "  if (i == NUM_ELEMENTS)\n",
    "    printf(\"SUCCESS! \");\n",
    "\n",
    "  // Free out memory\n",
    "  cudaFree(d_in);\n",
    "  cudaFree(d_out);\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1HXmQ3jBg4L",
    "outputId": "156ce70a-c963-4cb2-88de-6a86d196312b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! SUCCESS! "
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true stencil1d_3.cu -o stencil1d_3 -lcudadevrt\n",
    "\n",
    "repeticiones = 10\n",
    "for i in range(repeticiones):\n",
    "  !./stencil1d_3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_giij0LB0d2"
   },
   "source": [
    "Podemos observar que ya se ejetua con éxito el programa. \n",
    "\n",
    "Veamos ahora el profile: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XaUQygkfCJJ3",
    "outputId": "76279cf7-84c3-4d68-f06c-f81095daaa01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==737== NVPROF is profiling process 737, command: ./stencil1d_3\n",
      "SUCCESS! ==737== Profiling application: ./stencil1d_3\n",
      "==737== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   38.17%  5.8870us         1  5.8870us  5.8870us  5.8870us  [CUDA memcpy HtoD]\n",
      "                   32.78%  5.0560us         1  5.0560us  5.0560us  5.0560us  stencil_1d(int*, int*)\n",
      "                   29.04%  4.4790us         1  4.4790us  4.4790us  4.4790us  [CUDA memcpy DtoH]\n",
      "      API calls:   99.59%  200.10ms         2  100.05ms  5.4880us  200.09ms  cudaMalloc\n",
      "                    0.20%  403.24us         1  403.24us  403.24us  403.24us  cuDeviceTotalMem\n",
      "                    0.08%  164.77us       101  1.6310us     143ns  70.656us  cuDeviceGetAttribute\n",
      "                    0.05%  106.13us         2  53.066us  7.7810us  98.352us  cudaFree\n",
      "                    0.04%  77.835us         2  38.917us  28.998us  48.837us  cudaMemcpy\n",
      "                    0.02%  31.427us         1  31.427us  31.427us  31.427us  cuDeviceGetName\n",
      "                    0.01%  23.953us         1  23.953us  23.953us  23.953us  cudaLaunchKernel\n",
      "                    0.00%  6.5490us         1  6.5490us  6.5490us  6.5490us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9540us         3     651ns     255ns  1.3380us  cuDeviceGetCount\n",
      "                    0.00%  1.4540us         2     727ns     234ns  1.2200us  cuDeviceGet\n",
      "                    0.00%     268ns         1     268ns     268ns     268ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!nvprof ./stencil1d_3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26mDqJVJDFRh"
   },
   "source": [
    "Tengamos presentes que los resultados con el primer profile fueron de: \n",
    "\n",
    "```\n",
    "==738== Profiling result:\n",
    "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
    " GPU activities:   38.20%  5.6960us         1  5.6960us  5.6960us  5.6960us  [CUDA memcpy HtoD]\n",
    "                   32.40%  4.8320us         1  4.8320us  4.8320us  4.8320us  stencil_1d(int*, int*)\n",
    "                   29.40%  4.3840us         1  4.3840us  4.3840us  4.3840us  [CUDA memcpy DtoH]\n",
    "      API calls:   99.70%  279.86ms         2  139.93ms  5.0210us  279.86ms  cudaMalloc\n",
    "                    0.13%  372.11us         1  372.11us  372.11us  372.11us  cuDeviceTotalMem\n",
    "                    0.06%  162.05us       101  1.6040us     123ns  65.153us  cuDeviceGetAttribute\n",
    "                    0.05%  130.15us         2  65.072us  52.962us  77.183us  cudaMemcpy\n",
    "                    0.04%  118.75us         2  59.373us  11.104us  107.64us  cudaFree\n",
    "                    0.01%  30.679us         1  30.679us  30.679us  30.679us  cudaLaunchKernel\n",
    "                    0.01%  27.238us         1  27.238us  27.238us  27.238us  cuDeviceGetName\n",
    "                    0.00%  7.3760us         1  7.3760us  7.3760us  7.3760us  cuDeviceGetPCIBusId\n",
    "                    0.00%  1.2530us         3     417ns     187ns     723ns  cuDeviceGetCount\n",
    "                    0.00%  1.1450us         2     572ns     313ns     832ns  cuDeviceGet\n",
    "                    0.00%     231ns         1     231ns     231ns     231ns  cuDeviceGetUuid\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKrTIUveDn9S"
   },
   "source": [
    "A la vista de estos resultados hemos mejorado significativamente el tiempo de `cudaMalloc` y `cudaMemcpy`, que ha reducido su tiempo casi a la mitad. \n",
    "\n",
    "Lo cual se corresponde con el funcionamiento esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIgIP4OIF-tV"
   },
   "source": [
    "# Ejercicios opcionales de la práctica 2\n",
    "\n",
    "# 8. Producto de matrices en \n",
    "\n",
    "## Ejecución del código de CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwA35Fb6GukH",
    "outputId": "fa27e8b3-ff56-4db1-8d68-e9f8ca2c4427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing producto_cpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile producto_cpu.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define N 16\n",
    "#define M 1\n",
    "\n",
    "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]){\n",
    "    int n, m;\n",
    "    for (int i = 0; i < N; i++){\n",
    "        for (int j = 0; j < N; j++){\n",
    "            int sum = 0;\n",
    "            for (int k = 0; k < N; k++){\n",
    "                m = a[i][k];\n",
    "                n = b[k][j];\n",
    "                sum += m*n;\n",
    "            }\n",
    "            c[i][j] = sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultCPU(a, b, c);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    for (int y = 0; y < N; y++){\n",
    "        for (int x = 0; x < N; x++){\n",
    "            printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXJqGSJMHKub",
    "outputId": "adcd02d3-a3ec-4ead-f539-de5184f25217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['==781== NVPROF is profiling process 781, command: ./producto_cpu',\n",
       " '[0][0]=0 [0][1]=0 [0][2]=0 [0][3]=0 [0][4]=0 [0][5]=0 [0][6]=0 [0][7]=0 [0][8]=0 [0][9]=0 [0][10]=0 [0][11]=0 [0][12]=0 [0][13]=0 [0][14]=0 [0][15]=0 ',\n",
       " '[1][0]=120 [1][1]=120 [1][2]=120 [1][3]=120 [1][4]=120 [1][5]=120 [1][6]=120 [1][7]=120 [1][8]=120 [1][9]=120 [1][10]=120 [1][11]=120 [1][12]=120 [1][13]=120 [1][14]=120 [1][15]=120 ',\n",
       " '[2][0]=240 [2][1]=240 [2][2]=240 [2][3]=240 [2][4]=240 [2][5]=240 [2][6]=240 [2][7]=240 [2][8]=240 [2][9]=240 [2][10]=240 [2][11]=240 [2][12]=240 [2][13]=240 [2][14]=240 [2][15]=240 ',\n",
       " '[3][0]=360 [3][1]=360 [3][2]=360 [3][3]=360 [3][4]=360 [3][5]=360 [3][6]=360 [3][7]=360 [3][8]=360 [3][9]=360 [3][10]=360 [3][11]=360 [3][12]=360 [3][13]=360 [3][14]=360 [3][15]=360 ',\n",
       " '[4][0]=480 [4][1]=480 [4][2]=480 [4][3]=480 [4][4]=480 [4][5]=480 [4][6]=480 [4][7]=480 [4][8]=480 [4][9]=480 [4][10]=480 [4][11]=480 [4][12]=480 [4][13]=480 [4][14]=480 [4][15]=480 ',\n",
       " '[5][0]=600 [5][1]=600 [5][2]=600 [5][3]=600 [5][4]=600 [5][5]=600 [5][6]=600 [5][7]=600 [5][8]=600 [5][9]=600 [5][10]=600 [5][11]=600 [5][12]=600 [5][13]=600 [5][14]=600 [5][15]=600 ',\n",
       " '[6][0]=720 [6][1]=720 [6][2]=720 [6][3]=720 [6][4]=720 [6][5]=720 [6][6]=720 [6][7]=720 [6][8]=720 [6][9]=720 [6][10]=720 [6][11]=720 [6][12]=720 [6][13]=720 [6][14]=720 [6][15]=720 ',\n",
       " '[7][0]=840 [7][1]=840 [7][2]=840 [7][3]=840 [7][4]=840 [7][5]=840 [7][6]=840 [7][7]=840 [7][8]=840 [7][9]=840 [7][10]=840 [7][11]=840 [7][12]=840 [7][13]=840 [7][14]=840 [7][15]=840 ',\n",
       " '[8][0]=960 [8][1]=960 [8][2]=960 [8][3]=960 [8][4]=960 [8][5]=960 [8][6]=960 [8][7]=960 [8][8]=960 [8][9]=960 [8][10]=960 [8][11]=960 [8][12]=960 [8][13]=960 [8][14]=960 [8][15]=960 ',\n",
       " '[9][0]=1080 [9][1]=1080 [9][2]=1080 [9][3]=1080 [9][4]=1080 [9][5]=1080 [9][6]=1080 [9][7]=1080 [9][8]=1080 [9][9]=1080 [9][10]=1080 [9][11]=1080 [9][12]=1080 [9][13]=1080 [9][14]=1080 [9][15]=1080 ',\n",
       " '[10][0]=1200 [10][1]=1200 [10][2]=1200 [10][3]=1200 [10][4]=1200 [10][5]=1200 [10][6]=1200 [10][7]=1200 [10][8]=1200 [10][9]=1200 [10][10]=1200 [10][11]=1200 [10][12]=1200 [10][13]=1200 [10][14]=1200 [10][15]=1200 ',\n",
       " '[11][0]=1320 [11][1]=1320 [11][2]=1320 [11][3]=1320 [11][4]=1320 [11][5]=1320 [11][6]=1320 [11][7]=1320 [11][8]=1320 [11][9]=1320 [11][10]=1320 [11][11]=1320 [11][12]=1320 [11][13]=1320 [11][14]=1320 [11][15]=1320 ',\n",
       " '[12][0]=1440 [12][1]=1440 [12][2]=1440 [12][3]=1440 [12][4]=1440 [12][5]=1440 [12][6]=1440 [12][7]=1440 [12][8]=1440 [12][9]=1440 [12][10]=1440 [12][11]=1440 [12][12]=1440 [12][13]=1440 [12][14]=1440 [12][15]=1440 ',\n",
       " '[13][0]=1560 [13][1]=1560 [13][2]=1560 [13][3]=1560 [13][4]=1560 [13][5]=1560 [13][6]=1560 [13][7]=1560 [13][8]=1560 [13][9]=1560 [13][10]=1560 [13][11]=1560 [13][12]=1560 [13][13]=1560 [13][14]=1560 [13][15]=1560 ',\n",
       " '[14][0]=1680 [14][1]=1680 [14][2]=1680 [14][3]=1680 [14][4]=1680 [14][5]=1680 [14][6]=1680 [14][7]=1680 [14][8]=1680 [14][9]=1680 [14][10]=1680 [14][11]=1680 [14][12]=1680 [14][13]=1680 [14][14]=1680 [14][15]=1680 ',\n",
       " '[15][0]=1800 [15][1]=1800 [15][2]=1800 [15][3]=1800 [15][4]=1800 [15][5]=1800 [15][6]=1800 [15][7]=1800 [15][8]=1800 [15][9]=1800 [15][10]=1800 [15][11]=1800 [15][12]=1800 [15][13]=1800 [15][14]=1800 [15][15]=1800 ',\n",
       " 'GigaFlops: 0.668018==781== Profiling application: ./producto_cpu',\n",
       " '==781== Profiling result:',\n",
       " 'No kernels were profiled.',\n",
       " '            Type  Time(%)      Time     Calls       Avg       Min       Max  Name',\n",
       " '      API calls:   99.75%  241.65ms         2  120.83ms  1.3340us  241.65ms  cudaEventCreate',\n",
       " '                    0.15%  358.08us         1  358.08us  358.08us  358.08us  cuDeviceTotalMem',\n",
       " '                    0.07%  170.55us       101  1.6880us     130ns  71.752us  cuDeviceGetAttribute',\n",
       " '                    0.01%  36.254us         1  36.254us  36.254us  36.254us  cuDeviceGetName',\n",
       " '                    0.01%  14.734us         2  7.3670us  4.1010us  10.633us  cudaEventRecord',\n",
       " '                    0.00%  8.8030us         1  8.8030us  8.8030us  8.8030us  cudaEventSynchronize',\n",
       " '                    0.00%  6.0870us         1  6.0870us  6.0870us  6.0870us  cuDeviceGetPCIBusId',\n",
       " '                    0.00%  1.9970us         1  1.9970us  1.9970us  1.9970us  cudaEventElapsedTime',\n",
       " '                    0.00%  1.5940us         3     531ns     175ns  1.0930us  cuDeviceGetCount',\n",
       " '                    0.00%  1.2740us         2     637ns     295ns     979ns  cuDeviceGet',\n",
       " '                    0.00%     399ns         1     399ns     399ns     399ns  cuDeviceGetUuid']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true producto_cpu.cu -o producto_cpu -lcudadevrt\n",
    "!!nvprof ./producto_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNQ6LIcCMIAl"
   },
   "source": [
    "## GPU memoria global "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGz2fq8tMMbi",
    "outputId": "c79f0693-635d-461b-8fdc-9fcd1eb7a63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gpu_global.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile gpu_global.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#define N 16\n",
    "#define M 1\n",
    "\n",
    "__global__ void matrixMultGPU(int *a, int *b, int *c){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "    int fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
    "    if (col < N && fil < N){\n",
    "        for (k = 0; k < N; k++){\n",
    "            sum += a[fil*N+k] * b[k*N+col];\n",
    "        }\n",
    "        c[fil*N+col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int *dev_a, *dev_b, *dev_c;\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid(M, M);\n",
    "    dim3 dimBlock(N, N);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "    for (int y = 0; y < N; y++){\n",
    "        for (int x = 0; x < N; x++){\n",
    "            printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgkK-HCzMjQc",
    "outputId": "4133c227-2667-4720-9e7e-6c527301a3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==825== NVPROF is profiling process 825, command: ./gpu_global\n",
      "[0][0]=0 [0][1]=0 [0][2]=0 [0][3]=0 [0][4]=0 [0][5]=0 [0][6]=0 [0][7]=0 [0][8]=0 [0][9]=0 [0][10]=0 [0][11]=0 [0][12]=0 [0][13]=0 [0][14]=0 [0][15]=0 \n",
      "[1][0]=120 [1][1]=120 [1][2]=120 [1][3]=120 [1][4]=120 [1][5]=120 [1][6]=120 [1][7]=120 [1][8]=120 [1][9]=120 [1][10]=120 [1][11]=120 [1][12]=120 [1][13]=120 [1][14]=120 [1][15]=120 \n",
      "[2][0]=240 [2][1]=240 [2][2]=240 [2][3]=240 [2][4]=240 [2][5]=240 [2][6]=240 [2][7]=240 [2][8]=240 [2][9]=240 [2][10]=240 [2][11]=240 [2][12]=240 [2][13]=240 [2][14]=240 [2][15]=240 \n",
      "[3][0]=360 [3][1]=360 [3][2]=360 [3][3]=360 [3][4]=360 [3][5]=360 [3][6]=360 [3][7]=360 [3][8]=360 [3][9]=360 [3][10]=360 [3][11]=360 [3][12]=360 [3][13]=360 [3][14]=360 [3][15]=360 \n",
      "[4][0]=480 [4][1]=480 [4][2]=480 [4][3]=480 [4][4]=480 [4][5]=480 [4][6]=480 [4][7]=480 [4][8]=480 [4][9]=480 [4][10]=480 [4][11]=480 [4][12]=480 [4][13]=480 [4][14]=480 [4][15]=480 \n",
      "[5][0]=600 [5][1]=600 [5][2]=600 [5][3]=600 [5][4]=600 [5][5]=600 [5][6]=600 [5][7]=600 [5][8]=600 [5][9]=600 [5][10]=600 [5][11]=600 [5][12]=600 [5][13]=600 [5][14]=600 [5][15]=600 \n",
      "[6][0]=720 [6][1]=720 [6][2]=720 [6][3]=720 [6][4]=720 [6][5]=720 [6][6]=720 [6][7]=720 [6][8]=720 [6][9]=720 [6][10]=720 [6][11]=720 [6][12]=720 [6][13]=720 [6][14]=720 [6][15]=720 \n",
      "[7][0]=840 [7][1]=840 [7][2]=840 [7][3]=840 [7][4]=840 [7][5]=840 [7][6]=840 [7][7]=840 [7][8]=840 [7][9]=840 [7][10]=840 [7][11]=840 [7][12]=840 [7][13]=840 [7][14]=840 [7][15]=840 \n",
      "[8][0]=960 [8][1]=960 [8][2]=960 [8][3]=960 [8][4]=960 [8][5]=960 [8][6]=960 [8][7]=960 [8][8]=960 [8][9]=960 [8][10]=960 [8][11]=960 [8][12]=960 [8][13]=960 [8][14]=960 [8][15]=960 \n",
      "[9][0]=1080 [9][1]=1080 [9][2]=1080 [9][3]=1080 [9][4]=1080 [9][5]=1080 [9][6]=1080 [9][7]=1080 [9][8]=1080 [9][9]=1080 [9][10]=1080 [9][11]=1080 [9][12]=1080 [9][13]=1080 [9][14]=1080 [9][15]=1080 \n",
      "[10][0]=1200 [10][1]=1200 [10][2]=1200 [10][3]=1200 [10][4]=1200 [10][5]=1200 [10][6]=1200 [10][7]=1200 [10][8]=1200 [10][9]=1200 [10][10]=1200 [10][11]=1200 [10][12]=1200 [10][13]=1200 [10][14]=1200 [10][15]=1200 \n",
      "[11][0]=1320 [11][1]=1320 [11][2]=1320 [11][3]=1320 [11][4]=1320 [11][5]=1320 [11][6]=1320 [11][7]=1320 [11][8]=1320 [11][9]=1320 [11][10]=1320 [11][11]=1320 [11][12]=1320 [11][13]=1320 [11][14]=1320 [11][15]=1320 \n",
      "[12][0]=1440 [12][1]=1440 [12][2]=1440 [12][3]=1440 [12][4]=1440 [12][5]=1440 [12][6]=1440 [12][7]=1440 [12][8]=1440 [12][9]=1440 [12][10]=1440 [12][11]=1440 [12][12]=1440 [12][13]=1440 [12][14]=1440 [12][15]=1440 \n",
      "[13][0]=1560 [13][1]=1560 [13][2]=1560 [13][3]=1560 [13][4]=1560 [13][5]=1560 [13][6]=1560 [13][7]=1560 [13][8]=1560 [13][9]=1560 [13][10]=1560 [13][11]=1560 [13][12]=1560 [13][13]=1560 [13][14]=1560 [13][15]=1560 \n",
      "[14][0]=1680 [14][1]=1680 [14][2]=1680 [14][3]=1680 [14][4]=1680 [14][5]=1680 [14][6]=1680 [14][7]=1680 [14][8]=1680 [14][9]=1680 [14][10]=1680 [14][11]=1680 [14][12]=1680 [14][13]=1680 [14][14]=1680 [14][15]=1680 \n",
      "[15][0]=1800 [15][1]=1800 [15][2]=1800 [15][3]=1800 [15][4]=1800 [15][5]=1800 [15][6]=1800 [15][7]=1800 [15][8]=1800 [15][9]=1800 [15][10]=1800 [15][11]=1800 [15][12]=1800 [15][13]=1800 [15][14]=1800 [15][15]=1800 \n",
      "GigaFlops: 1.221502==825== Profiling application: ./gpu_global\n",
      "==825== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.90%  5.3954ms      1000  5.3950us  5.2800us  14.016us  matrixMultGPU(int*, int*, int*)\n",
      "                    0.06%  3.3920us         2  1.6960us  1.5040us  1.8880us  [CUDA memcpy HtoD]\n",
      "                    0.04%  2.1760us         1  2.1760us  2.1760us  2.1760us  [CUDA memcpy DtoH]\n",
      "      API calls:   97.23%  259.96ms         2  129.98ms     982ns  259.96ms  cudaEventCreate\n",
      "                    1.65%  4.4228ms      1000  4.4220us  3.2020us  26.529us  cudaLaunchKernel\n",
      "                    0.75%  2.0088ms         1  2.0088ms  2.0088ms  2.0088ms  cudaEventSynchronize\n",
      "                    0.15%  392.15us         1  392.15us  392.15us  392.15us  cuDeviceTotalMem\n",
      "                    0.07%  175.90us         3  58.631us  1.9950us  170.24us  cudaMalloc\n",
      "                    0.06%  157.44us       101  1.5580us     134ns  66.800us  cuDeviceGetAttribute\n",
      "                    0.06%  147.19us         3  49.063us  2.4900us  134.47us  cudaFree\n",
      "                    0.02%  56.798us         3  18.932us  8.3980us  28.383us  cudaMemcpy\n",
      "                    0.01%  30.590us         1  30.590us  30.590us  30.590us  cuDeviceGetName\n",
      "                    0.00%  8.2380us         2  4.1190us  3.8510us  4.3870us  cudaEventRecord\n",
      "                    0.00%  5.9590us         1  5.9590us  5.9590us  5.9590us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.3440us         1  2.3440us  2.3440us  2.3440us  cudaEventElapsedTime\n",
      "                    0.00%  1.3310us         2     665ns     242ns  1.0890us  cuDeviceGet\n",
      "                    0.00%  1.3040us         3     434ns     184ns     778ns  cuDeviceGetCount\n",
      "                    0.00%     298ns         1     298ns     298ns     298ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true gpu_global.cu -o gpu_global -lcudadevrt\n",
    "!nvprof ./gpu_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OHMjW_zNDlM"
   },
   "source": [
    "Obsérvese que con el uso de CPU con memoria global ahora el número de \n",
    "`Gflops` es de `GigaFlops: 1.248567` mientras que con CPU era de `GigaFlops: 0.460247` lo cual ya supone una mejora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj8KxcUCOBrZ"
   },
   "source": [
    "## Optimizaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6hSDhBvOEeH",
    "outputId": "b25acd2c-fbf5-49a4-83b7-f560c4007b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing optimizaciones.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile optimizaciones.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#define N 64\n",
    "#define MAX 8\n",
    "\n",
    "__global__ void matrixMultGPU(int *a, int *b, int *c, int n){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int thx = threadIdx.x;\n",
    "    int thy = threadIdx.y;\n",
    "    int col = thx + blockDim.x * blockIdx.x;\n",
    "    int fil = thy + blockDim.y * blockIdx.y;\n",
    "\n",
    "    __shared__ float Aij[MAX][MAX];\n",
    "    __shared__ float Bij[MAX][MAX];\n",
    "\n",
    "    for (int lim = 0; lim < (n + MAX - 1)/MAX; lim++){\n",
    "        if ((thy + (lim*MAX)) < n  && col < n){\n",
    "            Aij[thy][thx] = a[(col*n) + (thy + (lim*MAX))];\n",
    "        }\n",
    "        else {\n",
    "            Aij[thy][thx] = 0.0;\n",
    "        }\n",
    "        if ((thx + (lim*MAX)) < n  && fil < n){\n",
    "            Bij[thy][thx] = b[((thx + (lim*MAX))*n) + fil];\n",
    "        }\n",
    "        else{\n",
    "            Bij[thy][thx] = 0.0;\n",
    "        }\n",
    "        __syncthreads();\n",
    "    #pragma unroll\n",
    "        for (k = 0; k < MAX; k++){\n",
    "            sum += Aij[k][thx] * Bij[thy][k];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (col < n && fil < n){\n",
    "        c[col * n + fil] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int *dev_a, *dev_b, *dev_c;\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid((N + MAX - 1)/MAX, (N + MAX - 1)/MAX);\n",
    "    dim3 dimBlock(MAX, MAX);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c, N);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "    //for (int y = 0; y < N; y++){\n",
    "    //    for (int x = 0; x < N; x++){\n",
    "    //        printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "    //    }\n",
    "    //    printf(\"\\n\");\n",
    "    //}\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\\n\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNt7HstJOv27",
    "outputId": "30dd8df4-c22e-44ec-ed01-ea7e435f28a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==869== NVPROF is profiling process 869, command: ./optimizaciones\n",
      "GigaFlops: 45.511742\n",
      "==869== Profiling application: ./optimizaciones\n",
      "==869== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.90%  10.271ms      1000  10.270us  10.175us  11.008us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.07%  6.7830us         2  3.3910us  3.0720us  3.7110us  [CUDA memcpy HtoD]\n",
      "                    0.03%  3.2000us         1  3.2000us  3.2000us  3.2000us  [CUDA memcpy DtoH]\n",
      "      API calls:   95.33%  249.28ms         2  124.64ms  1.0350us  249.27ms  cudaEventCreate\n",
      "                    2.70%  7.0662ms         1  7.0662ms  7.0662ms  7.0662ms  cudaEventSynchronize\n",
      "                    1.60%  4.1792ms      1000  4.1790us  3.1720us  24.539us  cudaLaunchKernel\n",
      "                    0.13%  344.53us         1  344.53us  344.53us  344.53us  cuDeviceTotalMem\n",
      "                    0.07%  190.43us         3  63.476us  3.3350us  181.34us  cudaMalloc\n",
      "                    0.06%  148.76us       101  1.4720us     132ns  62.913us  cuDeviceGetAttribute\n",
      "                    0.05%  131.40us         3  43.801us  2.3320us  119.06us  cudaFree\n",
      "                    0.03%  85.705us         3  28.568us  15.595us  39.288us  cudaMemcpy\n",
      "                    0.01%  33.835us         1  33.835us  33.835us  33.835us  cuDeviceGetName\n",
      "                    0.00%  8.9580us         2  4.4790us  4.1690us  4.7890us  cudaEventRecord\n",
      "                    0.00%  5.6160us         1  5.6160us  5.6160us  5.6160us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.1630us         1  2.1630us  2.1630us  2.1630us  cudaEventElapsedTime\n",
      "                    0.00%  1.2800us         2     640ns     200ns  1.0800us  cuDeviceGet\n",
      "                    0.00%  1.2100us         3     403ns     202ns     693ns  cuDeviceGetCount\n",
      "                    0.00%     289ns         1     289ns     289ns     289ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true optimizaciones.cu -o optimizaciones -lcudadevrt\n",
    "!nvprof ./optimizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjBCd4FKO56F"
   },
   "source": [
    "Con la optimización de memoria compartida y desenrollado de bucles se han obtenido `GigaFlops: 45.45454` lo cual supera claramente a los `GigaFlops: 1.248567` de GPU con memoria global. \n",
    "\n",
    "A la vista de estos resultados conlcuímos que si bien el uso de la GPU acelera los cálculos, lo que verdaderamente marcará la diferencia es la optimización del código. \n",
    "\n",
    "\n",
    "A contnuación vamos a limpiar un poco la salida de los programas y efectuar los experimentos para poder completar las tablas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbBFtOLpQ8KT",
    "outputId": "d64ede92-ae49-4470-fcc3-5a9c0d8abe37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gpu_global_2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile gpu_global_2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#define M 1\n",
    "\n",
    "__global__ void matrixMultGPU(int N, int *a, int *b, int *c){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "    int fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
    "    if (col < N && fil < N){\n",
    "        for (k = 0; k < N; k++){\n",
    "            sum += a[fil*N+k] * b[k*N+col];\n",
    "        }\n",
    "        c[fil*N+col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    int N = strtol(argv[1], NULL, 10);\n",
    "\n",
    "    printf(\"Matriz %d x %d \", N, N);\n",
    "\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int *dev_a, *dev_b, *dev_c;\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid(M, M);\n",
    "    dim3 dimBlock(N, N);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(N, dev_a, dev_b, dev_c);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "  /*\n",
    "    for (int y = 0; y < N; y++){\n",
    "        for (int x = 0; x < N; x++){\n",
    "            printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "*/\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f \\n\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gr42A_R8RgtU",
    "outputId": "77fae855-a6c6-4319-a5b8-c7b7701a9e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==915== NVPROF is profiling process 915, command: ./gpu_global_2 16\n",
      "Matriz 16 x 16 GigaFlops: 1.202392 \n",
      "==915== Profiling application: ./gpu_global_2 16\n",
      "==915== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.89%  5.4742ms      1000  5.4740us  5.4070us  9.7920us  matrixMultGPU(int, int*, int*, int*)\n",
      "                    0.07%  3.8400us         2  1.9200us  1.5360us  2.3040us  [CUDA memcpy HtoD]\n",
      "                    0.04%  2.1760us         1  2.1760us  2.1760us  2.1760us  [CUDA memcpy DtoH]\n",
      "      API calls:   97.11%  253.36ms         2  126.68ms     984ns  253.36ms  cudaEventCreate\n",
      "                    1.57%  4.0983ms      1000  4.0980us  3.2060us  27.146us  cudaLaunchKernel\n",
      "                    0.94%  2.4525ms         1  2.4525ms  2.4525ms  2.4525ms  cudaEventSynchronize\n",
      "                    0.14%  368.30us         1  368.30us  368.30us  368.30us  cuDeviceTotalMem\n",
      "                    0.09%  231.34us         3  77.112us  2.3770us  224.19us  cudaMalloc\n",
      "                    0.06%  151.48us       101  1.4990us     129ns  63.858us  cuDeviceGetAttribute\n",
      "                    0.05%  137.02us         3  45.672us  2.5340us  123.28us  cudaFree\n",
      "                    0.02%  64.960us         3  21.653us  8.5500us  32.295us  cudaMemcpy\n",
      "                    0.01%  28.995us         1  28.995us  28.995us  28.995us  cuDeviceGetName\n",
      "                    0.00%  8.1340us         2  4.0670us  3.7400us  4.3940us  cudaEventRecord\n",
      "                    0.00%  6.0250us         1  6.0250us  6.0250us  6.0250us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.2580us         1  2.2580us  2.2580us  2.2580us  cudaEventElapsedTime\n",
      "                    0.00%  1.4610us         3     487ns     202ns     894ns  cuDeviceGetCount\n",
      "                    0.00%  1.1260us         2     563ns     205ns     921ns  cuDeviceGet\n",
      "                    0.00%     264ns         1     264ns     264ns     264ns  cuDeviceGetUuid\n",
      "==926== NVPROF is profiling process 926, command: ./gpu_global_2 32\n",
      "Matriz 32 x 32 GigaFlops: 4.497363 \n",
      "==926== Profiling application: ./gpu_global_2 32\n",
      "==926== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.95%  13.301ms      1000  13.301us  13.055us  13.791us  matrixMultGPU(int, int*, int*, int*)\n",
      "                    0.03%  3.8720us         2  1.9360us  1.7600us  2.1120us  [CUDA memcpy HtoD]\n",
      "                    0.02%  2.3040us         1  2.3040us  2.3040us  2.3040us  [CUDA memcpy DtoH]\n",
      "      API calls:   92.53%  188.86ms         2  94.430ms     821ns  188.86ms  cudaEventCreate\n",
      "                    5.05%  10.312ms         1  10.312ms  10.312ms  10.312ms  cudaEventSynchronize\n",
      "                    1.96%  4.0083ms      1000  4.0080us  3.1710us  30.453us  cudaLaunchKernel\n",
      "                    0.17%  356.40us         1  356.40us  356.40us  356.40us  cuDeviceTotalMem\n",
      "                    0.08%  168.98us         3  56.326us  2.3590us  163.32us  cudaMalloc\n",
      "                    0.08%  159.33us       101  1.5770us     126ns  72.262us  cuDeviceGetAttribute\n",
      "                    0.06%  121.21us         3  40.404us  2.5130us  109.55us  cudaFree\n",
      "                    0.03%  59.704us         3  19.901us  9.5110us  32.149us  cudaMemcpy\n",
      "                    0.01%  29.050us         1  29.050us  29.050us  29.050us  cuDeviceGetName\n",
      "                    0.00%  7.8340us         2  3.9170us  3.6080us  4.2260us  cudaEventRecord\n",
      "                    0.00%  7.2390us         1  7.2390us  7.2390us  7.2390us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.5790us         1  2.5790us  2.5790us  2.5790us  cudaEventElapsedTime\n",
      "                    0.00%  1.5480us         3     516ns     176ns  1.0500us  cuDeviceGetCount\n",
      "                    0.00%  1.2970us         2     648ns     206ns  1.0910us  cuDeviceGet\n",
      "                    0.00%     283ns         1     283ns     283ns     283ns  cuDeviceGetUuid\n",
      "==937== NVPROF is profiling process 937, command: ./gpu_global_2 64\n",
      "Matriz 64 x 64 GigaFlops: 1310.615089 \n",
      "==937== Profiling application: ./gpu_global_2 64\n",
      "==937== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   66.35%  6.7520us         2  3.3760us  3.3280us  3.4240us  [CUDA memcpy HtoD]\n",
      "                   33.65%  3.4240us         1  3.4240us  3.4240us  3.4240us  [CUDA memcpy DtoH]\n",
      "      API calls:   99.42%  191.71ms         2  95.857ms  1.0330us  191.71ms  cudaEventCreate\n",
      "                    0.18%  353.30us         1  353.30us  353.30us  353.30us  cuDeviceTotalMem\n",
      "                    0.10%  183.41us      1000     183ns     162ns  6.1460us  cudaLaunchKernel\n",
      "                    0.09%  173.11us         3  57.703us  2.0360us  167.95us  cudaMalloc\n",
      "                    0.09%  166.68us       101  1.6500us     128ns  80.332us  cuDeviceGetAttribute\n",
      "                    0.05%  98.640us         3  32.880us  2.2320us  90.806us  cudaFree\n",
      "                    0.04%  86.481us         3  28.827us  14.647us  46.129us  cudaMemcpy\n",
      "                    0.01%  26.787us         1  26.787us  26.787us  26.787us  cuDeviceGetName\n",
      "                    0.00%  6.8650us         1  6.8650us  6.8650us  6.8650us  cudaEventSynchronize\n",
      "                    0.00%  6.3030us         2  3.1510us  2.2420us  4.0610us  cudaEventRecord\n",
      "                    0.00%  5.2900us         1  5.2900us  5.2900us  5.2900us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9780us         1  1.9780us  1.9780us  1.9780us  cudaEventElapsedTime\n",
      "                    0.00%  1.2640us         2     632ns     304ns     960ns  cuDeviceGet\n",
      "                    0.00%  1.2340us         3     411ns     190ns     737ns  cuDeviceGetCount\n",
      "                    0.00%     322ns         1     322ns     322ns     322ns  cuDeviceGetUuid\n",
      "==948== NVPROF is profiling process 948, command: ./gpu_global_2 128\n",
      "Matriz 128 x 128 GigaFlops: 8550.589980 \n",
      "==948== Profiling application: ./gpu_global_2 128\n",
      "==948== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   73.15%  20.224us         2  10.112us  9.7600us  10.464us  [CUDA memcpy HtoD]\n",
      "                   26.85%  7.4240us         1  7.4240us  7.4240us  7.4240us  [CUDA memcpy DtoH]\n",
      "      API calls:   99.36%  189.44ms         2  94.719ms     876ns  189.44ms  cudaEventCreate\n",
      "                    0.18%  343.13us         1  343.13us  343.13us  343.13us  cuDeviceTotalMem\n",
      "                    0.11%  218.14us      1000     218ns     170ns     885ns  cudaLaunchKernel\n",
      "                    0.09%  168.70us         3  56.234us  41.191us  79.507us  cudaMemcpy\n",
      "                    0.08%  159.61us       101  1.5800us     127ns  65.166us  cuDeviceGetAttribute\n",
      "                    0.08%  150.99us         3  50.329us  2.1140us  145.79us  cudaMalloc\n",
      "                    0.06%  119.00us         3  39.666us  2.4420us  107.58us  cudaFree\n",
      "                    0.02%  28.792us         1  28.792us  28.792us  28.792us  cuDeviceGetName\n",
      "                    0.01%  11.294us         2  5.6470us  3.9490us  7.3450us  cudaEventRecord\n",
      "                    0.00%  6.8400us         1  6.8400us  6.8400us  6.8400us  cudaEventSynchronize\n",
      "                    0.00%  5.8660us         1  5.8660us  5.8660us  5.8660us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.4560us         1  2.4560us  2.4560us  2.4560us  cudaEventElapsedTime\n",
      "                    0.00%  1.3450us         2     672ns     283ns  1.0620us  cuDeviceGet\n",
      "                    0.00%  1.2090us         3     403ns     169ns     685ns  cuDeviceGetCount\n",
      "                    0.00%     261ns         1     261ns     261ns     261ns  cuDeviceGetUuid\n",
      "==959== NVPROF is profiling process 959, command: ./gpu_global_2 512\n",
      "Matriz 512 x 512 GigaFlops: 843415.254114 \n",
      "==959== Profiling application: ./gpu_global_2 512\n",
      "==959== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   68.17%  175.90us         2  87.948us  87.740us  88.156us  [CUDA memcpy HtoD]\n",
      "                   31.83%  82.141us         1  82.141us  82.141us  82.141us  [CUDA memcpy DtoH]\n",
      "      API calls:   98.69%  199.29ms         2  99.644ms     911ns  199.29ms  cudaEventCreate\n",
      "                    0.66%  1.3279ms         3  442.64us  262.22us  764.63us  cudaMemcpy\n",
      "                    0.19%  380.59us         1  380.59us  380.59us  380.59us  cuDeviceTotalMem\n",
      "                    0.14%  283.46us         3  94.485us  4.1640us  178.76us  cudaMalloc\n",
      "                    0.12%  235.42us         3  78.471us  9.2380us  119.38us  cudaFree\n",
      "                    0.10%  193.48us      1000     193ns     167ns  12.113us  cudaLaunchKernel\n",
      "                    0.08%  159.40us       101  1.5780us     136ns  71.111us  cuDeviceGetAttribute\n",
      "                    0.01%  28.821us         1  28.821us  28.821us  28.821us  cuDeviceGetName\n",
      "                    0.00%  7.6830us         2  3.8410us  2.3480us  5.3350us  cudaEventRecord\n",
      "                    0.00%  6.8650us         1  6.8650us  6.8650us  6.8650us  cudaEventSynchronize\n",
      "                    0.00%  5.4520us         1  5.4520us  5.4520us  5.4520us  cuDeviceGetPCIBusId\n",
      "                    0.00%  3.0210us         1  3.0210us  3.0210us  3.0210us  cudaEventElapsedTime\n",
      "                    0.00%  1.7340us         3     578ns     203ns  1.1830us  cuDeviceGetCount\n",
      "                    0.00%  1.1700us         2     585ns     324ns     846ns  cuDeviceGet\n",
      "                    0.00%     249ns         1     249ns     249ns     249ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true gpu_global_2.cu -o gpu_global_2 -lcudadevrt\n",
    "# 16 32 64 128 512\n",
    "!nvprof ./gpu_global_2 16\n",
    "!nvprof ./gpu_global_2 32\n",
    "!nvprof ./gpu_global_2 64\n",
    "!nvprof ./gpu_global_2 128\n",
    "!nvprof ./gpu_global_2 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KznwW_Q_VbY0"
   },
   "source": [
    "## Tabla de resutlados \n",
    "(Note que para la construcción de esta tabla se ha usado los datos de la ejecución que se recoge en el apéndice). \n",
    "\n",
    "\n",
    "GPU sin usar memoria compartidad | \t| Tiempo de Ejecución (msec) | \t| \t- |  -   \n",
    "--- | --- | --- | ---  | --- | ---| \n",
    "Tamaño de la matriz\t | CPU- >GPU |\tGPU- >CPU | \tEjecución kernel | \tRatio comparado con 128x128\t | GFLOPs  | \n",
    "16x16\t|0.003 | 0.002| 5.443 |0.03 | 1.228|\n",
    "32x32\t|0.003 | 0.002| 13.275 | 0.078 | 4.51|  \n",
    "64x64\t| 0.006| 0.003 |181 | 1.06 | 1347.1 |  \n",
    "128x128\t| 0.018|0.007 |170 |  1| 11771 |  \n",
    "512x512\t| 0.176|0.082 | 172| 1.01| 933104|  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iorrqnEasc2M",
    "outputId": "4de6118a-83f4-48cb-bf1d-7116835eaed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032017647058823526\n",
      "0.07780588235294118\n",
      "1.0647058823529412\n",
      "1.0\n",
      "1.011764705882353\n"
     ]
    }
   ],
   "source": [
    "# cálculo de ratios\n",
    "\n",
    "rt = [5.443, 13.227, 181,170,172]\n",
    "for r in rt:\n",
    "  print(r/rt[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG5VQI1jtPdi"
   },
   "source": [
    "## Comparativas usando memoria compartida \n",
    "\n",
    "Compararemos la versión optimizada, ya que es la más eficiente. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZs42SkWtPFz",
    "outputId": "b85ceb1f-4a2f-457d-e27c-51b438af3df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing optimizaciones2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile optimizaciones2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define MAX 8\n",
    "\n",
    "__global__ void matrixMultGPU(int *a, int *b, int *c, int n){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int thx = threadIdx.x;\n",
    "    int thy = threadIdx.y;\n",
    "    int col = thx + blockDim.x * blockIdx.x;\n",
    "    int fil = thy + blockDim.y * blockIdx.y;\n",
    "\n",
    "    __shared__ float Aij[MAX][MAX];\n",
    "    __shared__ float Bij[MAX][MAX];\n",
    "\n",
    "    for (int lim = 0; lim < (n + MAX - 1)/MAX; lim++){\n",
    "        if ((thy + (lim*MAX)) < n  && col < n){\n",
    "            Aij[thy][thx] = a[(col*n) + (thy + (lim*MAX))];\n",
    "        }\n",
    "        else {\n",
    "            Aij[thy][thx] = 0.0;\n",
    "        }\n",
    "        if ((thx + (lim*MAX)) < n  && fil < n){\n",
    "            Bij[thy][thx] = b[((thx + (lim*MAX))*n) + fil];\n",
    "        }\n",
    "        else{\n",
    "            Bij[thy][thx] = 0.0;\n",
    "        }\n",
    "        __syncthreads();\n",
    "    #pragma unroll\n",
    "        for (k = 0; k < MAX; k++){\n",
    "            sum += Aij[k][thx] * Bij[thy][k];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (col < n && fil < n){\n",
    "        c[col * n + fil] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    int N = strtol(argv[1], NULL, 10);\n",
    "\n",
    "    printf(\"Matriz %d x %d \", N, N);\n",
    "    int a[N][N], b[N][N], c[N][N];\n",
    "    int *dev_a, *dev_b, *dev_c;\n",
    "    int cont, i , j;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid((N + MAX - 1)/MAX, (N + MAX - 1)/MAX);\n",
    "    dim3 dimBlock(MAX, MAX);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c, N);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "    //for (int y = 0; y < N; y++){\n",
    "    //    for (int x = 0; x < N; x++){\n",
    "    //        printf(\"[%d][%d]=%d \", y, x, c[x][y]);\n",
    "    //    }\n",
    "    //    printf(\"\\n\");\n",
    "    //}\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\\n\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rZ3j8dtumUZ",
    "outputId": "e13f2f69-994d-4cac-82bf-dcd23211f63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==1003== NVPROF is profiling process 1003, command: ./optimizaciones2 16\n",
      "Matriz 16 x 16 GigaFlops: 1.258926\n",
      "==1003== Profiling application: ./optimizaciones2 16\n",
      "==1003== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.89%  5.2104ms      1000  5.2100us  5.1510us  5.8560us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.07%  3.4240us         2  1.7120us  1.4720us  1.9520us  [CUDA memcpy HtoD]\n",
      "                    0.04%  2.1760us         1  2.1760us  2.1760us  2.1760us  [CUDA memcpy DtoH]\n",
      "      API calls:   96.38%  188.83ms         2  94.417ms     857ns  188.83ms  cudaEventCreate\n",
      "                    2.13%  4.1767ms      1000  4.1760us  3.2930us  23.068us  cudaLaunchKernel\n",
      "                    1.03%  2.0234ms         1  2.0234ms  2.0234ms  2.0234ms  cudaEventSynchronize\n",
      "                    0.18%  351.81us         1  351.81us  351.81us  351.81us  cuDeviceTotalMem\n",
      "                    0.08%  158.32us         3  52.774us  1.9150us  153.56us  cudaMalloc\n",
      "                    0.08%  147.93us       101  1.4640us     127ns  63.465us  cuDeviceGetAttribute\n",
      "                    0.06%  120.09us         3  40.031us  2.2880us  109.41us  cudaFree\n",
      "                    0.03%  57.091us         3  19.030us  8.8110us  29.102us  cudaMemcpy\n",
      "                    0.01%  28.342us         1  28.342us  28.342us  28.342us  cuDeviceGetName\n",
      "                    0.00%  9.7230us         2  4.8610us  4.5430us  5.1800us  cudaEventRecord\n",
      "                    0.00%  6.3600us         1  6.3600us  6.3600us  6.3600us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9160us         1  1.9160us  1.9160us  1.9160us  cudaEventElapsedTime\n",
      "                    0.00%  1.7090us         3     569ns     218ns  1.1340us  cuDeviceGetCount\n",
      "                    0.00%  1.2730us         2     636ns     294ns     979ns  cuDeviceGet\n",
      "                    0.00%     272ns         1     272ns     272ns     272ns  cuDeviceGetUuid\n",
      "==1014== NVPROF is profiling process 1014, command: ./optimizaciones2 32\n",
      "Matriz 32 x 32 GigaFlops: 8.362972\n",
      "==1014== Profiling application: ./optimizaciones2 32\n",
      "==1014== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.91%  6.5491ms      1000  6.5490us  6.4950us  12.000us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.06%  3.8400us         2  1.9200us  1.7280us  2.1120us  [CUDA memcpy HtoD]\n",
      "                    0.04%  2.3360us         1  2.3360us  2.3360us  2.3360us  [CUDA memcpy DtoH]\n",
      "      API calls:   95.79%  193.51ms         2  96.754ms     862ns  193.51ms  cudaEventCreate\n",
      "                    2.12%  4.2780ms      1000  4.2780us  3.1510us  25.969us  cudaLaunchKernel\n",
      "                    1.62%  3.2804ms         1  3.2804ms  3.2804ms  3.2804ms  cudaEventSynchronize\n",
      "                    0.18%  356.15us         1  356.15us  356.15us  356.15us  cuDeviceTotalMem\n",
      "                    0.08%  156.08us         3  52.025us  2.5520us  150.41us  cudaMalloc\n",
      "                    0.08%  154.91us         3  51.635us  4.0630us  139.58us  cudaFree\n",
      "                    0.08%  153.97us       101  1.5240us     129ns  66.941us  cuDeviceGetAttribute\n",
      "                    0.03%  68.390us         3  22.796us  9.5890us  40.149us  cudaMemcpy\n",
      "                    0.01%  28.630us         1  28.630us  28.630us  28.630us  cuDeviceGetName\n",
      "                    0.00%  9.5330us         2  4.7660us  4.6610us  4.8720us  cudaEventRecord\n",
      "                    0.00%  6.2400us         1  6.2400us  6.2400us  6.2400us  cuDeviceGetPCIBusId\n",
      "                    0.00%  3.2970us         1  3.2970us  3.2970us  3.2970us  cudaEventElapsedTime\n",
      "                    0.00%  1.8010us         3     600ns     206ns  1.2110us  cuDeviceGetCount\n",
      "                    0.00%  1.2360us         2     618ns     315ns     921ns  cuDeviceGet\n",
      "                    0.00%     229ns         1     229ns     229ns     229ns  cuDeviceGetUuid\n",
      "==1025== NVPROF is profiling process 1025, command: ./optimizaciones2 64\n",
      "Matriz 64 x 64 GigaFlops: 45.537293\n",
      "==1025== Profiling application: ./optimizaciones2 64\n",
      "==1025== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.91%  10.259ms      1000  10.258us  10.176us  11.167us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.06%  6.5280us         2  3.2640us  3.0400us  3.4880us  [CUDA memcpy HtoD]\n",
      "                    0.03%  3.1680us         1  3.1680us  3.1680us  3.1680us  [CUDA memcpy DtoH]\n",
      "      API calls:   94.01%  192.07ms         2  96.036ms     968ns  192.07ms  cudaEventCreate\n",
      "                    3.51%  7.1675ms         1  7.1675ms  7.1675ms  7.1675ms  cudaEventSynchronize\n",
      "                    1.99%  4.0755ms      1000  4.0750us  3.1840us  24.114us  cudaLaunchKernel\n",
      "                    0.18%  375.78us         1  375.78us  375.78us  375.78us  cuDeviceTotalMem\n",
      "                    0.10%  194.24us       101  1.9230us     134ns  76.914us  cuDeviceGetAttribute\n",
      "                    0.08%  158.19us         3  52.731us  2.0950us  152.86us  cudaMalloc\n",
      "                    0.06%  127.13us         3  42.377us  2.7560us  115.28us  cudaFree\n",
      "                    0.04%  88.321us         3  29.440us  20.750us  41.774us  cudaMemcpy\n",
      "                    0.01%  29.582us         1  29.582us  29.582us  29.582us  cuDeviceGetName\n",
      "                    0.00%  8.3890us         2  4.1940us  4.0630us  4.3260us  cudaEventRecord\n",
      "                    0.00%  6.5040us         1  6.5040us  6.5040us  6.5040us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.3240us         1  2.3240us  2.3240us  2.3240us  cudaEventElapsedTime\n",
      "                    0.00%  1.7920us         3     597ns     227ns  1.2010us  cuDeviceGetCount\n",
      "                    0.00%  1.2950us         2     647ns     274ns  1.0210us  cuDeviceGet\n",
      "                    0.00%     321ns         1     321ns     321ns     321ns  cuDeviceGetUuid\n",
      "==1036== NVPROF is profiling process 1036, command: ./optimizaciones2 128\n",
      "Matriz 128 x 128 GigaFlops: 113.898789\n",
      "==1036== Profiling application: ./optimizaciones2 128\n",
      "==1036== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.93%  35.525ms      1000  35.525us  34.623us  36.191us  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.05%  19.232us         2  9.6160us  9.5680us  9.6640us  [CUDA memcpy HtoD]\n",
      "                    0.02%  7.0080us         1  7.0080us  7.0080us  7.0080us  [CUDA memcpy DtoH]\n",
      "      API calls:   83.48%  189.90ms         2  94.948ms  1.2700us  189.90ms  cudaEventCreate\n",
      "                   13.99%  31.822ms         1  31.822ms  31.822ms  31.822ms  cudaEventSynchronize\n",
      "                    2.04%  4.6382ms      1000  4.6380us  3.7660us  25.986us  cudaLaunchKernel\n",
      "                    0.17%  394.70us         1  394.70us  394.70us  394.70us  cuDeviceTotalMem\n",
      "                    0.08%  186.29us         3  62.096us  2.4680us  180.01us  cudaMalloc\n",
      "                    0.08%  179.62us         3  59.872us  36.975us  98.601us  cudaMemcpy\n",
      "                    0.07%  156.08us         3  52.025us  3.1260us  140.14us  cudaFree\n",
      "                    0.07%  153.91us       101  1.5230us     136ns  64.786us  cuDeviceGetAttribute\n",
      "                    0.01%  28.737us         1  28.737us  28.737us  28.737us  cuDeviceGetName\n",
      "                    0.00%  10.638us         2  5.3190us  5.2580us  5.3800us  cudaEventRecord\n",
      "                    0.00%  6.0990us         1  6.0990us  6.0990us  6.0990us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.8190us         1  2.8190us  2.8190us  2.8190us  cudaEventElapsedTime\n",
      "                    0.00%  1.9910us         3     663ns     210ns  1.4210us  cuDeviceGetCount\n",
      "                    0.00%  1.2400us         2     620ns     310ns     930ns  cuDeviceGet\n",
      "                    0.00%     254ns         1     254ns     254ns     254ns  cuDeviceGetUuid\n",
      "==1047== NVPROF is profiling process 1047, command: ./optimizaciones2 512\n",
      "Matriz 512 x 512 GigaFlops: 329.444397\n",
      "==1047== Profiling application: ./optimizaciones2 512\n",
      "==1047== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.97%  813.99ms      1000  813.99us  653.01us  1.7294ms  matrixMultGPU(int*, int*, int*, int)\n",
      "                    0.02%  176.06us         2  88.029us  87.997us  88.061us  [CUDA memcpy HtoD]\n",
      "                    0.01%  81.917us         1  81.917us  81.917us  81.917us  [CUDA memcpy DtoH]\n",
      "      API calls:   80.19%  810.57ms         1  810.57ms  810.57ms  810.57ms  cudaEventSynchronize\n",
      "                   19.16%  193.71ms         2  96.853ms     993ns  193.70ms  cudaEventCreate\n",
      "                    0.40%  4.0216ms      1000  4.0210us  3.1510us  40.786us  cudaLaunchKernel\n",
      "                    0.14%  1.3713ms         3  457.12us  240.60us  811.44us  cudaMemcpy\n",
      "                    0.04%  399.46us         1  399.46us  399.46us  399.46us  cuDeviceTotalMem\n",
      "                    0.03%  271.86us         3  90.620us  21.408us  168.88us  cudaFree\n",
      "                    0.03%  257.73us         3  85.910us  3.4270us  167.01us  cudaMalloc\n",
      "                    0.02%  156.71us       101  1.5510us     136ns  66.351us  cuDeviceGetAttribute\n",
      "                    0.00%  42.395us         1  42.395us  42.395us  42.395us  cuDeviceGetName\n",
      "                    0.00%  8.8860us         2  4.4430us  3.8500us  5.0360us  cudaEventRecord\n",
      "                    0.00%  5.7580us         1  5.7580us  5.7580us  5.7580us  cuDeviceGetPCIBusId\n",
      "                    0.00%  5.1200us         1  5.1200us  5.1200us  5.1200us  cudaEventElapsedTime\n",
      "                    0.00%  1.9210us         3     640ns     201ns  1.3740us  cuDeviceGetCount\n",
      "                    0.00%  1.0960us         2     548ns     199ns     897ns  cuDeviceGet\n",
      "                    0.00%     257ns         1     257ns     257ns     257ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true optimizaciones2.cu -o optimizaciones2 -lcudadevrt\n",
    "# 16 32 64 128 512\n",
    "!nvprof ./optimizaciones2 16\n",
    "!nvprof ./optimizaciones2 32\n",
    "!nvprof ./optimizaciones2 64\n",
    "!nvprof ./optimizaciones2 128\n",
    "!nvprof ./optimizaciones2 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfL1sD4PxJyw",
    "outputId": "5d36f2e7-d4af-4457-9ecc-98ecf9adb0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1452938527358703\n",
      "0.18464309840126097\n",
      "0.2871819410042783\n",
      "1.0\n",
      "22.489304210763343\n"
     ]
    }
   ],
   "source": [
    "# cálculo de ratios\n",
    "\n",
    "rt = [5.162, 6.56, 10.203, 35.528,799]\n",
    "for r in rt:\n",
    "  print(r/rt[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5y06LCUOwk60"
   },
   "source": [
    "GPU **optimizada** | \t| Tiempo de Ejecución (msec) | \t| \t- |  -   \n",
    "--- | --- | --- | ---  | --- | ---| \n",
    "Tamaño de la matriz\t | CPU- >GPU |\tGPU- >CPU | \tEjecución kernel | \tRatio comparado con 128x128\t | GFLOPs  | \n",
    "16x16\t| 0.0036| 0.0021 | 5.162| 0.145| 1.266|\n",
    "32x32\t| 0.0037| 0.002 |6.56  | 0.184|8.365 | \n",
    "64x64\t| 0.006| 0.003| 10.203 |0.287|45.67 |\n",
    "128x128\t| 0.18 | 0.0069| 35.528 |1| 113.9|\n",
    "512x512\t| 0.179 | 0.08| 799 |22.48| 355.46|\n",
    "\n",
    "\n",
    "Teniendo presente los resultados de las ejecuciones sin compartir memoria.  \n",
    "\n",
    "\n",
    "Puede observarse que los tiempos de copia de datos se mantienen constantes pero que el tiempo de ejecución del kernel baja notablemente, manifestándose en un menor ratio y un mayor número de GFLOP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjmnrdsa0Z5G"
   },
   "source": [
    "## Como ejercicio adicional, prueba a migrar los códigos a aritmética en doble precisión (cambiar \"float\" por \"double\" en el tipo de dato de las matrices). ¿En qué medida se ven afectadas las prestaciones?\n",
    "\n",
    "**Solución**\n",
    "\n",
    "Código con doubles: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IT8j0OI40iwo",
    "outputId": "43ae49ae-a014-477f-fe2b-11e46189a046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing optimizaciones3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile optimizaciones3.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "#define MAX 8\n",
    "\n",
    "__global__ void matrixMultGPU(double *a, double *b, double *c, int n){\n",
    "    int k;\n",
    "    float sum = 0;\n",
    "    int thx = threadIdx.x;\n",
    "    int thy = threadIdx.y;\n",
    "    int col = thx + blockDim.x * blockIdx.x;\n",
    "    int fil = thy + blockDim.y * blockIdx.y;\n",
    "\n",
    "    __shared__ float Aij[MAX][MAX];\n",
    "    __shared__ float Bij[MAX][MAX];\n",
    "\n",
    "    for (int lim = 0; lim < (n + MAX - 1)/MAX; lim++){\n",
    "        if ((thy + (lim*MAX)) < n  && col < n){\n",
    "            Aij[thy][thx] = a[(col*n) + (thy + (lim*MAX))];\n",
    "        }\n",
    "        else {\n",
    "            Aij[thy][thx] = 0.0;\n",
    "        }\n",
    "        if ((thx + (lim*MAX)) < n  && fil < n){\n",
    "            Bij[thy][thx] = b[((thx + (lim*MAX))*n) + fil];\n",
    "        }\n",
    "        else{\n",
    "            Bij[thy][thx] = 0.0;\n",
    "        }\n",
    "        __syncthreads();\n",
    "    #pragma unroll\n",
    "        for (k = 0; k < MAX; k++){\n",
    "            sum += Aij[k][thx] * Bij[thy][k];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if (col < n && fil < n){\n",
    "        c[col * n + fil] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    int N = strtol(argv[1], NULL, 10);\n",
    "\n",
    "    printf(\"Matriz %d x %d \", N, N);\n",
    "    double a[N][N], b[N][N], c[N][N];\n",
    "    double *dev_a, *dev_b, *dev_c;\n",
    "    int  i , j;\n",
    "    double cont;\n",
    "\n",
    "    cudaEvent_t start, stop;\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "\n",
    "    for (i = 0; i < N; i++){\n",
    "        cont = 0.0;\n",
    "        for (j = 0; j < N; j++){\n",
    "            a[i][j] = cont;\n",
    "            b[i][j] = cont;\n",
    "            cont++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int size = N*N*sizeof(int);\n",
    "    cudaMalloc((void **) &dev_a, size);\n",
    "    cudaMalloc((void **) &dev_b, size);\n",
    "    cudaMalloc((void **) &dev_c, size);\n",
    "\n",
    "    cudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid((N + MAX - 1)/MAX, (N + MAX - 1)/MAX);\n",
    "    dim3 dimBlock(MAX, MAX);\n",
    "\n",
    "    int nIter = 1000;\n",
    "    cudaEventRecord(start);\n",
    "\n",
    "    for (int m = 0; m < nIter; m++){\n",
    "        matrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c, N);\n",
    "    }\n",
    "\n",
    "    cudaEventRecord(stop);\n",
    "    cudaEventSynchronize(stop);\n",
    "\n",
    "    cudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float msecTotal = 0.0;\n",
    "    cudaEventElapsedTime(&msecTotal, start, stop);\n",
    "\n",
    "    cudaFree(dev_a);\n",
    "    cudaFree(dev_b);\n",
    "    cudaFree(dev_c);\n",
    "\n",
    "\n",
    "    float msecPerKernelExecution = msecTotal / nIter;\n",
    "    double flopsPerMMull = 2.0 * N * N * N;\n",
    "    double gigaFlops = (flopsPerMMull * 1.0e-9f) / (msecPerKernelExecution / 1000.0f);\n",
    "\n",
    "    printf(\"GigaFlops: %f\\n\", gigaFlops);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCBIgFWM1P6F",
    "outputId": "0fe4d316-4e01-44bc-f7fa-bb7933b317af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==1091== NVPROF is profiling process 1091, command: ./optimizaciones3 16\n",
      "Matriz 16 x 16 GigaFlops: 1.801244\n",
      "==1091== Profiling application: ./optimizaciones3 16\n",
      "==1091== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.85%  2.8477ms      1000  2.8470us  2.7830us  7.8400us  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.10%  2.8160us         2  1.4080us  1.1200us  1.6960us  [CUDA memcpy HtoD]\n",
      "                    0.05%  1.5680us         1  1.5680us  1.5680us  1.5680us  [CUDA memcpy DtoH]\n",
      "      API calls:   97.95%  250.03ms         2  125.02ms     973ns  250.03ms  cudaEventCreate\n",
      "                    1.68%  4.2807ms      1000  4.2800us  3.3870us  25.333us  cudaLaunchKernel\n",
      "                    0.14%  347.75us         1  347.75us  347.75us  347.75us  cuDeviceTotalMem\n",
      "                    0.08%  213.14us         3  71.046us  2.0950us  206.25us  cudaMalloc\n",
      "                    0.06%  155.65us       101  1.5410us     128ns  63.361us  cuDeviceGetAttribute\n",
      "                    0.05%  131.46us         3  43.820us  2.8520us  115.07us  cudaFree\n",
      "                    0.02%  52.273us         3  17.424us  7.3330us  25.501us  cudaMemcpy\n",
      "                    0.01%  27.342us         1  27.342us  27.342us  27.342us  cuDeviceGetName\n",
      "                    0.00%  9.3410us         2  4.6700us  4.4600us  4.8810us  cudaEventRecord\n",
      "                    0.00%  8.1370us         1  8.1370us  8.1370us  8.1370us  cuDeviceGetPCIBusId\n",
      "                    0.00%  7.0330us         1  7.0330us  7.0330us  7.0330us  cudaEventSynchronize\n",
      "                    0.00%  1.9450us         1  1.9450us  1.9450us  1.9450us  cudaEventElapsedTime\n",
      "                    0.00%  1.4840us         3     494ns     206ns     997ns  cuDeviceGetCount\n",
      "                    0.00%  1.1700us         2     585ns     205ns     965ns  cuDeviceGet\n",
      "                    0.00%     277ns         1     277ns     277ns     277ns  cuDeviceGetUuid\n",
      "==1102== NVPROF is profiling process 1102, command: ./optimizaciones3 32\n",
      "Matriz 32 x 32 GigaFlops: 7.808687\n",
      "==1102== Profiling application: ./optimizaciones3 32\n",
      "==1102== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.91%  7.1355ms      1000  7.1350us  7.0710us  8.0960us  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.05%  3.8720us         2  1.9360us  1.7600us  2.1120us  [CUDA memcpy HtoD]\n",
      "                    0.03%  2.3040us         1  2.3040us  2.3040us  2.3040us  [CUDA memcpy DtoH]\n",
      "      API calls:   95.59%  197.19ms         2  98.595ms     746ns  197.19ms  cudaEventCreate\n",
      "                    2.00%  4.1214ms      1000  4.1210us  3.1630us  25.439us  cudaLaunchKernel\n",
      "                    1.94%  4.0011ms         1  4.0011ms  4.0011ms  4.0011ms  cudaEventSynchronize\n",
      "                    0.18%  378.53us         1  378.53us  378.53us  378.53us  cuDeviceTotalMem\n",
      "                    0.08%  173.39us       101  1.7160us     140ns  70.479us  cuDeviceGetAttribute\n",
      "                    0.08%  162.31us         3  54.102us  2.5590us  156.56us  cudaMalloc\n",
      "                    0.06%  131.66us         3  43.886us  2.4710us  120.50us  cudaFree\n",
      "                    0.03%  67.642us         3  22.547us  9.3260us  37.237us  cudaMemcpy\n",
      "                    0.02%  32.276us         1  32.276us  32.276us  32.276us  cuDeviceGetName\n",
      "                    0.00%  8.9030us         2  4.4510us  4.2000us  4.7030us  cudaEventRecord\n",
      "                    0.00%  5.6810us         1  5.6810us  5.6810us  5.6810us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.0220us         1  2.0220us  2.0220us  2.0220us  cudaEventElapsedTime\n",
      "                    0.00%  1.6130us         2     806ns     264ns  1.3490us  cuDeviceGet\n",
      "                    0.00%  1.5950us         3     531ns     204ns  1.0780us  cuDeviceGetCount\n",
      "                    0.00%     334ns         1     334ns     334ns     334ns  cuDeviceGetUuid\n",
      "==1113== NVPROF is profiling process 1113, command: ./optimizaciones3 64\n",
      "Matriz 64 x 64 GigaFlops: 39.996291\n",
      "==1113== Profiling application: ./optimizaciones3 64\n",
      "==1113== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.92%  11.842ms      1000  11.842us  11.744us  17.567us  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.06%  6.7200us         2  3.3600us  3.2320us  3.4880us  [CUDA memcpy HtoD]\n",
      "                    0.03%  3.2320us         1  3.2320us  3.2320us  3.2320us  [CUDA memcpy DtoH]\n",
      "      API calls:   93.78%  210.46ms         2  105.23ms     953ns  210.46ms  cudaEventCreate\n",
      "                    3.87%  8.6774ms         1  8.6774ms  8.6774ms  8.6774ms  cudaEventSynchronize\n",
      "                    1.88%  4.2148ms      1000  4.2140us  3.2810us  24.139us  cudaLaunchKernel\n",
      "                    0.17%  380.84us         1  380.84us  380.84us  380.84us  cuDeviceTotalMem\n",
      "                    0.08%  187.74us       101  1.8580us     154ns  79.073us  cuDeviceGetAttribute\n",
      "                    0.08%  181.43us         3  60.476us  4.3680us  144.95us  cudaFree\n",
      "                    0.07%  158.90us         3  52.965us  2.4430us  153.14us  cudaMalloc\n",
      "                    0.04%  100.51us         3  33.504us  14.481us  62.044us  cudaMemcpy\n",
      "                    0.01%  30.492us         1  30.492us  30.492us  30.492us  cuDeviceGetName\n",
      "                    0.00%  8.6780us         2  4.3390us  4.1070us  4.5710us  cudaEventRecord\n",
      "                    0.00%  5.2590us         1  5.2590us  5.2590us  5.2590us  cuDeviceGetPCIBusId\n",
      "                    0.00%  3.3890us         1  3.3890us  3.3890us  3.3890us  cudaEventElapsedTime\n",
      "                    0.00%  1.5430us         3     514ns     138ns  1.0860us  cuDeviceGetCount\n",
      "                    0.00%  1.2450us         2     622ns     380ns     865ns  cuDeviceGet\n",
      "                    0.00%     340ns         1     340ns     340ns     340ns  cuDeviceGetUuid\n",
      "==1126== NVPROF is profiling process 1126, command: ./optimizaciones3 128\n",
      "Matriz 128 x 128 GigaFlops: 85.383300\n",
      "==1126== Profiling application: ./optimizaciones3 128\n",
      "==1126== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.94%  47.831ms      1000  47.831us  47.231us  48.607us  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.04%  19.742us         2  9.8710us  9.5990us  10.143us  [CUDA memcpy HtoD]\n",
      "                    0.01%  6.9430us         1  6.9430us  6.9430us  6.9430us  [CUDA memcpy DtoH]\n",
      "      API calls:   79.63%  195.07ms         2  97.533ms     915ns  195.07ms  cudaEventCreate\n",
      "                   18.24%  44.690ms         1  44.690ms  44.690ms  44.690ms  cudaEventSynchronize\n",
      "                    1.70%  4.1763ms      1000  4.1760us  3.2030us  24.777us  cudaLaunchKernel\n",
      "                    0.14%  345.12us         1  345.12us  345.12us  345.12us  cuDeviceTotalMem\n",
      "                    0.07%  175.17us         3  58.388us  39.572us  92.383us  cudaMemcpy\n",
      "                    0.07%  167.74us       101  1.6600us     134ns  72.118us  cuDeviceGetAttribute\n",
      "                    0.07%  160.69us         3  53.561us  2.2000us  155.57us  cudaMalloc\n",
      "                    0.06%  137.43us         3  45.811us  2.5070us  124.25us  cudaFree\n",
      "                    0.01%  28.512us         1  28.512us  28.512us  28.512us  cuDeviceGetName\n",
      "                    0.00%  9.2230us         2  4.6110us  4.5580us  4.6650us  cudaEventRecord\n",
      "                    0.00%  7.9990us         1  7.9990us  7.9990us  7.9990us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.5030us         1  2.5030us  2.5030us  2.5030us  cudaEventElapsedTime\n",
      "                    0.00%  1.7760us         3     592ns     260ns  1.2060us  cuDeviceGetCount\n",
      "                    0.00%  1.2670us         2     633ns     192ns  1.0750us  cuDeviceGet\n",
      "                    0.00%     309ns         1     309ns     309ns     309ns  cuDeviceGetUuid\n",
      "==1137== NVPROF is profiling process 1137, command: ./optimizaciones3 512\n",
      "Matriz 512 x 512 GigaFlops: 243.940397\n",
      "==1137== Profiling application: ./optimizaciones3 512\n",
      "==1137== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.98%  1.09960s      1000  1.0996ms  919.49us  2.4612ms  matrixMultGPU(double*, double*, double*, int)\n",
      "                    0.02%  176.16us         2  88.077us  87.709us  88.446us  [CUDA memcpy HtoD]\n",
      "                    0.01%  81.150us         1  81.150us  81.150us  81.150us  [CUDA memcpy DtoH]\n",
      "      API calls:   83.51%  1.09335s         1  1.09335s  1.09335s  1.09335s  cudaEventSynchronize\n",
      "                   15.78%  206.60ms         2  103.30ms     985ns  206.59ms  cudaEventCreate\n",
      "                    0.51%  6.6554ms      1000  6.6550us  3.4530us  503.94us  cudaLaunchKernel\n",
      "                    0.11%  1.4398ms         3  479.95us  253.48us  863.15us  cudaMemcpy\n",
      "                    0.03%  386.29us         1  386.29us  386.29us  386.29us  cuDeviceTotalMem\n",
      "                    0.02%  277.55us         3  92.517us  4.0390us  182.39us  cudaMalloc\n",
      "                    0.02%  267.98us         3  89.326us  21.022us  167.29us  cudaFree\n",
      "                    0.01%  151.91us       101  1.5040us     133ns  64.733us  cuDeviceGetAttribute\n",
      "                    0.00%  28.996us         1  28.996us  28.996us  28.996us  cuDeviceGetName\n",
      "                    0.00%  9.5190us         2  4.7590us  4.1480us  5.3710us  cudaEventRecord\n",
      "                    0.00%  5.8780us         1  5.8780us  5.8780us  5.8780us  cuDeviceGetPCIBusId\n",
      "                    0.00%  4.6220us         1  4.6220us  4.6220us  4.6220us  cudaEventElapsedTime\n",
      "                    0.00%  1.2320us         2     616ns     268ns     964ns  cuDeviceGet\n",
      "                    0.00%  1.1100us         3     370ns     165ns     678ns  cuDeviceGetCount\n",
      "                    0.00%     251ns         1     251ns     251ns     251ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -arch=sm_35 -rdc=true optimizaciones3.cu -o optimizaciones3 -lcudadevrt\n",
    "# 16 32 64 128 512\n",
    "!nvprof ./optimizaciones3 16\n",
    "!nvprof ./optimizaciones3 32\n",
    "!nvprof ./optimizaciones3 64\n",
    "!nvprof ./optimizaciones3 128\n",
    "!nvprof ./optimizaciones3 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKovw2qM4Y8-",
    "outputId": "7ea65abd-c5f8-4d9e-a239-57439f74e09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10791938451246028\n",
      "0.14864525840441545\n",
      "0.24598595082789765\n",
      "1.0\n",
      "22.495400568656965\n"
     ]
    }
   ],
   "source": [
    "# cálculo de ratios\n",
    "\n",
    "rt = [5.162, 7.11, 11.766, 47.832, 1076]\n",
    "for r in rt:\n",
    "  print(r/rt[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXaIvX4I4grk"
   },
   "source": [
    "El compendio de resultado obtenidos es de: \n",
    "\n",
    "GPU sin usar memoria compartidad | \t| Tiempo de Ejecución (msec) | \t| \t- |  -   \n",
    "--- | --- | --- | ---  | --- | ---| \n",
    "Tamaño de la matriz\t | CPU- >GPU |\tGPU- >CPU | \tEjecución kernel | \tRatio comparado con 128x128\t | GFLOPs  | \n",
    "16x16\t| 0.0034| 0.0021 | 5.162| 0.107| 1.206|\n",
    "32x32\t| 0.0037| 0.0027 |7.11  |0.148 |7.807| \n",
    "64x64\t| 0.006| 0.003| 11.766 | 0.246 |39.94 |\n",
    "128x128\t| 0.18 | 0.0069| 47.832|1| 85.39|\n",
    "512x512\t| 0.179 | 0.081| 1076 | 22.49| 249.4|\n",
    "\n",
    "\n",
    "Puede apreciarse cómo los tiempos de CPU->GPU y viceversa no han aumentado significativamente, pero sí lo ha hecho el tiempo de ejecución; y por ende, también a disminuido el número de GFLOPS. \n",
    "\n",
    "Sin embargo, algo llamativo es que el ratio se mantiene constante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4poCRKI5z3h"
   },
   "source": [
    "# Reducción en GPU\n",
    "\n",
    "Comenzaremos mostrando el código proporcionado y explicándolo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3uMD5Q7DF6p",
    "outputId": "07178303-b2ad-42fb-9736-ac3e434e7935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction0.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction0.cu\n",
    "\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, int n)\n",
    "{\n",
    "  int stride;\n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
    "  if(threadIdx.x + blockDim.x < n)\n",
    "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  for(stride = 1 ; stride < blockDim.x; stride *= 2)\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if(threadIdx.x % (2*stride) == 0)\n",
    "          scratch[threadIdx.x] += scratch[threadIdx.x + stride];\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "  if(threadIdx.x == 0)\n",
    "    g_data[0] = scratch[0];\n",
    "return; \n",
    "}\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "            // initialize the input data on the host to be integer values\n",
    "            // between 0 and 1000\n",
    "            for( unsigned int i = 0; i < num_elements; ++i)\n",
    "            {\n",
    "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
    "                h_data[i] = i*1.0;\n",
    "}\n",
    "        // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "   //int threads = (num_elements/2) + num_elements%2;\n",
    "   int threads = num_elements;\n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5NFDFyoEXWP"
   },
   "source": [
    "La funciones que aparecen son las siguientes: \n",
    "1. `void reduction(float *g_data, int n)`\n",
    "2. `computeOnDevice(float* h_data, int num_elements)`\n",
    "3. `void computeGold( float* reference, float* idata, const unsigned int len)`\n",
    "4. `main`\n",
    "Que realizan las funciones: \n",
    "\n",
    "### 1. `void reduction(float *g_data, int n)`. \n",
    "\n",
    "- Utilizando la memoria compartida guarda los `n` primeros elementos en un vector. \n",
    "- Realiza la suma acumulada en la posición $X$  de $2^i \\leq n$, es decir implementa el **esquema 2**, de esta manera se simula en una hebra el proceso iterarivo de sumar los elementos que disten distancia 2 de un vector y después reducir la longitud del vector a la mitad. \n",
    "\n",
    "### 2. `computeOnDevice(float* h_data, int num_elements)`\n",
    "Realiza las funciones pertinentes de CUDA, ya sea de copia en memoria y llamada a la función para poder ejectuar `reduction` en la gráfica y obtener los resultados. \n",
    "\n",
    "### 3. `void computeGold( float* reference, float* idata, const unsigned int len)`\n",
    "\n",
    "Realiza la misma reducción en local. \n",
    "\n",
    "### 4. `main` \n",
    "\n",
    "Inicializa el vector de manera aleatoria, llama a las funciones `computeOnDevice` y `computeGold` y comprueba que ambos resultados son iguales. \n",
    "\n",
    "Un ejemplo de ejución del programa es el siguiente: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRI3ni8SI8lJ",
    "outputId": "e4118fcd-c988-45ca-c839-b95786b1572b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    " !/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction0.cu -o labsolReduction0 -lcudadevrt\n",
    " !./labsolReduction0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfazFpHbKnXE"
   },
   "source": [
    "## Apartado 2: Realiza un análisis del efecto en el rendimiento por los accesos a memoria y la divergencia de Threads.\n",
    "\n",
    "Para ello utilizaremos el profile del programa `./labsolReduction0` donde se produce la divergencia. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2qKqf5sMBdG",
    "outputId": "0a66ef9c-7ad7-4817-d685-eab06d062020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==1184== NVPROF is profiling process 1184, command: ./labsolReduction0\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n",
      "==1184== Profiling application: ./labsolReduction0\n",
      "==1184== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   61.25%  4.7040us         1  4.7040us  4.7040us  4.7040us  reduction(float*, int)\n",
      "                   20.00%  1.5360us         1  1.5360us  1.5360us  1.5360us  [CUDA memcpy DtoH]\n",
      "                   18.75%  1.4400us         1  1.4400us  1.4400us  1.4400us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.61%  189.24ms         1  189.24ms  189.24ms  189.24ms  cudaMalloc\n",
      "                    0.19%  353.38us         1  353.38us  353.38us  353.38us  cuDeviceTotalMem\n",
      "                    0.09%  171.53us       101  1.6980us     131ns  78.711us  cuDeviceGetAttribute\n",
      "                    0.05%  99.963us         1  99.963us  99.963us  99.963us  cudaFree\n",
      "                    0.02%  42.052us         2  21.026us  19.496us  22.556us  cudaMemcpy\n",
      "                    0.02%  30.904us         1  30.904us  30.904us  30.904us  cudaLaunchKernel\n",
      "                    0.01%  26.398us         1  26.398us  26.398us  26.398us  cuDeviceGetName\n",
      "                    0.00%  6.2270us         1  6.2270us  6.2270us  6.2270us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.9230us         3     641ns     195ns  1.1970us  cuDeviceGetCount\n",
      "                    0.00%  1.2520us         2     626ns     299ns     953ns  cuDeviceGet\n",
      "                    0.00%     275ns         1     275ns     275ns     275ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!nvprof ./labsolReduction0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ts1_wInKTKR3"
   },
   "source": [
    "Podemos comprobar que la función que más actividad de GPU consume es la función `reduction` es un $71.76\\%$ del tiempo total, aquí se aprecia que es la que contiene la condición de `if`, es decir la divergencia. \n",
    "\n",
    "y en lo que refiere llamadas a la API las que consumen más son (citando la documentación oficial): \n",
    "\n",
    "- `cudaMalloc` cuya función es *Allocate memory on the device* con un tiempo de $99.54\\%$\n",
    "- `cuDeviceTotalMem`: *Returns the total amount of memory on the device* $0.26\\%$\n",
    "\n",
    "Por lo que se deduce que el cuello de botiella principal se encuenta en la gestión de la memoria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LxOKqNjVjNT"
   },
   "source": [
    "## Generalizar el funcionamiento del más eficiente para cualquier tamaño de elementos, N >> Tamaño de bloque. \n",
    "\n",
    "\n",
    "Primero determinaremos qué comportamiento es el más eficiente viendo los tiempos de ejecución del otro ejemplo proporcionado: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciM83Dc3b-Yw",
    "outputId": "dbc30d1f-a796-4ef3-f76d-c5866a0f57a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction1.cu\n",
    "\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, int n)\n",
    "{\n",
    "  int stride;\n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
    "  if(threadIdx.x + blockDim.x < n)\n",
    "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  for(stride = 1 ; stride < blockDim.x; stride *= 2)\n",
    "  {\n",
    "    __syncthreads();\n",
    "    if(threadIdx.x % (2*stride) == 0)\n",
    "          scratch[threadIdx.x] += scratch[threadIdx.x + stride];\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "  if(threadIdx.x == 0)\n",
    "    g_data[0] = scratch[0];\n",
    "return; \n",
    "}\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "            // initialize the input data on the host to be integer values\n",
    "            // between 0 and 1000\n",
    "            for( unsigned int i = 0; i < num_elements; ++i)\n",
    "            {\n",
    "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
    "                h_data[i] = i*1.0;\n",
    "}\n",
    "        // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "   int threads = (num_elements/2) + num_elements%2; \n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0mskp_xVy_M",
    "outputId": "d141660e-1b01-4543-db3e-c09493c9b4da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction3.cu\n",
    "\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, int n)\n",
    "{\n",
    "  int stride;\n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
    "  if(threadIdx.x + blockDim.x < n)\n",
    "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  \n",
    "  ///////  Reduction scheme 3 //////\n",
    "  int stride2;\n",
    "  for (stride = 1, stride2=1; stride <= 9; stride++, stride2<<=1)\n",
    "  {\n",
    "      int t = threadIdx.x << stride;\n",
    "      if (t  + stride2 < n)\n",
    "        scratch[ t ] = scratch[ t ]  + scratch[ t + stride2];\n",
    "     __syncthreads();\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "  if(threadIdx.x == 0)\n",
    "    g_data[0] = scratch[0];\n",
    "return; \n",
    "}\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "            // initialize the input data on the host to be integer values\n",
    "            // between 0 and 1000\n",
    "            for( unsigned int i = 0; i < num_elements; ++i)\n",
    "            {\n",
    "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
    "                h_data[i] = i*1.0;\n",
    "}\n",
    "        // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "   //int threads = (num_elements/2) + num_elements%2;\n",
    "   int threads = num_elements;\n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXaV3Fy1WXav",
    "outputId": "3bd4f602-0e1d-4d5b-f536-039667a7dbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Reduction 0\n",
      "==1261== NVPROF is profiling process 1261, command: ./labsolReduction0\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n",
      "==1261== Profiling application: ./labsolReduction0\n",
      "==1261== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   69.56%  10.016us         1  10.016us  10.016us  10.016us  reduction(float*, int)\n",
      "                   16.44%  2.3680us         1  2.3680us  2.3680us  2.3680us  [CUDA memcpy DtoH]\n",
      "                   14.00%  2.0160us         1  2.0160us  2.0160us  2.0160us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.55%  195.73ms         1  195.73ms  195.73ms  195.73ms  cudaMalloc\n",
      "                    0.24%  465.09us         1  465.09us  465.09us  465.09us  cuDeviceTotalMem\n",
      "                    0.08%  153.12us       101  1.5160us     129ns  63.885us  cuDeviceGetAttribute\n",
      "                    0.06%  122.85us         1  122.85us  122.85us  122.85us  cudaFree\n",
      "                    0.03%  54.052us         2  27.026us  25.253us  28.799us  cudaMemcpy\n",
      "                    0.02%  41.183us         1  41.183us  41.183us  41.183us  cuDeviceGetName\n",
      "                    0.02%  31.197us         1  31.197us  31.197us  31.197us  cudaLaunchKernel\n",
      "                    0.00%  6.6840us         1  6.6840us  6.6840us  6.6840us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.5450us         3     515ns     190ns  1.0430us  cuDeviceGetCount\n",
      "                    0.00%  1.2200us         2     610ns     218ns  1.0020us  cuDeviceGet\n",
      "                    0.00%     248ns         1     248ns     248ns     248ns  cuDeviceGetUuid\n",
      "Reduction 1\n",
      "==1272== NVPROF is profiling process 1272, command: ./labsolReduction1\n",
      "Test FAILED\n",
      "device: 32640.000000  host: 130816.000000\n",
      "==1272== Profiling application: ./labsolReduction1\n",
      "==1272== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   67.18%  8.3840us         1  8.3840us  8.3840us  8.3840us  reduction(float*, int)\n",
      "                   16.92%  2.1110us         1  2.1110us  2.1110us  2.1110us  [CUDA memcpy DtoH]\n",
      "                   15.90%  1.9840us         1  1.9840us  1.9840us  1.9840us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.61%  191.06ms         1  191.06ms  191.06ms  191.06ms  cudaMalloc\n",
      "                    0.21%  408.42us         1  408.42us  408.42us  408.42us  cuDeviceTotalMem\n",
      "                    0.08%  152.32us       101  1.5080us     127ns  65.208us  cuDeviceGetAttribute\n",
      "                    0.05%  88.992us         1  88.992us  88.992us  88.992us  cudaFree\n",
      "                    0.02%  43.430us         2  21.715us  15.536us  27.894us  cudaMemcpy\n",
      "                    0.01%  27.686us         1  27.686us  27.686us  27.686us  cuDeviceGetName\n",
      "                    0.01%  24.220us         1  24.220us  24.220us  24.220us  cudaLaunchKernel\n",
      "                    0.00%  6.4800us         1  6.4800us  6.4800us  6.4800us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.6270us         2     813ns     291ns  1.3360us  cuDeviceGet\n",
      "                    0.00%  1.5540us         3     518ns     267ns     960ns  cuDeviceGetCount\n",
      "                    0.00%     284ns         1     284ns     284ns     284ns  cuDeviceGetUuid\n",
      "Reduction 3\n",
      "==1283== NVPROF is profiling process 1283, command: ./labsolReduction3\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n",
      "==1283== Profiling application: ./labsolReduction3\n",
      "==1283== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   62.64%  6.9760us         1  6.9760us  6.9760us  6.9760us  reduction(float*, int)\n",
      "                   19.25%  2.1440us         1  2.1440us  2.1440us  2.1440us  [CUDA memcpy DtoH]\n",
      "                   18.10%  2.0160us         1  2.0160us  2.0160us  2.0160us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.69%  244.04ms         1  244.04ms  244.04ms  244.04ms  cudaMalloc\n",
      "                    0.16%  382.41us         1  382.41us  382.41us  382.41us  cuDeviceTotalMem\n",
      "                    0.07%  162.63us       101  1.6100us     127ns  68.160us  cuDeviceGetAttribute\n",
      "                    0.04%  104.80us         1  104.80us  104.80us  104.80us  cudaFree\n",
      "                    0.02%  51.098us         2  25.549us  23.933us  27.165us  cudaMemcpy\n",
      "                    0.01%  31.381us         1  31.381us  31.381us  31.381us  cuDeviceGetName\n",
      "                    0.01%  26.868us         1  26.868us  26.868us  26.868us  cudaLaunchKernel\n",
      "                    0.00%  7.5010us         1  7.5010us  7.5010us  7.5010us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.2670us         3     422ns     191ns     751ns  cuDeviceGetCount\n",
      "                    0.00%  1.0680us         2     534ns     207ns     861ns  cuDeviceGet\n",
      "                    0.00%     273ns         1     273ns     273ns     273ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction1.cu -o labsolReduction1 -lcudadevrt\n",
    "!/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction3.cu -o labsolReduction3 -lcudadevrt\n",
    "print('Reduction 0')\n",
    "!nvprof ./labsolReduction0\n",
    "print('Reduction 1')\n",
    "!nvprof ./labsolReduction1\n",
    "print('Reduction 3')\n",
    "!nvprof ./labsolReduction3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioROslujcece"
   },
   "source": [
    "A la vista de los resultados el tercero es el más eficiente, será el que modificaremos. \n",
    "\n",
    "Observemos que para este código el tamaño de bloque es igual al de elementos. \n",
    "\n",
    "La primera modificación que podemos hacer es determinar un nuevo tamaño de bloque dado por: \n",
    "\n",
    "`int threads = (num_elements/2) + num_elements%2;`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgSleHYzd7g6",
    "outputId": "804e705f-4161-4427-dad0-f2172aa735c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction4.cu\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, int n)\n",
    "{\n",
    "  int stride;\n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  scratch[threadIdx.x ] = g_data[threadIdx.x];\n",
    "  if(threadIdx.x + blockDim.x < n)\n",
    "    scratch[threadIdx.x + blockDim.x] = g_data[threadIdx.x + blockDim.x];\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  \n",
    "  ///////  Reduction scheme 3 //////\n",
    "  int stride2;\n",
    "  for (stride = 1, stride2=1; stride <= 9; stride++, stride2<<=1)\n",
    "  {\n",
    "      int t = threadIdx.x << stride;\n",
    "      if (t  + stride2 < n)\n",
    "        scratch[ t ] = scratch[ t ]  + scratch[ t + stride2];\n",
    "     __syncthreads();\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "  if(threadIdx.x == 0)\n",
    "    g_data[0] = scratch[0];\n",
    "return; \n",
    "}\n",
    "\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "            // initialize the input data on the host to be integer values\n",
    "            // between 0 and 1000\n",
    "            for( unsigned int i = 0; i < num_elements; ++i)\n",
    "            {\n",
    "                //h_data[i] = floorf(1000*(rand()/(float)RAND_MAX));\n",
    "                h_data[i] = i*1.0;\n",
    "}\n",
    "        // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "   int threads = (num_elements/2) + num_elements%2;\n",
    "  \n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKFawQCGeDzl",
    "outputId": "5274d425-1b1e-41be-fbd2-e3b2e5700d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction4.cu -o labsolReduction4 -lcudadevrt\n",
    "! ./labsolReduction4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ClS2c-Xi61K"
   },
   "source": [
    "Podemos generalizar más todavía la formulación, para un número muy pequeño de hebras $threads$ lo que conllevaría  aumentar el número de elementos contiguos a sumar. \n",
    "\n",
    "Para ello cada hebra deberá de realizar la suma de lo que antes eran varias hilos, con este fin los cambios esenciales a la función `reduction` han sido:\n",
    "\n",
    "1. Copia de los elementos del vector en memoria compartida \n",
    "\n",
    "```\n",
    "// Alamacenamos nuestra posición y los contiguos \n",
    "  for(int i = init; i < init + stride_size && i < n; i++){\n",
    "    scratch[i] = g_data[i]; // \n",
    "  }\n",
    "  // Almacenamos los saltos \n",
    "  for (int stride = init+stride_size; stride < n; stride+= stride_size)\n",
    "  {\n",
    "    scratch[stride] = g_data[stride];\n",
    "  }\n",
    "  __syncthreads();\n",
    "```\n",
    "\n",
    "2. Como ahora $thread < n$, los elementos contiguos serán mayores de dos, así que los sumaremos. \n",
    "\n",
    "\n",
    "```\n",
    "///////  Reduction scheme 3 //////\n",
    "  for(int i = init+1; i < init + stride_size; i++){\n",
    "    if(i < n)\n",
    "      scratch[init] = scratch[init] + scratch[i]; // sumamos elementos contiguos \n",
    "    __syncthreads(); // agrupamos\n",
    "  }\n",
    "```\n",
    "\n",
    "3. Finalmente igualmente que hacíamos con stride, sumaremos las primeras casillas que contienen la sumatoria del paso dos:\n",
    "\n",
    "\n",
    "```\n",
    "int stride_size = ( n + blockDim.x -1) / blockDim.x; // ceil \n",
    "  int init = threadIdx.x * stride_size; \n",
    "if (init + j*stride_size < n)\n",
    "        scratch[ init ] = scratch[ init ] + scratch[init  + j*stride_size];\n",
    "```\n",
    "Como suponemos que que $thread$ es muy pequeño, esto tomará pocos valores y por eficiencia lo haremos directamente en la hebra $0$. \n",
    "\n",
    "Notemos además que **hemos adaptado nuestro código para que admita un número de hebras que no sean potencias de dos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHaU2Y33gbB4",
    "outputId": "44cfe6c6-540b-4053-ffd8-82c1df10f2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing labsolReduction5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile labsolReduction5.cu\n",
    "// includes, kernels\n",
    "#include <stdio.h>\n",
    "#include <assert.h>\n",
    "#define NUM_ELEMENTS 512\n",
    "\n",
    "// **===------------------------------------------------------------------===**\n",
    "//! @param g_idata  input data in global memory\n",
    "//                  result is expected in index 0 of g_idata\n",
    "//! @param n        input number of elements to scan from input data\n",
    "// **===------------------------------------------------------------------===**\n",
    "__global__ void reduction(float *g_data, const int n)\n",
    "{\n",
    "  // params\n",
    "  int stride_size = ( n + blockDim.x -1) / blockDim.x; // ceil \n",
    "  int init = threadIdx.x * stride_size; \n",
    "  \n",
    "  // Define shared memory\n",
    "  __shared__ float scratch[NUM_ELEMENTS];\n",
    "  // Load the shared memory\n",
    "  // Alamcenamos nuestra posición y los contiguos \n",
    "  for(int i = init; i < init + stride_size && i < n; i++){\n",
    "    scratch[i] = g_data[i]; // \n",
    "  }\n",
    "  // Almacenamos los saltos \n",
    "  for (int stride = init+stride_size; stride < n; stride+= stride_size)\n",
    "  {\n",
    "    scratch[stride] = g_data[stride];\n",
    "  }\n",
    "  __syncthreads();\n",
    "  // Do sum reduction from shared memory\n",
    "  \n",
    "  ///////  Reduction scheme 3 //////\n",
    "  for(int i = init+1; i < init + stride_size; i++){\n",
    "    if(i < n)\n",
    "      scratch[init] = scratch[init] + scratch[i]; // sumamos elementos contiguos \n",
    "    __syncthreads(); // agrupamos\n",
    "  }\n",
    "  // sumamos el resultado del bloque de la derecha\n",
    "  if(threadIdx.x == 0) {\n",
    "  for(int j = blockDim.x-1; j > 0 ; j-- ){\n",
    "    if (init + j*stride_size < n)\n",
    "        scratch[ init ] = scratch[ init ] + scratch[init  + j*stride_size];\n",
    "    __syncthreads();\n",
    "  }\n",
    "  // Store results back to global memory\n",
    "    g_data[0] = scratch[0];\n",
    "  }\n",
    "return; \n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "// Program main\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv);\n",
    "float computeOnDevice(float* h_data, int array_mem_size);\n",
    "extern \"C\" void computeGold( float* reference, float* idata, const unsigned int len);\n",
    "int main( int argc, char** argv)\n",
    "{\n",
    "    runTest( argc, argv);\n",
    "    return EXIT_SUCCESS;\n",
    "}\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Run naive scan test\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "void runTest( int argc, char** argv)\n",
    "{\n",
    "    int num_elements = NUM_ELEMENTS;\n",
    "    const unsigned int array_mem_size = sizeof( float) * num_elements;\n",
    "    // allocate host memory to store the input data\n",
    "    float* h_data = (float*) malloc( array_mem_size);\n",
    "\n",
    "    // * No arguments: Randomly generate input data and compare against the host's\n",
    "    // initialize the input data on the host to be integer values\n",
    "    // between 0 and 1000\n",
    "    for( unsigned int i = 0; i < num_elements; ++i)\n",
    "      {\n",
    "                  h_data[i] = i*1.0;\n",
    "\n",
    "    }\n",
    "    // compute reference solution\n",
    "    float reference = 0.0f;\n",
    "    computeGold(&reference , h_data, num_elements);\n",
    "    float result = computeOnDevice(h_data, num_elements);\n",
    "    // We can use an epsilon of 0 since values are integral and in a range\n",
    "    // that can be exactly represented\n",
    "    float epsilon = 0.0f;\n",
    "    unsigned int result_regtest = (abs(result - reference) <= epsilon);\n",
    "    printf( \"Test %s\\n\", (1 == result_regtest) ? \"PASSED\" : \"FAILED\");\n",
    "    printf( \"device: %f  host: %f\\n\", result, reference);\n",
    "    \n",
    "    // cleanup memory\n",
    "    free( h_data);\n",
    "}\n",
    "/////////////////////////////////////////////////////////////////////////\n",
    "// Take h_data from host, copies it to device, setup grid and thread\n",
    " // dimentions, excutes kernel function, and copy result of scan back\n",
    " // to h_data.\n",
    " // Note: float* h_data is both the input and the output of this function.\n",
    " /////////////////////////////////////////////////////////////////////////\n",
    " float computeOnDevice(float* h_data, int num_elements)\n",
    " {\n",
    "   float* d_data = NULL;\n",
    "   float result;\n",
    "   // Memory allocation on device side\n",
    "   cudaMalloc((void**)&d_data, num_elements*sizeof(float));\n",
    "   // Copy from host memory to device memory\n",
    "   cudaMemcpy(d_data, h_data, num_elements*sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "   int threads = 3; \n",
    "\n",
    "   // Invoke the kernel\n",
    "   reduction<<<1,threads>>>(d_data,num_elements);\n",
    "   // Copy from device memory back to host memory\n",
    "   cudaMemcpy(&result, d_data, sizeof(float), cudaMemcpyDeviceToHost);\n",
    "   cudaFree(d_data);\n",
    "   return result;\n",
    "}\n",
    " ///////////////////////////////////////////////////////////////////////\n",
    " void computeGold( float* reference, float* idata, const unsigned int len)\n",
    " {\n",
    "   reference[0] = 0;\n",
    "   double total_sum = 0;\n",
    "   unsigned int i;\n",
    "   for( i = 0; i < len; ++i)\n",
    "   {\n",
    "       total_sum += idata[i];\n",
    "   }\n",
    "   reference[0] = total_sum;\n",
    " }\n",
    " ///////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1EuJeGcggRY",
    "outputId": "37a5008f-f900-4f95-e585-2047a3cc72f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "==1363== NVPROF is profiling process 1363, command: ./labsolReduction5\n",
      "Test PASSED\n",
      "device: 130816.000000  host: 130816.000000\n",
      "==1363== Profiling application: ./labsolReduction5\n",
      "==1363== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   91.25%  42.367us         1  42.367us  42.367us  42.367us  reduction(float*, int)\n",
      "                    4.55%  2.1120us         1  2.1120us  2.1120us  2.1120us  [CUDA memcpy DtoH]\n",
      "                    4.20%  1.9520us         1  1.9520us  1.9520us  1.9520us  [CUDA memcpy HtoD]\n",
      "      API calls:   99.71%  261.85ms         1  261.85ms  261.85ms  261.85ms  cudaMalloc\n",
      "                    0.13%  351.39us         1  351.39us  351.39us  351.39us  cuDeviceTotalMem\n",
      "                    0.06%  152.37us       101  1.5080us     128ns  65.985us  cuDeviceGetAttribute\n",
      "                    0.04%  103.47us         1  103.47us  103.47us  103.47us  cudaFree\n",
      "                    0.03%  81.230us         2  40.615us  26.747us  54.483us  cudaMemcpy\n",
      "                    0.01%  31.207us         1  31.207us  31.207us  31.207us  cuDeviceGetName\n",
      "                    0.01%  27.077us         1  27.077us  27.077us  27.077us  cudaLaunchKernel\n",
      "                    0.00%  6.2970us         1  6.2970us  6.2970us  6.2970us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.5200us         3     840ns     290ns  1.9120us  cuDeviceGetCount\n",
      "                    0.00%  1.6490us         2     824ns     291ns  1.3580us  cuDeviceGet\n",
      "                    0.00%     259ns         1     259ns     259ns     259ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc -I /usr/local/cuda/samples/common/inc -arch=sm_35 -rdc=true labsolReduction5.cu -o labsolReduction5 -lcudadevrt\n",
    "!nvprof ./labsolReduction5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ds1JTWQQqWQZ"
   },
   "source": [
    "Podemos observar que el resultado es correcto y que como era de esperar el tiempo se ha visto incrementado. \n",
    "\n",
    "Concretamente, para una ejecución de 3 hebras se ha tardado $442.367us$ mientras que antes para $256$ hebras ha tardado $6.9760us$. \n",
    "\n",
    "Notemos que el ratio de $tiempo \\times numero hebra$ es para el caso $threads = 3$\n",
    "$$442.365 \\times 3 = 1327.101$$ \n",
    "\n",
    "y para el caso $threads = 256$\n",
    "\n",
    "$$6.970 \\times 256 = 1784.32$$ \n",
    "\n",
    "Es decir que el factor de paralelización no es proporcional al beneficio en tiempo, lo que pone de manifiesto la ley de Amdahl: \n",
    "\n",
    "*La mejora obtenida en el rendimiento de un sistema debido a la alteración de uno de sus componentes está limitada por la fracción de tiempo que se utiliza dicho componente`*\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nY1bM8-CfmIs",
    "tXsgi5VVhDeN",
    "Njc2mXiGihEe",
    "3LCY7dKnlab2",
    "lgC8daU3lyYp",
    "qNFf9oksmy_6",
    "Pr0EXXy7nMAh",
    "x1oyFHn2hrxN",
    "Dj_6S9CYn5MF",
    "e1NhUlknrQB3",
    "eD3hkYzatxAz",
    "OFh-s45N-SYR",
    "wil7WJ0y9K_f",
    "wPKobWhu-ud4",
    "yDd3R_Xd-_xo",
    "1G3BFG_W_Oy8",
    "T-jJOTwrATiL",
    "LIgIP4OIF-tV",
    "eNQ6LIcCMIAl",
    "Hj8KxcUCOBrZ",
    "KznwW_Q_VbY0",
    "vG5VQI1jtPdi",
    "mjmnrdsa0Z5G",
    "Y5NFDFyoEXWP",
    "YfazFpHbKnXE"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
